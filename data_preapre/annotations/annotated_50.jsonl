{"paperId": "d88f70c59b02bba47b3b25b36598917e130b950a", "externalIds": {"MAG": "2264517602", "DBLP": "journals/cmmm/LiuTCW16", "PubMedCentral": "4752975", "DOI": "10.1155/2016/6918381", "CorpusId": 20993322, "PubMed": "26941831"}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/d88f70c59b02bba47b3b25b36598917e130b950a", "title": "Drug-Drug Interaction Extraction via Convolutional Neural Networks", "abstract": "Drug-drug interaction (DDI) extraction as a typical relation extraction task in natural language processing (NLP) has always attracted great attention. Most state-of-the-art DDI extraction systems are based on support vector machines (SVM) with a large number of manually defined features. Recently, convolutional neural networks (CNN), a robust machine learning method which almost does not need manually defined features, has exhibited great potential for many NLP tasks. It is worth employing CNN for DDI extraction, which has never been investigated. We proposed a CNN-based method for DDI extraction. Experiments conducted on the 2013 DDIExtraction challenge corpus demonstrate that CNN is a good choice for DDI extraction. The CNN-based DDI extraction method achieves an F-score of 69.75%, which outperforms the existing best performing method by 2.75%.", "label": 1}
{"paperId": "bc9a0045398fa6c8486b6c208011ab9f65220427", "externalIds": {"ACL": "L08-1584", "MAG": "1571200267", "DBLP": "conf/lrec/WentlandKSH08", "CorpusId": 1304185}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/bc9a0045398fa6c8486b6c208011ab9f65220427", "title": "Building a Multilingual Lexical Resource for Named Entity Disambiguation, Translation and Transliteration", "abstract": "In this paper, we present HeiNER, the multilingual Heidelberg Named Entity Resource. HeiNER contains 1,547,586 disambiguated English Named Entities together with translations and transliterations to 15 languages. Our work builds on the approach described in (Bunescu and Pasca, 2006), yet extends it to a multilingual dimension. Translating Named Entities into the various target languages is carried out by exploiting crosslingual information contained in the online encyclopedia Wikipedia. In addition, HeiNER provides linguistic contexts for every NE in all target languages which makes it a valuable resource for multilingual Named Entity Recognition, Disambiguation and Classification. The results of our evaluation against the assessments of human annotators yield a high precision of 0.95 for the NEs we extract from the English Wikipedia. These source language NEs are thus very reliable seeds for our multilingual NE translation method.", "label": 0}
{"paperId": "07788cd9c6693d2cefce6714f21e3988cac1150f", "externalIds": {"ArXiv": "2108.13112", "ACL": "2021.ranlp-1.100", "DBLP": "conf/ranlp/LoukachevitchAB21", "DOI": "10.26615/978-954-452-072-4_100", "CorpusId": 237397713}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/07788cd9c6693d2cefce6714f21e3988cac1150f", "title": "NEREL: A Russian Dataset with Nested Named Entities, Relations and Events", "abstract": "In this paper, we present NEREL, a Russian dataset for named entity recognition and relation extraction. NEREL is significantly larger than existing Russian datasets: to date it contains 56K annotated named entities and 39K annotated relations. Its important difference from previous datasets is annotation of nested named entities, as well as relations within nested entities and at the discourse level. NEREL can facilitate development of novel models that can extract relations between nested named entities, as well as relations on both sentence and document levels. NEREL also contains the annotation of events involving named entities and their roles in the events. The NEREL collection is available via https://github.com/nerel-ds/NEREL.", "label": 0}
{"paperId": "652ff4eb452423ff3b2a94ee9130e39a24c28a00", "externalIds": {"DOI": "10.1101/2024.06.05.24308365", "CorpusId": 270255271}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/652ff4eb452423ff3b2a94ee9130e39a24c28a00", "title": "Assessing equitable use of large language models for clinical decision support in real-world settings: fine-tuning and internal-external validation using electronic health records from South Asia", "abstract": "Objective Fair and safe Large Language Models (LLMs) hold the potential for clinical task-shifting which, if done reliably, can benefit over-burdened healthcare systems, particularly for resource-limited settings and traditionally overlooked populations. However, this powerful technology remains largely understudied in real-world contexts, particularly in the global South. This study aims to assess if openly available LLMs can be used equitably and reliably for processing medical notes in real-world settings in South Asia. Methods We used publicly available medical LLMs to parse clinical notes from a large electronic health records (EHR) database in Pakistan. ChatGPT, GatorTron, BioMegatron, BioBert and ClinicalBERT were tested for bias when applied to these data, after fine-tuning them to a) publicly available clinical datasets I2B2 and N2C2 for medical concept extraction (MCE) and emrQA for medical question answering (MQA), and b) the local EHR dataset. For MCE models were applied to clinical notes with 3-label and 9-label formats and for MQA were applied to medical questions. Internal and external validation performance was measured for a) and b) using F1, precision, recall, and accuracy for MCE and BLEU and ROUGE-L for MQA. Results LLMs not fine-tuned to the local EHR dataset performed poorly, suggesting bias, when externally validated on it. Fine-tuning the LLMs to the local EHR data improved model performance. Specifically, the 3- label precision, recall, F1 score, and accuracy for the dataset improved by 21-31%, 11-21%, 16-27%, and 6-10% amongst GatorTron, BioMegatron, BioBert and ClinicalBERT. As an exception, ChatGPT performed better on the local EHR dataset by 10% for precision and 13% for each of recall, F1 score, and accuracy. 9-label performance trends were similar. Conclusions Publicly available LLMs, predominantly trained in global north settings, were found to be biased when used in a real-world clinical setting. Fine-tuning them to local data and clinical contexts can help improve their reliable and equitable use in resource-limited settings. Close collaboration between clinical and technical experts can ensure responsible and unbiased powerful tech accessible to resource-limited, overburdened settings used in ways that are safe, fair, and beneficial for all.", "label": 1}
{"paperId": "544f8c8e1dade4525ab2992e099715acb9e8ca01", "externalIds": {"MAG": "2044391799", "ACL": "W04-1212", "DBLP": "conf/bionlp/SinclairW04", "DOI": "10.3115/1567594.1567608", "CorpusId": 16811149}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/544f8c8e1dade4525ab2992e099715acb9e8ca01", "title": "Classification from Full Text: A Comparison of Canonical Sections of Scientific Papers", "abstract": "The accelerating growth in biomedical literature has stimulated activity on automated classification of and information extraction from this literature. The work described here attempts to improve on an earlier classification study associating biological articles to GO codes. It demonstrates the need, under particular assumptions, for more access to full text articles and for the use of Part-of-Speech tagging.", "label": 1}
{"paperId": "43d172a6d288e85c59a44655368f9af85490c800", "externalIds": {"DBLP": "conf/bcb/ShahriRRK19", "MAG": "2947205688", "DOI": "10.1101/654475", "CorpusId": 190872871}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/43d172a6d288e85c59a44655368f9af85490c800", "title": "PPPred: Classifying Protein-phenotype Co-mentions Extracted from Biomedical Literature", "abstract": "The MEDLINE database provides an extensive source of scientific articles and heterogeneous biomedical information in the form of unstructured text. One of the most important knowledge present within articles are the relations between human proteins and their phenotypes, which can stay hidden due to the exponential growth of publications. This has presented a range of opportunities for the development of computational methods to extract these biomedical relations from the articles. However, currently, no such method exists for the automated extraction of relations involving human proteins and human phenotype ontology (HPO) terms. In our previous work, we developed a comprehensive database composed of all co-mentions of proteins and phenotypes. In this study, we present a supervised machine learning approach called PPPred (Protein-Phenotype Predictor) for classifying the validity of a given sentence-level co-mention. Using an in-house developed gold standard dataset, we demonstrate that PPPred significantly outperforms several baseline methods. This two-step approach of co-mention extraction and classification constitutes a complete biomedical relation extraction pipeline for extracting protein-phenotype relations. CCS CONCEPTS \u2022Computing methodologies \u2192 Information extraction; Supervised learning by classification; \u2022Applied computing \u2192Bioinformatics;", "label": 1}
{"paperId": "7dce3c780c85c41ff9dfe7511962ecddb2291ab8", "externalIds": {"ACL": "E17-1108", "MAG": "2608829447", "DBLP": "conf/eacl/MoensL17", "DOI": "10.18653/V1/E17-1108", "CorpusId": 17894632}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/7dce3c780c85c41ff9dfe7511962ecddb2291ab8", "title": "Structured Learning for Temporal Relation Extraction from Clinical Records", "abstract": "We propose a scalable structured learning model that jointly predicts temporal relations between events and temporal expressions (TLINKS), and the relation between these events and the document creation time (DCTR). We employ a structured perceptron, together with integer linear programming constraints for document-level inference during training and prediction to exploit relational properties of temporality, together with global learning of the relations at the document level. Moreover, this study gives insights in the results of integrating constraints for temporal relation extraction when using structured learning and prediction. Our best system outperforms the state-of-the art on both the CONTAINS TLINK task, and the DCTR task.", "label": 1}
{"paperId": "9c025e17c3fd857b3ed3370456d0a43389e6570f", "externalIds": {"DBLP": "conf/medinfo/AverbuchKBMR04", "MAG": "2343724232", "DOI": "10.3233/978-1-60750-949-3-282", "CorpusId": 17676347, "PubMed": "15360819"}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/9c025e17c3fd857b3ed3370456d0a43389e6570f", "title": "Context-Sensitive Medical Information Retrieval", "abstract": "Substantial medical data such as pathology reports, operative reports, discharge summaries, and radiology reports are stored in textual form. Databases containing free-text medical narratives often need to be searched to find relevant information for clinical and research purposes. Terms that appear in these documents tend to appear in different contexts. The con-text of negation, a negative finding, is of special importance, since many of the most frequently described findings are those denied by the patient or subsequently \"ruled out.\" Hence, when searching free-text narratives for patients with a certain medical condition, if negation is not taken into account, many of the retrieved documents will be irrelevant. The purpose of this work is to develop a methodology for automated learning of negative context patterns in medical narratives and test the effect of context identification on the performance of medical information retrieval. The algorithm presented significantly improves the performance of information retrieval done on medical narratives. The precision im-proves from about 60%, when using context-insensitive retrieval, to nearly 100%. The impact on recall is only minor. In addition, context-sensitive queries enable the user to search for terms in ways not otherwise available", "label": 1}
{"paperId": "5b6be8682e11bb0187bc79b0781c134bc27802dc", "externalIds": {"CorpusId": 268298305}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/5b6be8682e11bb0187bc79b0781c134bc27802dc", "title": "Relation extraction methods for biomedical literature", "abstract": "Protein-protein interactions (PPIs) play an important role in understanding biological processes. Although recent research in text mining has achieved a significant progress in automatic PPI extraction from literature, performance of existing systems still needs to be improved. In this chapter, we present a novel algorithm for extracting PPIs from literature which consists of two phases. First, we automatically categorize the data into subsets based on its syntactic properties and extract candidate PPI pairs from these subsets. Second, we apply support vector machines (SVM) to classify candidate PPI pairs using features specific for each subset. We obtain promising results on five benchmark datasets: AIMed, BioInfer, HPRD50, IEPA, and LLL with F-scores ranging from 60% to 84%, which are comparable to the state-of-the-art PPI extraction systems. Furthermore, our system achieves the best performance on cross-corpora evaluation and comparative performance in terms of speed.", "label": 1}
{"paperId": "169523e2a6be4b21e544212383c4f1ce2593f05e", "externalIds": {"ACL": "W10-4232", "MAG": "1885537185", "DBLP": "conf/inlg/SparksGMK10", "CorpusId": 13340006}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/169523e2a6be4b21e544212383c4f1ce2593f05e", "title": "UDel: Named Entity Recognition and Reference Regeneration from Surface Text", "abstract": "This report describes the methods and results of a system developed for the GREC Named Entity Recognition and GREC Named Entity Regeneration Challenges 2010. We explain our process of automatically annotating surface text, as well as how we use this output to select improved referring expressions for named entities.", "label": 0}
{"paperId": "1dd018dc97be9d1a8305e23fb97a1473b638ff74", "externalIds": {"DBLP": "journals/access/ShaoCYW20", "MAG": "3015323854", "DOI": "10.1109/ACCESS.2020.2986826", "CorpusId": 216244186}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/1dd018dc97be9d1a8305e23fb97a1473b638ff74", "title": "ELAD: An Entity Linking Based Affiliation Disambiguation Framework", "abstract": "The number of papers has exploded as more and more people and more types of institutions participating in scientific research. At the same time, institution name disambiguation (IND) is getting more sophisticated, which is critical for research assessment, scholar alignment, etc. Previous knowledge-based and rule-based methods require knowledge and rules prepared in advance, which cannot cope with growing and changing data and learning rules, especially for data with a long period and abundant sources. This paper proposes an automatic learning framework to solve the problem, which is based on entity linking, entity type recognition, candidate generation, and result selection. Experiments show that precision and recall is much higher than the traditional method, ELAD learns more knowledge from the knowledge graph, and it can deal with ever-changing and ever-increasing data. What\u2019s more, it solves many problems that cannot be solved by traditional methods: the connection between institution entities, mistakes correction, and the reduction of manual and pre-prepared knowledge. At last, for the case study, we develop two applications based on ELAD which proves its reliability.", "label": 0}
{"paperId": "026f123a3e8820e93a52311ca3221c7de5a61b74", "externalIds": {"MAG": "2385510523", "CorpusId": 63624881}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/026f123a3e8820e93a52311ca3221c7de5a61b74", "title": "A Method of Named Entity Disambiguation Based on Chinese Wikipedia", "abstract": "In this paper,a statistical model is proposed for Chinese named entity disambiguation by making use of rich links information and various types of page information in Chinese Wikipedia.The text and Wikipedia features are combined effectively in this model by different means.At the same time,the word sense options contained in Wikipedia disambiguation pages of the related named entity are considered as candidate named entities.In the experiment,the accuracy 87.5% can be obtained on a small test set.The experimental results show that the proposed method is feasible and effective.", "label": 0}
{"paperId": "358ca777d9992bdc06fdcc1940e3b18a8da68878", "externalIds": {"ACL": "P19-1423", "MAG": "2963014179", "DBLP": "conf/acl/SahuCMA19", "ArXiv": "1906.04684", "DOI": "10.18653/v1/P19-1423", "CorpusId": 184487889}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/358ca777d9992bdc06fdcc1940e3b18a8da68878", "title": "Inter-sentence Relation Extraction with Document-level Graph Convolutional Neural Network", "abstract": "Inter-sentence relation extraction deals with a number of complex semantic relationships in documents, which require local, non-local, syntactic and semantic dependencies. Existing methods do not fully exploit such dependencies. We present a novel inter-sentence relation extraction model that builds a labelled edge graph convolutional neural network model on a document-level graph. The graph is constructed using various inter- and intra-sentence dependencies to capture local and non-local dependency information. In order to predict the relation of an entity pair, we utilise multi-instance learning with bi-affine pairwise scoring. Experimental results show that our model achieves comparable performance to the state-of-the-art neural models on two biochemistry datasets. Our analysis shows that all the types in the graph are effective for inter-sentence relation extraction.", "label": 1}
{"paperId": "b0b31c242318ba1211a19c867a596679b60bf563", "externalIds": {"DBLP": "journals/bioinformatics/TrieschniggPLJKR09", "PubMedCentral": "2682526", "DOI": "10.1093/bioinformatics/btp249", "CorpusId": 9716979, "PubMed": "19376821"}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/b0b31c242318ba1211a19c867a596679b60bf563", "title": "MeSH Up: effective MeSH text classification for improved document retrieval", "abstract": "Motivation: Controlled vocabularies such as the Medical Subject Headings (MeSH) thesaurus and the Gene Ontology (GO) provide an efficient way of accessing and organizing biomedical information by reducing the ambiguity inherent to free-text data. Different methods of automating the assignment of MeSH concepts have been proposed to replace manual annotation, but they are either limited to a small subset of MeSH or have only been compared with a limited number of other systems. Results: We compare the performance of six MeSH classification systems [MetaMap, EAGL, a language and a vector space model-based approach, a K-Nearest Neighbor (KNN) approach and MTI] in terms of reproducing and complementing manual MeSH annotations. A KNN system clearly outperforms the other published approaches and scales well with large amounts of text using the full MeSH thesaurus. Our measurements demonstrate to what extent manual MeSH annotations can be reproduced and how they can be complemented by automatic annotations. We also show that a statistically significant improvement can be obtained in information retrieval (IR) when the text of a user's query is automatically annotated with MeSH concepts, compared to using the original textual query alone. Conclusions: The annotation of biomedical texts using controlled vocabularies such as MeSH can be automated to improve text-only IR. Furthermore, the automatic MeSH annotation system we propose is highly scalable and it generates improvements in IR comparable with those observed for manual annotations. Contact: trieschn@ewi.utwente.nl Supplementary information: Supplementary data are available at Bioinformatics online.", "label": 1}
{"paperId": "0e95a845d6fa9dfed63ce52f793bc376d6feb5a6", "externalIds": {"MAG": "2567101426", "DOI": "10.1109/WSCAR.2016.26", "CorpusId": 15188517}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/0e95a845d6fa9dfed63ce52f793bc376d6feb5a6", "title": "Improved Bayesian Based Method for Classifying Disease Documents", "abstract": "Na\u00efve Bayes has been proved to be decently competitive learning and classification approach in many fields and still been actively researched. We propose a Bayesian based classification method for biomedical disease-related documents. The proposed method relies on the difference in class distribution between the presence vs absence of the attributes. Specifically, in a simple inductive learning setting, the difference in class probability between the presence vs absence of feature fj can be a good metric for the contribution of fj in predicting the class. The proposed method works well with biomedical text abstracts as attribute values (feature count) of word features are not high. We found that heavy medical terms tends to occur with fairly low frequencies in these abstracts but have significant contribution in determining the class and the subject of the document. Therefore, this technique is suitable for biomedical text mining because it gives rise to terms with low per-document frequency and such terms play a good role in predicting the class in biomedical texts. The evaluation is conducted with seven datasets and compared to the Bayesian method as our baseline using accuracy and AUC with encouraging results, and the proposed method outperformed the baseline significantly. Moreover, we investigated the effect of low average frequency terms and their contribution in classification accuracy.", "label": 1}
{"paperId": "11c960208ecd2a391081c923c231ef193336016d", "externalIds": {"MAG": "2508939750", "DBLP": "conf/chase/ZhangBS16", "DOI": "10.1109/CHASE.2016.32", "CorpusId": 5040854}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/11c960208ecd2a391081c923c231ef193336016d", "title": "Bring Biomedical Ontologies to Personalized Healthcare: A Smart Inquiry Framework", "abstract": "High-quality inquiry (i.e. history taking) is the foundation of accurate diagnosis. Traditionally, inquiry occurs between doctors and patients, requiring lots of time and patience, but often receiving a lot of complaints. This paper proposes a smart inquiry framework, aiming for interacting with patient readily by mining personalized questions from biomedical big data. In other words, the patient can tell his feelings at any time and place, then the system will ask you simple questions, just like an experienced and very kind doctor. What you should do is answering Yes or No. Finally, you will get a preliminary suggestion. There are two key technologies in this paper: 1) training a probability graph from the medical big data, as the whole framework's knowledge base, 2) based on the recommendation algorithm, designing an automatic question answering system, to guide the patients speaking out other more symptoms from the initial feeling. The new proposed framework can serve everyone with low cost and high efficiency, helping them to dynamically sort out and record the state of the body. This will play a fundamental role in the field of personalized healthcare.", "label": 1}
{"paperId": "b8df5bcabd43a1b9e8a159bc8249e33408112faa", "externalIds": {"DBLP": "conf/emnlp/BlairB22", "DOI": "10.18653/v1/2022.findings-emnlp.506", "CorpusId": 256631069}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/b8df5bcabd43a1b9e8a159bc8249e33408112faa", "title": "Improving Few-Shot Domain Transfer for Named Entity Disambiguation with Pattern Exploitation", "abstract": ",", "label": 0}
{"paperId": "fa56e8dadd16a897cd89d701b8a9a7285ee0f3d4", "externalIds": {"DBLP": "conf/coling/KhatriSDS22", "ACL": "2022.smm4h-1.32", "CorpusId": 252819301}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/fa56e8dadd16a897cd89d701b8a9a7285ee0f3d4", "title": "UB Health Miners@SMM4H\u201922: Exploring Pre-processing Techniques To Classify Tweets Using Transformer Based Pipelines.", "abstract": "Here we discuss our implementation of two tasks in the Social Media Mining for Health Applications (SMM4H) 2022 shared tasks \u2013 classification, detection, and normalization of Adverse Events (AE) mentioned in English tweets (Task 1) and classification of English tweets self-reporting exact age (Task 4). We have explored different methods and models for binary classification, multi-class classification and named entity recognition (NER) for these tasks. We have also processed the provided dataset for noise, imbalance, and creative language expression from data. Using diverse NLP methods we classified tweets for mentions of adverse drug effects (ADEs) and self-reporting the exact age in the tweets. Further, extracted reactions from the tweets and normalized these adverse effects to a standard concept ID in the MedDRA vocabulary.", "label": 1}
{"paperId": "2d5d2038d87fd9270622284a828e6b3b5cd41417", "externalIds": {"DBLP": "conf/emnlp/XiongYLWC0T23", "DOI": "10.18653/v1/2023.findings-emnlp.586", "CorpusId": 266176243}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/2d5d2038d87fd9270622284a828e6b3b5cd41417", "title": "EARA: Improving Biomedical Semantic Textual Similarity with Entity-Aligned Attention and Retrieval Augmentation", "abstract": ",", "label": 1}
{"paperId": "11eab492b442db28b859ec4c8cfe8241f51e479e", "externalIds": {"DBLP": "conf/cbms/ValleSGZRG21", "DOI": "10.1109/CBMS52027.2021.00022", "CorpusId": 236096666}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/11eab492b442db28b859ec4c8cfe8241f51e479e", "title": "A Meta-Path-Based Prediction Method for Disease Comorbidities", "abstract": "The simultaneous presence of diseases worsens the prognosis of patients and makes their treatment difficult. Identifying the co-occurrence of diseases is key to improving the situation of patients and designing effective therapeutic strategies. On the one hand, the increasing availability of clinical information opens new ways to unveil hidden relationships between diseases. On the other hand, heterogeneous information networks have been used in recent years to discover novel knowledge from disease data, including symptoms, genes or drugs. The use of meta-paths allows the complex semantics of the relationships between the different types of nodes to be included in heterogeneous networks. In this study, we propose a system to predict disease comorbidities through the use of meta-paths in a heterogeneous network of diseases and symptoms, built from textual sources of public access. The results obtained improve those of similar studies based on biological data, and the predictions calculated for diabetes and Crohn's disease are supported by medical literature. Both the used data and the obtained prediction model are publicly accessible.", "label": 1}
{"paperId": "e62324cceeca146d0f295bd0cb8910ef46f46e87", "externalIds": {"CorpusId": 29256242}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/e62324cceeca146d0f295bd0cb8910ef46f46e87", "title": "PTENLoss Does Not Predict for Response to RAD 001 ( Everolimus ) in a Glioblastoma Orthotopic XenograftTest Panel", "abstract": "Purpose:Hyperactivation of the phosphatidylinositol 3-kinase/Akt signaling through disruption of PTEN function is common inglioblastomamultiforme, and these genetic changes are predicted to enhance sensitivity to mammalian target of rapamycin (mTOR) inhibitors such as RAD001 (everolimus). Experimental Design: To test whether PTEN loss could be used as a predictive marker for mTOR inhibitor sensitivity, the response of 17 serially transplantable glioblastoma multiforme xenografts was evaluated in an orthotopic therapy evaluationmodel. Of these17 xenograft lines, 7 have either genomic deletion or mutation of PTEN. Results: Consistent with activation of Akt signaling, there was a good correlation between loss of PTEN function and elevated levels of Akt phosphorylation. However, of the 7 lines with disrupted PTEN function, only 1 tumor line (GBM10) was significantly sensitive to RAD001therapy (25% prolongation inmedian survival), whereas1of10 xenograft lines with wild-type PTENwas significantly sensitive to RAD001 (GS22; 34% prolongation in survival). Relative to placebo, 5 days of RAD001treatment was associated with a marked 66% reduction in theMIB1 proliferation index in the sensitive GBM10 line (deleted PTEN) comparedwith a 25% and 7% reduction in MIB1labeling index in the insensitive GBM14 (mutant PTEN) and GBM15 (wild-type PTEN) lines, respectively. Consistent with a cytostatic antitumor effect, bioluminescent imaging of luciferasetransduced intracranial GBM10 xenografts showed slowed tumor growth without significant tumor regression during RAD001therapy. Conclusion:These data suggest that loss of PTEN function is insufficient to adequately predict responsiveness to mTOR inhibitors in glioblastoma multiforme. The mammalian target of rapamycin (mTOR) is an important modulator of mitogenic signaling in both normal and tumor cells, and small-molecule inhibitors of mTOR have shown promising activity in several tumor types (1\u20133). mTOR functions to integrate mitogenic signals with the nutrient status of the cell to promote cell growth and proliferation only under adequate nutrient conditions. mTOR signals to multiple components of the protein translation machinery to promote the translation of a subset of mRNA transcripts with complex 5\u00b6-untranslated regions (reviewed in ref. 4). Many of these gene products are important for driving tumor cell growth, proliferation, and angiogenesis, and the antitumor effects of mTOR inhibitors are predominantly linked to disruption of these processes. Mitogenic activation of mTOR signaling is controlled in part through the phosphatidylinositol 3-kinase (PI3K)/Akt signaling pathway. Akt-mediated phosphorylation of both mTOR itself and the mTOR inhibitory molecule TSC2 can promote activation of mTOR signaling (5\u20138). The PI3K/Akt signaling pathway is commonly hyperactivated in glioblastoma multiforme through functional loss of the PTEN tumor suppressor protein. In keeping with the hypothesis that constitutive hyperactivity within a signaling pathway results in hypersensitivity to pathway inhibition, several studies in isogenic tumor models have shown that loss of PTEN function results in increased sensitivity to mTOR inhibitors (9 \u2013 11). These observations have prompted several groups to propose clinical trials in which only those patients with tumors lacking PTEN Cancer Therapy: Preclinical Authors\u2019 Affiliations: Departments of Radiation Oncology, Neurosurgery, Neurology, Oncology, and Laboratory Medicine and Pathology and Division of Biostatistics, Mayo Clinic, Rochester, Minnesota; Novartis Institute for BioMedical Research, Basel, Switzerland; and Department of Neurological Surgery and Brain Tumor Research Center, University of California-San Francisco, San Francisco, California Received 9/10/07; revised1/10/08; accepted1/30/08. Grant support: NIH grants NS49720 and CA097257 (C.D. James) and CA108961, CA25224, and CA114740 (J.N. Sarkaria, E. Galanis, and C. Giannini); American Cancer Society Research Scholar Grant (J.N. Sarkaria); and Accelerate Brain Cancer Cure (J.N. Sarkaria and C.D. James). The costs of publication of this article were defrayed in part by the payment of page charges.This article must therefore be hereby marked advertisement in accordance with18 U.S.C. Section1734 solely to indicate this fact. Note: Supplementary data for this article are available at Clinical Cancer Research Online (http://clincancerres.aacrjournals.org/). Requests for reprints: Jann N. Sarkaria, 200 First Street, SW, Rochester, MN 55905. Phone: 507-266-3877; Fax: 502-284-3906; E-mail: sarkaria.jann@ mayo.edu. F2008 American Association for Cancer Research. doi:10.1158/1078-0432.CCR-07-4152 www.aacrjournals.org Clin Cancer Res 2008;14(12) June15, 2008 3993 Research. on June 9, 2017. \u00a9 2008 American Association for Cancer clincancerres.aacrjournals.org Downloaded from function would be treated with a mTOR inhibitor-based regimen. However, other factors, such as energy deprivation and amino acid starvation, are also important mediators of mTOR activity (12\u201320), and given these data, it is not clear whether PTEN status is a major factor that influences in vivo responses to mTOR inhibitors in patient tumors. We have reported previously the development of a panel of glioblastoma multiforme xenografts established from patient samples and passaged serially in the flank of nude mice, and we have used this panel for assessing the influence of epidermal growth factor receptor (EGFR) amplification status and PTEN status on responsiveness to the EGFR inhibitor erlotinib (21). To understand more fully whether PTEN status would be a useful predictor of response to therapy with the mTOR inhibitor RAD001 (everolimus), we correlated the molecular status of PTEN within our xenograft lines with the extent of survival prolongation for orthotopic tumors established from these lines following therapy with RAD001. The results of this study suggest that loss of PTEN function is insufficient to predict RAD001 sensitivity. Materials andMethods Cell culture assays. Established gliomas cell lines differing in PTEN status (PTEN-/-: LN401, BS125II.2, BS153, and U87; PTEN+/+: LN229, LN427, LN751, and LN428) were plated into 96-well plates, incubated overnight, and then treated with graded concentrations of RAD001. After 4 days of incubation at 37jC, cells were fixed onto the plates with 6% glutaraldehyde. After washing in water, cells were stained with methylene blue, washed, and incubated with 3% hydrochloric acid and absorbance was measured at 650 nm. The IC50 values (RAD001 concentration that reduces methylene blue staining by 50%) for each line were calculated using Softmax 1.2.0 software. U87 and U251 cells also plated and treated with RAD001 as described above and then pulsed with [H]thymidine for 2 h. Cells were harvested by trypsinization, transferred onto glass filters, and lysed in distilled water. Filter-bound radioactivity was determined by liquid scintillation", "label": 0}
{"paperId": "a178afaae690ecb70622457f4569bd517e12c5cc", "externalIds": {"MAG": "1653392063", "CorpusId": 45513692}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/a178afaae690ecb70622457f4569bd517e12c5cc", "title": "Classifying Biomedical Text Abstracts based on Hierarchical 'Concept' Structure", "abstract": "Classifying biomedical literature is a difficult and challenging task, especially when a large number of biomedical articles should be organized into a hierarchical structure. In this paper, we present an approach for classifying a collection of biomedical text abstracts downloaded from Medline database with the help of ontology alignment. To accomplish our goal, we construct two types of hierarchies, the OHSUMED disease hierarchy and the Medline abstract disease hierarchies from the OHSUMED dataset and the Medline abstracts, respectively. Then, we enrich the OHSUMED disease hierarchy before adapting it to ontology alignment process for finding probable concepts or categories. Subsequently, we compute the cosine similarity between the vector in probable concepts (in the \"enriched\" OHSUMED disease hierarchy) and the vector in Medline abstract disease hierarchies. Finally, we assign category to the new Medline abstracts based on the similarity score. The results obtained from the experiments show the performance of our proposed approach for hierarchical classification is slightly better than the performance of the multi-class flat classification.", "label": 1}
{"paperId": "524ff6265b7b0a5b4d78c43a8a0790c6079123e3", "externalIds": {"CorpusId": 262091998}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/524ff6265b7b0a5b4d78c43a8a0790c6079123e3", "title": "Automating Biomedical Abstract Screening using Network Embedding", "abstract": ": Systematic review (SR) is an essential process to identify, evaluate, and summarize the \ufb01ndings of all relevant individual studies concerning health-related questions. However, conducting a SR is labor-intensive, as identifying relevant studies is a daunting process that entails multiple researchers screening thousands of articles for relevance. Automating evidence synthesis using machine learning models has been proposed but primarily focuses on the text and ignores additional features like citation information. Recent work demonstrated that citation embeddings can out-perform the text itself, suggesting that better network representation may expedite SRs. Yet, how to utilize the rich information in heterogeneous information networks for network embeddings is understudied. Also, the lack of a uni\ufb01ed source that includes the metadata of biomedical literature makes the research more challenging. To deal with this problem, we propose four works. First, we propose a model that exploits three representations, documents, topics, and citation networks to show the e\ufb00ectiveness of the additional features. Second, we introduce the PubMed Graph Benchmark, one of the largest heterogeneous networks to date, which aggregates the rich meta-data into a uni\ufb01ed source that includes abstracts, authors, citations, MeSH terms, etc. Third, we propose a heterogeneous network embedding model that uses a community-based multi-view graph convolutional network for learning better embeddings for evidence synthesis. Lastly, we propose a hierarchical network embedding model that uses the Poincare embedding model on the MeSH tree and the citation network.", "label": 1}
{"paperId": "7f8b9397184a5daa0178c569206546610d1d3a7a", "externalIds": {"MAG": "1890275775", "PubMedCentral": "4546596", "DOI": "10.1371/journal.pone.0136270", "CorpusId": 2520161, "PubMed": "26295801"}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/7f8b9397184a5daa0178c569206546610d1d3a7a", "title": "Data-Driven Information Extraction from Chinese Electronic Medical Records", "abstract": "Objective This study aims to propose a data-driven framework that takes unstructured free text narratives in Chinese Electronic Medical Records (EMRs) as input and converts them into structured time-event-description triples, where the description is either an elaboration or an outcome of the medical event. Materials and Methods Our framework uses a hybrid approach. It consists of constructing cross-domain core medical lexica, an unsupervised, iterative algorithm to accrue more accurate terms into the lexica, rules to address Chinese writing conventions and temporal descriptors, and a Support Vector Machine (SVM) algorithm that innovatively utilizes Normalized Google Distance (NGD) to estimate the correlation between medical events and their descriptions. Results The effectiveness of the framework was demonstrated with a dataset of 24,817 de-identified Chinese EMRs. The cross-domain medical lexica were capable of recognizing terms with an F1-score of 0.896. 98.5% of recorded medical events were linked to temporal descriptors. The NGD SVM description-event matching achieved an F1-score of 0.874. The end-to-end time-event-description extraction of our framework achieved an F1-score of 0.846. Discussion In terms of named entity recognition, the proposed framework outperforms state-of-the-art supervised learning algorithms (F1-score: 0.896 vs. 0.886). In event-description association, the NGD SVM is superior to SVM using only local context and semantic features (F1-score: 0.874 vs. 0.838). Conclusions The framework is data-driven, weakly supervised, and robust against the variations and noises that tend to occur in a large corpus. It addresses Chinese medical writing conventions and variations in writing styles through patterns used for discovering new terms and rules for updating the lexica.", "label": 1}
{"paperId": "5dfcc1f19a22c3bc081f2ff4410eb1efc7061838", "externalIds": {"DBLP": "journals/corr/abs-2012-08478", "ArXiv": "2012.08478", "MAG": "3111946788", "DOI": "10.1609/aaai.v35i14.17519", "CorpusId": 229180995}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/5dfcc1f19a22c3bc081f2ff4410eb1efc7061838", "title": "Nested Named Entity Recognition with Partially-Observed TreeCRFs", "abstract": "Named entity recognition (NER) is a well-studied task in natural language processing. However, the widely-used sequence labeling framework is difficult to detect entities with nested structures. In this work, we view nested NER as constituency parsing with partially-observed trees and model it with partially-observed TreeCRFs. Specifically, we view all labeled entity spans as observed nodes in a constituency tree, and other spans as latent nodes. With the TreeCRF we achieve a uniform way to jointly model the observed and the latent nodes. To compute the probability of partial trees with partial marginalization, we propose a variant of the Inside algorithm, the Masked Inside algorithm, that supports different inference operations for different nodes (evaluation for the observed, marginalization for the latent, and rejection for nodes incompatible with the observed) with efficient parallelized implementation, thus significantly speeding up training and inference. Experiments show that our approach achieves the state-of-the-art (SOTA) F1 scores on the ACE2004, ACE2005 dataset, and shows comparable performance to SOTA models on the GENIA dataset. We release the code at https://github.com/FranxYao/Partially-Observed-TreeCRFs.", "label": 1}
{"paperId": "c3d92f37c9c2d164d95dcfdeb181dfa758f60437", "externalIds": {"DBLP": "conf/bionlp/StenetorpGHCDLW13", "ACL": "W13-2013", "MAG": "2916147465", "CorpusId": 9610093}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/c3d92f37c9c2d164d95dcfdeb181dfa758f60437", "title": "BioNLP Shared Task 2013: Supporting Resources", "abstract": "This paper describes the technical contribution of the supporting resources provided for the BioNLP Shared Task 2013. Following the tradition of the previous two BioNLP Shared Task events, the task organisers and several external groups sought to make system development easier for the task participants by providing automatically generated analyses using a variety of automated tools. Providing analyses created by different tools that address the same task also enables extrinsic evaluation of the tools through the evaluation of their contributions to the event extraction task. Such evaluation can improve understanding of the applicability and benefits of specific tools and representations. The supporting resources described in this paper will continue to be publicly available from the shared task homepage http://2013.bionlp-st.org/", "label": 1}
{"paperId": "02ec859969d4c4dda92abb4bfff95ade96227be2", "externalIds": {"ArXiv": "2108.02255", "DBLP": "journals/corr/abs-2108-02255", "CorpusId": 236924530}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/02ec859969d4c4dda92abb4bfff95ade96227be2", "title": "An Empirical Study of UMLS Concept Extraction from Clinical Notes using Boolean Combination Ensembles", "abstract": "Our objective in this study is to investigate the behavior of Boolean operators on combining annotation output from multiple Natural Language Processing (NLP) systems across multiple corpora and to assess how filtering by aggregation of Unified Medical Language System (UMLS) Metathesaurus concepts affects system performance for Named Entity Recognition (NER) of UMLS concepts. We used three corpora annotated for UMLS concepts: 2010 i2b2 VA challenge set (31,161 annotations), Multi-source Integrated Platform for Answering Clinical Questions (MiPACQ) corpus (17,457 annotations including UMLS concept unique identifiers), and Fairview Health Services corpus (44,530 annotations). Our results showed that for UMLS concept matching, Boolean ensembling of the MiPACQ corpus trended towards higher performance over individual systems. Use of an approximate grid-search can help optimize the precision-recall tradeoff and can provide a set of heuristics for choosing an optimal set of ensembles.", "label": 1}
{"paperId": "5a8c3728285be5a7e23383e4438df759a5f09289", "externalIds": {"ArXiv": "1909.08135", "DBLP": "journals/corr/abs-1909-08135", "MAG": "2973865639", "CorpusId": 202660640}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/5a8c3728285be5a7e23383e4438df759a5f09289", "title": "Extracting evidence of supplement-drug interactions from literature", "abstract": "To improve discovery of dietary supplement safety information, we demonstrate an automated method for extracting evidence of supplement-drug interactions (SDIs) from scientific text. To address the lack of labeled data in this domain, we use labels of the closely related task of identifying drug-drug interactions (DDIs) for supervision. We fine-tune the contextualized word representations of BERT-large using labeled data from the PDDI corpus. We process 22M abstracts from PubMed using this model, and extract evidence for 55946 unique interactions between 1923 supplements and 2727 drugs (precision: 0.74, accuracy: 0.83), demonstrating that learning the task of DDI classification transfers successfully to the related problem of SDI classification. We implement a freely-available public interface this http URL to browse and search evidence sentences extracted by our model.", "label": 1}
{"paperId": "2c75545d594e5544a1538aa05eb641e91e1bf45f", "externalIds": {"MAG": "2972890185", "DBLP": "conf/smm4h/HeWMZHLY19", "ACL": "W19-3201", "DOI": "10.18653/v1/W19-3201", "CorpusId": 203432068}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/2c75545d594e5544a1538aa05eb641e91e1bf45f", "title": "Extracting Kinship from Obituary to Enhance Electronic Health Records for Genetic Research", "abstract": "Claims database and electronic health records database do not usually capture kinship or family relationship information, which is imperative for genetic research. We identify online obituaries as a new data source and propose a special named entity recognition and relation extraction solution to extract names and kinships from online obituaries. Built on 1,809 annotated obituaries and a novel tagging scheme, our joint neural model achieved macro-averaged precision, recall and F measure of 72.69%, 78.54% and 74.93%, and micro-averaged precision, recall and F measure of 95.74%, 98.25% and 96.98% using 57 kinships with 10 or more examples in a 10-fold cross-validation experiment. The model performance improved dramatically when trained with 34 kinships with 50 or more examples. Leveraging additional information such as age, death date, birth date and residence mentioned by obituaries, we foresee a promising future of supplementing EHR databases with comprehensive and accurate kinship information for genetic research.", "label": 1}
{"paperId": "48685f26b32d199e6a4d80f6c61e62cc9738e403", "externalIds": {"ACL": "W10-1901", "MAG": "2173988953", "DBLP": "conf/bionlp/Vlachos10", "CorpusId": 3878510}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/48685f26b32d199e6a4d80f6c61e62cc9738e403", "title": "Two Strong Baselines for the BioNLP 2009 Event Extraction Task", "abstract": "This paper presents two strong baselines for the BioNLP 2009 shared task on event extraction. First we re-implement a rule-based approach which allows us to explore the task and the effect of domain-adapted parsing on it. We then replace the rule-based component with support vector machine classifiers and achieve performance near the state-of-the-art without using any external resources. The good performances achieved and the relative simplicity of both approaches make them reproducible baselines. We conclude with suggestions for future work with respect to the task representation.", "label": 1}
{"paperId": "b7d2db37e8af746b9324ff4c647123e92b59f5ba", "externalIds": {"DBLP": "journals/tcbb/SiSZRL23", "DOI": "10.1109/TCBB.2022.3173447", "CorpusId": 248833021, "PubMed": "35576420"}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/b7d2db37e8af746b9324ff4c647123e92b59f5ba", "title": "Biomedical Argument Mining Based on Sequential Multi-Task Learning", "abstract": "Biomedical argument mining aims to automatically identify and extract the argumentative structure in biomedical text. It helps to determine not only what positions people adopt, but also why they hold such opinions, which provides valuable insights into medical decision making. Generally, biomedical argument mining consists of three subtasks: argument component identification, argument component classification and relation identification. Current approaches employ conventional multi-task learning framework for jointly addressing the latter two subtasks, and achieve some success. However, explicit sequential dependency between these two subtasks is ignored, which is crucial for accurate biomedical argument mining. Moreover, relation identification is conducted solely based on the argument component pair without considering its potentially valuable context. Therefore, in this paper, a novel sequential multi-task learning approach is proposed for biomedical argument mining. Specifically, to model explicit sequential dependency between argument component classification and relation identification, an information transfer strategy is employed to capture the information of argument component type that is transferred to relation identification. Furthermore, graph convolutional network is employed to model dependency relation among the related argument component pairs. The proposed method has been evaluated on a benchmark dataset and the experimental results show that the proposed method outperforms the state-of-the-art methods.", "label": 1}
{"paperId": "f80523f8aac26806971343eb1a3cc9d8099d8e86", "externalIds": {"ACL": "C10-1078", "DBLP": "conf/coling/LippincottSSK10", "MAG": "1608193633", "CorpusId": 42212}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/f80523f8aac26806971343eb1a3cc9d8099d8e86", "title": "Exploring variation across biomedical subdomains", "abstract": "Previous research has demonstrated the importance of handling differences between domains such as \"newswire\" and \"biomedicine\" when porting NLP systems from one domain to another. In this paper we identify the related issue of subdomain variation, i.e., differences between subsets of a domain that might be expected to behave homogeneously. Using a large corpus of research articles, we explore how subdomains of biomedicine vary across a variety of linguistic dimensions and discover that there is rich variation. We conclude that an awareness of such variation is necessary when deploying NLP systems for use in single or multiple subdomains.", "label": 1}
{"paperId": "eb9fb8385c5824b029633c0cb68a8fb8573380ad", "externalIds": {"DBLP": "conf/naacl/NguyenG15", "ACL": "W15-1506", "MAG": "2251622960", "DOI": "10.3115/v1/W15-1506", "CorpusId": 12585424}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/eb9fb8385c5824b029633c0cb68a8fb8573380ad", "title": "Relation Extraction: Perspective from Convolutional Neural Networks", "abstract": "Up to now, relation extraction systems have made extensive use of features generated by linguistic analysis modules. Errors in these features lead to errors of relation detection and classification. In this work, we depart from these traditional approaches with complicated feature engineering by introducing a convolutional neural network for relation extraction that automatically learns features from sentences and minimizes the dependence on external toolkits and resources. Our model takes advantages of multiple window sizes for filters and pre-trained word embeddings as an initializer on a non-static architecture to improve the performance. We emphasize the relation extraction problem with an unbalanced corpus. The experimental results show that our system significantly outperforms not only the best baseline systems for relation extraction but also the state-of-the-art systems for relation classification.", "label": 0}
{"paperId": "1cd3be6144ecf29f4434727a7a577245baafb3e8", "externalIds": {"ArXiv": "2104.01364", "DBLP": "conf/semeval/GangwarJSM21", "ACL": "2021.semeval-1.175", "DOI": "10.18653/v1/2021.semeval-1.175", "CorpusId": 233025340}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/1cd3be6144ecf29f4434727a7a577245baafb3e8", "title": "Counts@IITK at SemEval-2021 Task 8: SciBERT Based Entity And Semantic Relation Extraction For Scientific Data", "abstract": "This paper presents the system for SemEval 2021 Task 8 (MeasEval). MeasEval is a novel span extraction, classification, and relation extraction task focused on finding quantities, attributes of these quantities, and additional information, including the related measured entities, properties, and measurement contexts. Our submitted system, which placed fifth (team rank) on the leaderboard, consisted of SciBERT with [CLS] token embedding and CRF layer on top. We were also placed first in Quantity (tied) and Unit subtasks, second in MeasuredEntity, Modifier and Qualifies subtasks, and third in Qualifier subtask.", "label": 0}
{"paperId": "ca4c3a01c67c048b9ff654c208f28b91f2aa923a", "externalIds": {"MAG": "2607159126", "DOI": "10.1080/15476286.2017.1312226", "CorpusId": 4964364, "PubMed": "28421868"}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/ca4c3a01c67c048b9ff654c208f28b91f2aa923a", "title": "RKNNMDA: Ranking-based KNN for MiRNA-Disease Association prediction", "abstract": "ABSTRACT Cumulative verified experimental studies have demonstrated that microRNAs (miRNAs) could be closely related with the development and progression of human complex diseases. Based on the assumption that functional similar miRNAs may have a strong correlation with phenotypically similar diseases and vice versa, researchers developed various effective computational models which combine heterogeneous biologic data sets including disease similarity network, miRNA similarity network, and known disease-miRNA association network to identify potential relationships between miRNAs and diseases in biomedical research. Considering the limitations in previous computational study, we introduced a novel computational method of Ranking-based KNN for miRNA-Disease Association prediction (RKNNMDA) to predict potential related miRNAs for diseases, and our method obtained an AUC of 0.8221 based on leave-one-out cross validation. In addition, RKNNMDA was applied to 3 kinds of important human cancers for further performance evaluation. The results showed that 96%, 80% and 94% of predicted top 50 potential related miRNAs for Colon Neoplasms, Esophageal Neoplasms, and Prostate Neoplasms have been confirmed by experimental literatures, respectively. Moreover, RKNNMDA could be used to predict potential miRNAs for diseases without any known miRNAs, and it is anticipated that RKNNMDA would be of great use for novel miRNA-disease association identification.", "label": 0}
{"paperId": "cf6b6a55e3e10fdb5590c66ef6056abe40c867e7", "externalIds": {"ACL": "2020.acl-main.137", "DBLP": "conf/acl/KruiperVCDK20", "MAG": "3025620128", "ArXiv": "2005.07751", "DOI": "10.18653/v1/2020.acl-main.137", "CorpusId": 218674072}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/cf6b6a55e3e10fdb5590c66ef6056abe40c867e7", "title": "In Layman\u2019s Terms: Semi-Open Relation Extraction from Scientific Texts", "abstract": "Information Extraction (IE) from scientific texts can be used to guide readers to the central information in scientific documents. But narrow IE systems extract only a fraction of the information captured, and Open IE systems do not perform well on the long and complex sentences encountered in scientific texts. In this work we combine the output of both types of systems to achieve Semi-Open Relation Extraction, a new task that we explore in the Biology domain. First, we present the Focused Open Biological Information Extraction (FOBIE) dataset and use FOBIE to train a state-of-the-art narrow scientific IE system to extract trade-off relations and arguments that are central to biology texts. We then run both the narrow IE system and a state-of-the-art Open IE system on a corpus of 10K open-access scientific biological texts. We show that a significant amount (65%) of erroneous and uninformative Open IE extractions can be filtered using narrow IE extractions. Furthermore, we show that the retained extractions are significantly more often informative to a reader.", "label": 1}
{"paperId": "3e5de204257ae81d54826c6b38b60493634a0dc7", "externalIds": {"MAG": "2947102967", "PubMedCentral": "6606160", "DOI": "10.5210/ojphi.v11i1.9729", "CorpusId": 190871816}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/3e5de204257ae81d54826c6b38b60493634a0dc7", "title": "ZooPhy: A bioinformatics pipeline for virus phylogeography and surveillance", "abstract": "ObjectiveWe will describe the ZooPhy system for virus phylogeography and public health surveillance [1]. ZooPhy is designed for public health personnel that do not have expertise in bioinformatics or phylogeography. We will show its functionality by performing case studies of different viruses of public health concern including influenza and rabies virus. We will also provide its URL for user feedback by ISDS delegates.IntroductionSequence-informed surveillance is now recognized as an important extension to the monitoring of rapidly evolving pathogens [2]. This includes phylogeography, a field that studies the geographical lineages of species including viruses [3] by using sequence data (and relevant metadata such as sampling location). This work relies on bioinformatics knowledge. For example, the user first needs to find a relevant sequence database, navigate through it, and use proper search parameters to obtain the desired data. They also must ensure that there is sufficient metadata such as collection date and sampling location. They then need to align the sequences and integrate everything into specific software for phylogeography. For example, BEAST [4] is a popular tool for discrete phylogeography. For proper use, the software requires knowledge of phylogenetics and utilization of BEAUti, its XML processing software. The user then needs to use other software, like TreeAnnotator [4], to produce a single (\u201crepresentative\u201d) maximum clade credibility (MCC) tree. Even then, the evolutionary spread of the virus can be difficult to interpret via a simple tree viewer. There is software (such as SpreaD3 [5]) for visualizing a tree within a geographic context, yet for novice users, it might not be easy to use. Currently, there are only a few systems designed to automate these types of tasks for virus surveillance and phylogeography.MethodsWe have developed ZooPhy, a pipeline for sequence-informed surveillance and phylogeography [1]. It is designed for health agency personnel that do not have expertise in bioinformatics or phylogeography. We created a large database of all virus sequences and metadata from GenBank [6] as well as a smaller database for selected viruses perceived to be of great interest for health agencies including: influenza (A, B, and C), Ebola, rabies, West Nile virus, and Zika virus.In Figure 1A, we show our front-end architecture, created in the style of the influenza research database [7], that enables the user to search by: virus, gene name, host, time-frame, and geography. We also allow users to upload their own list of GenBank accessions or unpublished sequences. Hitting \u201cSearch\u201d produces a Results tab which includes the metadata of the sequences. We provide a feature to randomly down-sample by a specified percentage or number. We also allow the user to download the metadata in CSV format or the unaligned sequences in FASTA format.The final tab, \"Run\", includes a text box for specifying an email in order to send job updates and final results on virus spread. We also enable for the user to study the influence of predictors on virus spread (via a generalized linear model). Currently, we have predictors such as temperature, great circle distance, population, and sample size for selected countries. We also offer experts the ability to specify advanced modeling parameters including the molecular clock type (strict vs. relaxed), coalescent tree prior, and chain length and sampling frequency for the Markov-chain Monte Carlo. When the user selects \u201cStart ZooPhy\u201d, a pre-processor eliminates incomplete or non-disjoint record locations and sends the rest for analysis.ResultsWhen initiated, the ZooPhy pipeline includes sequence alignment via Mafft [8] and creation of an XML template via BEASTGen for input into BEAST for discrete phylogeography. It then uses TreeAnnotator [3] to create an MCC tree from the posterior distribution of sampled trees. ZooPhy uses the MCC as input into SpreaD3 for a recreation of the time-estimated migration via a map. If the user selects the GLM option, the system runs an R script to calculate the Bayes factor of the inclusion probability for each predictor and draws a plot including the regression coefficient and its 95% Bayesian credible interval. We are currently working on new visualization techniques such as those demonstrated by Dudas et al. that combine time-oriented spread via a map and evolution on a phylogenetic tree annotated by discrete locations [9].ConclusionsRecent advances in phylodynamics, bioinformatics, and visualization have demonstrated the potential of pipelines to support surveillance. One example is NextStrain which can perform real-time virus phylodynamics [10]. The system has recently been added as an app to the Global Initiative on Sharing Avian Influenza Data (GISAID) database for influenza tracking using DNA sequences [11]. This presentation will highlight a pipeline for virus phylogeography designed for epidemiologists who are not experts in bioinformatics but wish to leverage virus sequence data as part of routine surveillance. We will describe the development and implementation of our system, ZooPhy, and use real-world case studies to demonstrate its functionality. We invite ISDS delegates to use the system via our web portal, https://zodo.asu.edu/zoophy/ and provide feedback on system utilization.References1. Scotch, M., et al., At the intersection of public-health informatics and bioinformatics: using advanced Web technologies for phylogeography. Epidemiology, 2010. 21(6), 764-768.2. Gardy, J.L. and N.J. Loman, Towards a genomics-informed, real-time, global pathogen surveillance system. Nat Rev Genet, 2018. 19: p. 9-20.3. Avise, J.C., Phylogeography : the history and formation of species. 2000, Cambridge, Mass.: Harvard University Press.4. Suchard, M.A., et al., Bayesian phylogenetic and phylodynamic data integration using BEAST 1.10. Virus Evol, 2018. 4.5. Bielejec, F., et al., SpreaD3: Interactive Visualization of Spatiotemporal History and Trait Evolutionary Processes. Mol Biol Evol, 2016. 33(8): p. 2167-9.6. Benson, D. A.,et al., GenBank. Nucleic Acids Res, 2018. 46, p. D41-D47.7. Zhang, Y., et al., Influenza Research Database: An integrated bioinformatics resource for influenza virus research. Nucleic Acids Res, 2017. 45: p. D466-D474.8. Katoh, K. and D.M. Standley, MAFFT: iterative refinement and additional methods. Methods Mol Biol, 2014. 1079: p. 131-46.9. Dudas, G., et al., Virus genomes reveal factors that spread and sustained the Ebola epidemic. Nature, 2017. 544(7650): p. 309-315.10. Hadfield, J., et al., Nextstrain: real-time tracking of pathogen evolution. Bioinformatics, 2018.11. NextFlu. 2018; Available from: https://www.gisaid.org/epiflu-applications/nextflu-app/.\u00a0", "label": 0}
{"paperId": "411c6e5948bb50a9bad23581e2118aca14c24cd2", "externalIds": {"MAG": "2781953834", "CorpusId": 17878549}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/411c6e5948bb50a9bad23581e2118aca14c24cd2", "title": "Protein-protein Interaction Passage Extraction Using the Interaction Pattern Kernel Approach for the BioCreative 2015 BioC Track", "abstract": "Discovering the interactions between proteins mentioned in biomedical literatures is one of the core topics of text mining in the field of life science. In this paper, we propose a system under interaction pattern generation approach to capture frequent PPI patterns in text with the use of official BioC API and Semantic Class Labeling. We also present an interaction pattern tree kernel method that integrates the PPI pattern with convolution tree kernel to extract protein-protein interactions. Empirical evaluations on the LLL, IEPA, and HPRD50 corpora demonstrate that our method is effective and outperforms several well-known PPI extraction methods.", "label": 1}
{"paperId": "9ab261817a91e3e9435607bbfc9b54157c7926c1", "externalIds": {"DBLP": "journals/corr/abs-2209-07834", "ACL": "2022.argmining-1.18", "ArXiv": "2209.07834", "DOI": "10.48550/arXiv.2209.07834", "CorpusId": 252355558}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/9ab261817a91e3e9435607bbfc9b54157c7926c1", "title": "Entity-based Claim Representation Improves Fact-Checking of Medical Content in Tweets", "abstract": "False medical information on social media poses harm to people\u2019s health. While the need for biomedical fact-checking has been recognized in recent years, user-generated medical content has received comparably little attention. At the same time, models for other text genres might not be reusable, because the claims they have been trained with are substantially different. For instance, claims in the SciFact dataset are short and focused: \u201cSide effects associated with antidepressants increases risk of stroke\u201d. In contrast, social media holds naturally-occurring claims, often embedded in additional context: \"\u2018If you take antidepressants like SSRIs, you could be at risk of a condition called serotonin syndrome\u2019 Serotonin syndrome nearly killed me in 2010. Had symptoms of stroke and seizure.\u201d This showcases the mismatch between real-world medical claims and the input that existing fact-checking systems expect. To make user-generated content checkable by existing models, we propose to reformulate the social-media input in such a way that the resulting claim mimics the claim characteristics in established datasets. To accomplish this, our method condenses the claim with the help of relational entity information and either compiles the claim out of an entity-relation-entity triple or extracts the shortest phrase that contains these elements. We show that the reformulated input improves the performance of various fact-checking models as opposed to checking the tweet text in its entirety.", "label": 1}
{"paperId": "10633b9c807e4418dc012414abf2e340c8d7edcf", "externalIds": {"ArXiv": "2406.10671", "CorpusId": 270560782}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/10633b9c807e4418dc012414abf2e340c8d7edcf", "title": "Augmenting Biomedical Named Entity Recognition with General-domain Resources", "abstract": "Training a neural network-based biomedical named entity recognition (BioNER) model usually requires extensive and costly human annotations. While several studies have employed multi-task learning with multiple BioNER datasets to reduce human effort, this approach does not consistently yield performance improvements and may introduce label ambiguity in different biomedical corpora. We aim to tackle those challenges through transfer learning from easily accessible resources with fewer concept overlaps with biomedical datasets. In this paper, we proposed GERBERA, a simple-yet-effective method that utilized a general-domain NER dataset for training. Specifically, we performed multi-task learning to train a pre-trained biomedical language model with both the target BioNER dataset and the general-domain dataset. Subsequently, we fine-tuned the models specifically for the BioNER dataset. We systematically evaluated GERBERA on five datasets of eight entity types, collectively consisting of 81,410 instances. Despite using fewer biomedical resources, our models demonstrated superior performance compared to baseline models trained with multiple additional BioNER datasets. Specifically, our models consistently outperformed the baselines in six out of eight entity types, achieving an average improvement of 0.9% over the best baseline performance across eight biomedical entity types sourced from five different corpora. Our method was especially effective in amplifying performance on BioNER datasets characterized by limited data, with a 4.7% improvement in F1 scores on the JNLPBA-RNA dataset.", "label": 1}
{"paperId": "ccfbf27f0960ea4ccdc8fe8ef7581d0d4bfc363e", "externalIds": {"MAG": "2971345087", "DBLP": "conf/wmt/PengLLL19", "ACL": "W19-5420", "DOI": "10.18653/v1/W19-5420", "CorpusId": 201739611}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/ccfbf27f0960ea4ccdc8fe8ef7581d0d4bfc363e", "title": "Huawei\u2019s NMT Systems for the WMT 2019 Biomedical Translation Task", "abstract": "This paper describes Huawei\u2019s neural machine translation systems for the WMT 2019 biomedical translation shared task. We trained and fine-tuned our systems on a combination of out-of-domain and in-domain parallel corpora for six translation directions covering English\u2013Chinese, English\u2013French and English\u2013German language pairs. Our submitted systems achieve the best BLEU scores on English\u2013French and English\u2013German language pairs according to the official evaluation results. In the English\u2013Chinese translation task, our systems are in the second place. The enhanced performance is attributed to more in-domain training and more sophisticated models developed. Development of translation models and transfer learning (or domain adaptation) methods has significantly contributed to the progress of the task.", "label": 1}
{"paperId": "5287187e504d41db7975313d553f1483e6d45c11", "externalIds": {"CorpusId": 251542057}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/5287187e504d41db7975313d553f1483e6d45c11", "title": "NTTD at the NTCIR-16 Real-MedNLP Task", "abstract": "The NTTD team participated in the Subtask1-CR-JA and Subtask1-RR-JA subtasks of the NTCIR-16 Real-MedNLP Task. This paper reports our approach to solve the NER (named entity recognition) problem when dealing with limited labeled medical documents. The documents are real Case-Report and Radiographic-Report data in Japanese. We first applied our recently developed annotation inconsistency detection tool to detect and correct inappropriate labels within the given training data. Then we applied data augmentation methods to create additional labeled data and combined the original and additional data as training data of our model. In this task, we fine-tuned Flair by the forementioned training data and acquired the results.", "label": 1}
{"paperId": "c9ba1646c3f592a717403a9d6db24fc4a096550e", "externalIds": {"DOI": "10.1088/1742-6596/2504/1/012020", "CorpusId": 258998135}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/c9ba1646c3f592a717403a9d6db24fc4a096550e", "title": "AJE: Attention Mechanism for Entity-relation Joint Extraction", "abstract": "Joint extraction of entities and relations is an significant issue of information extraction, which is very helpful for many downstream tasks, including knowledge base construction, question answering, and biomedical text diagnosis[1], etc. The common approach of existing models is to extract the subject and the relation first, then compute the subject and the relation to obtain the object, and finally, the triplet is judged. However, such an approach cannot efficiently handle of information extraction, and the results are not very good for Subject-Object Overlap (SOO) case. In this paper, a joint entity-relation extraction method AJE is proposed based on dot-product attention mechanism. The method first maps subject, object and relationship into three matrices of Q, K and V. After that, the attention weighting is achieved on these three matrices and the output vector is used to determine whether the triple is correct or not. The F1-score is used in experiments to show that the proposed model is more efficient than the current existing ones. It also has better results in handling other cases such as SOO, multi-triple problem, etc.", "label": 0}
{"paperId": "2d8c9491dd40d1b65caf4467b1c512d5958935c3", "externalIds": {"PubMedCentral": "3296162", "MAG": "2031736760", "DBLP": "journals/ijbi/KadahAF11", "DOI": "10.1155/2011/840181", "CorpusId": 1178933, "PubMed": "22481901"}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/2d8c9491dd40d1b65caf4467b1c512d5958935c3", "title": "Parallel Computation in Medical Imaging Applications", "abstract": "There is currently a rapidly growing interest in parallel computation application in various medical imaging and image processing fields. This trend is expected to continue growing as more sophisticated and challenging medical imaging, image processing, and high-order data visualization problems are being addressed. The ongoing cost drop in computational tools and their wide accessibility play a center role as well. Given its short history, this area is still not a well-defined scientific discipline. The selected topics and papers for this special issue shed more light on various aspects of this expanding field and its potential in accelerating medical imaging applications. \n \nThis special issue contains eleven papers covering various imaging modalities including MRI, CT, X-ray, US, and optical tomography. The papers demonstrated the potential of parallel computation in medical imaging and visualization in a wide range of applications including image reconstruction, image denoising, motion estimation, deformable registration, diffeomorphic mapping, and modeling. \n \nIn the paper entitled \u201cCUDA-accelerated geodesic ray-tracing for fiber tracking,\u201d E. van Aart et al. present an accelerated algorithm for brain fiber tracking. Noninvasive diffusion weighted imaging followed by reconstructing the brain fiber structure provides a unique way to inspect the complex structures inside the brain in a microscopic level. However, these processes are computationally expensive. The proposed algorithm utilizes the parallel structure of a graphics processing unit in combination with the CUDA platform to substantially accelerate the execution time of the fiber tracking by a factor up to 40 times compared to a multithreaded CPU implementation. \n \nIn the paper entitled \u201cEfficient probabilistic and geometric anatomical mapping using particle mesh approximation on GPUs,\u201d L. Ha et al. developed a new three-dimensional deformable registration algorithm for mapping brain datasets. The problem typically involves significant amount of computation time and thus became infeasible for practical purposes. The proposed registration method generates a mapping between anatomies represented as a multicompartment model. The implementation of the algorithm using particle mesh approximation on graphical processing units (GPUs) achieves the speed up of three orders of magnitudes compared to a CPU reference implementation, making it possible to use the technique in time-critical applications. \n \nIn the paper entitled \u201cHeterogeneous computing for vertebra detection and segmentation in X-ray images,\u201d F. Lecron et al. address the low computational efficiency of the conventional active shape model (ACM) algorithm and exploit the potential acceleration achieved when ACM is implemented on a parallel computation architecture. The paper demonstrates a global speedup ranging from 3 to 22, in comparison with the CPU implementation. \n \nIn the paper entitled \u201cMapping iterative medical imaging algorithm on cell accelerator,\u201d M. Xu and P. Thulasiraman investigate the potential of parallel computation in accelerating the image algebraic reconstruction techniques which in one application may benefit image reconstruction on CT machines. The authors efficiently map the optimized algorithm on the cell broadband engine (BE) for improved performance over CPU version. The implementation on a cell BE is shown to be five times faster when compared to the performance on Sun Fire x4600, a shared memory machine. \n \nIn the paper entitled \u201cGPU-accelerated finite element method for modelling light transport in diffuse optical tomography,\u201d M. Schweiger introduces a GPU-accelerated finite element solver for the computation of light transport in scattering media. Solutions are presented for both time-domain and frequency-domain problems. A comparison with a CPU-based implementation shows significant performance gains of the graphics-accelerated solution, with improvements of approximately a factor of 10 and 20 for double- and single-precision computations, respectively. \n \nIn the area of MRI reconstruction, the paper entitled \u201cHigh-performance 3D compressive sensing MRI reconstruction using many-core architectures,\u201d by D. Kim et al., investigates how different throughput-oriented architectures can benefit compressed sensing (CS) MRI reconstruction algorithm and what levels of acceleration are feasible on different modern platforms. The authors demonstrate that a CUDA-based code running on a GPU can reconstruct a 256 \u00d7 160 \u00d7 80 volume from an 8-channel acquisition in as fast as 12 seconds, which is a significant improvement over the state of the art. This achievement may potentially bring CS methods even closer to clinical viability. \n \nIn the paper entitled \u201cTrue 4D image denoising on the GPU,\u201d A. Eklund et al. show the implementation of a four-dimensional denoising algorithm on a GPU. The algorithm was applied to a 4D CT heart dataset of the resolution 512 \u00d7 512 \u00d7 445 \u00d7 20. The result is that the GPU can complete the denoising in as fast as 8 minutes. On the contrary, the CPU implementation requires about 50 minutes. The short processing time increases the clinical value of true 4D image denoising significantly. \n \nIn the field of simulation and phantom modeling, the paper entitled \u201cPatient specific dosimetry phantoms using multichannel LDDMM of the whole body,\u201d by D. J. Tward et al., describes an accelerated automated procedure for creating detailed patient specific pediatric dosimetry phantoms from a small set of segmented organs in a child's CT scan. The algorithm involves full body mappings from adult template to pediatric images using multichannel large deformation diffeomorphic metric mapping with a parallel implementation. The performance of the algorithm was validated on a set of 24 male and 18 female pediatric patients. Running times for the various patients examined ranged from over 30 hours on a single processor to under 1 hour on 24 processors in parallel. \n \nIn the paper entitled \u201cNumerical solution of diffusion models in biomedical imaging on multicore processors,\u201d L. D'Amore et al. address the solution of nonlinear partial differential equations (PDEs) of diffusion/advection type, underlying most problems in image analysis. As a case study, the paper addresses the segmentation of medical structures and performs a comparative study of numerical algorithms arising from using the semi-implicit and the fully implicit discretization schemes. Comparison criteria take into account both the accuracy and the efficiency of the algorithms including convergence, execution time, and parallel efficiency. This analysis is carried out in a multicore-based parallel computing environment. \n \nIn the paper entitled \u201cOn the usage of GPUs for efficient motion estimation in medical image sequences,\u201d J. Thiyagalingam et al. investigate the mapping of an enhanced motion estimation algorithm to novel GPU architectures. Using a database of three-dimensional ultrasound image sequences, the authors show that the mapping leads to substantial performance gains, up to a factor of 60 and can provide near-real-time performance. The paper also shows how architectural peculiarities of these devices can be best exploited in the benefit of algorithms, most specifically for addressing the challenges related to their access patterns and different memory configurations. The paper further evaluates the performance of the algorithm on three different GPU architectures and performs a comprehensive analysis of the results. \n \nIn the paper entitled \u201cFast random permutation tests enable objective evaluation of methods for single subject fMRI analysis\u201d by A. Eklund et al., it is shown that how the computational power of cost-efficient GPUs can be used to speed up random permutation tests. These tests are commonly involved in fMRI data analysis for identifying areas in the brain that are active. However, the computational burden with processing times ranging from hours to days has made them impractical for routine use in single-subject fMRI analysis. A test on GPU with 10000 permutations takes less than a minute, making statistical analysis of advanced detection methods in fMRI practically feasible. To exemplify the permutation-based approach, brain activity maps generated by the general linear model (GLM) and canonical correlation analysis (CCA) are compared at the same significance level.", "label": 0}
{"paperId": "bd98f9090b9c03fcb93ef51510d01d3fd059ba73", "externalIds": {"MAG": "1988946940", "ACL": "W07-1020", "DBLP": "conf/bionlp/Hakenberg07", "DOI": "10.3115/1572392.1572419", "CorpusId": 11328858}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/bd98f9090b9c03fcb93ef51510d01d3fd059ba73", "title": "What\u2019s in a gene name? Automated refinement of gene name dictionaries", "abstract": "Many approaches for named entity recognition rely on dictionaries gathered from curated databases (such as Entrez Gene for gene names.) Strategies for matching entries in a dictionary against arbitrary text use either inexact string matching that allows for known deviations, dictionaries enriched according to some observed rules, or a combination of both. Such refined dictionaries cover potential structural, lexical, orthographical, or morphological variations. In this paper, we present an approach to automatically analyze dictionaries to discover how names are composed and which variations typically occur. This knowledge can be constructed by looking at single entries (names and synonyms for one gene), and then be transferred to entries that show similar patterns in one or more synonyms. For instance, knowledge about words that are frequently missing in (or added to) a name (\"antigen\", \"protein\", \"human\") could automatically be extracted from dictionaries. This paper should be seen as a vision paper, though we implemented most of the ideas presented and show results for the task of gene name recognition. The automatically extracted name composition rules can easily be included in existing approaches, and provide valuable insights into the biomedical sub-language.", "label": 1}
{"paperId": "d624ae62649a9c20e3dabc57375b1d915161bbc7", "externalIds": {"DBLP": "conf/mie/AvillachMJTPDTPCGMBHGHMPFSF09", "MAG": "1500494212", "DOI": "10.3233/978-1-60750-044-5-190", "CorpusId": 13374884, "PubMed": "19745295"}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/d624ae62649a9c20e3dabc57375b1d915161bbc7", "title": "A Semantic Approach for the Homogeneous Identification of Events in Eight Patient Databases: A Contribution to the European eu-ADR Project", "abstract": "The overall objective of the eu-ADR project is the design, development, and validation of a computerised system that exploits data from electronic health records and biomedical databases for the early detection of adverse drug reactions. Eight different databases, containing health records of more than 30 million European citizens, are involved in the project. Unique queries cannot be performed across different databases because of their heterogeneity: Medical record and Claims databases, four different terminologies for coding diagnoses, and two languages for the information described in free text. The aim of our study was to provide database owners with a common basis for the construction of their queries. Using the UMLS, we provided a list of medical concepts, with their corresponding terms and codes in the four terminologies, which should be considered to retrieve the relevant information for the events of interest from the databases.", "label": 1}
{"paperId": "fc3cc0eff910949dc56045e68f7c7a4d8b851edf", "externalIds": {"MAG": "2130594257", "CorpusId": 85720772}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/fc3cc0eff910949dc56045e68f7c7a4d8b851edf", "title": "Gene function prediction by mining biomedical literature", "abstract": "Tese de mestrado em Bioinformatica, apresentada a Universidade de Lisboa, atraves da Faculdade de Ciencias, 2004", "label": 1}
{"paperId": "02a8bf543bb43038f8ab3bb9ca2f8103ae0a5be0", "externalIds": {"MAG": "2128004504", "DBLP": "journals/jamia/WellnerHMAMPYHH07", "DOI": "10.1197/JAMIA.M2435", "CorpusId": 24985266, "PubMed": "17600096"}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/02a8bf543bb43038f8ab3bb9ca2f8103ae0a5be0", "title": "Research Paper: Rapidly Retargetable Approaches to De-identification in Medical Records", "abstract": "OBJECTIVE\nThis paper describes a successful approach to de-identification that was developed to participate in a recent AMIA-sponsored challenge evaluation.\n\n\nMETHOD\nOur approach focused on rapid adaptation of existing toolkits for named entity recognition using two existing toolkits, Carafe and LingPipe.\n\n\nRESULTS\nThe \"out of the box\" Carafe system achieved a very good score (phrase F-measure of 0.9664) with only four hours of work to adapt it to the de-identification task. With further tuning, we were able to reduce the token-level error term by over 36% through task-specific feature engineering and the introduction of a lexicon, achieving a phrase F-measure of 0.9736.\n\n\nCONCLUSIONS\nWe were able to achieve good performance on the de-identification task by the rapid retargeting of existing toolkits. For the Carafe system, we developed a method for tuning the balance of recall vs. precision, as well as a confidence score that correlated well with the measured F-score.", "label": 1}
{"paperId": "5b2bd05d33d52903d52fb1aab0af7958d340147e", "externalIds": {"MAG": "2116937573", "DOI": "10.1111/jsm.12264", "CorpusId": 598879, "PubMed": "23890102"}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/5b2bd05d33d52903d52fb1aab0af7958d340147e", "title": "On MeSH: have female genitalia fallen into oblivion?", "abstract": "MeSH, or Medical Subject Headings, is the most reputable controlled vocabulary in the biomedical community. First introduced in 1963 by the U.S. National Library of Medicine (NLM), it consists today of 26,853 descriptors. Its use enables health information seekers to search and retrieve scientific articles from among the more than 20 million that are indexed in the NLM databases MEDLINE and PubMed [1]. Most descriptors are accompanied by a definition and are organized in a hierarchical tree that permits searching at various levels of specificity [1]. Medical specialties, study designs, diseases, anatomical body parts, and many chemical and pharmaceutical components share the privilege of existing as MeSH descriptors. The most intimate parts of the body\u2014penis, vagina, vulva, foreskin, anal canal, Bartholin\u2019s glands, breasts\u2014are well located, organized, enumerated, and defined in the MeSH repository. \u201cLabia minora\u201d and \u201clabia majora,\u201d however, do not yet appear in MeSH. \u201cClitoris\u201d does exist as a descriptor, though still undefined. Its tree number is A05.360.319.887.436: \u201cAll MeSH Categories\u201d > \u201cAnatomy category\u201d > \u201cUrogenital System\u201d > \u201cGenitalia\u201d > \u201cGenitalia, Female\u201d > \u201cVulva\u201d > \u201cClitoris\u201d. It can also be linked to 23 other subheadings [1]. One must ask, why is the MeSH descriptor \u201cClitoris\u201d not defined? The MeSH Section staff is the board entitled with the task to update the controlled vocabulary. Any accusation that the undefined status of \u201cClitoris\u201d is due to MeSH being a primarily masculine institution oblivious to the idea of female genitalia would be unfounded, as four of the ten MeSH Section staff board are women [1]. Neither can we say that the MeSH section staff has not felt compelled to describe \u201cClitoris\u201d because the term has not drawn enough attention from the scholarly community. If one adds \u201cClitoris\u201d to the PubMed search builder, the database will retrieve 1,263 references. This figure is far from the 32,747 articles tagged under the MeSH descriptor \u201cPenis.\u201d But it is a far larger number than the 336 articles tagged under the MeSH descriptor \u201cOnchocerciasis, Ocular\u201d or the 443 under \u201cAnisakiasis,\u201d and it is closer to the 1,288 tagged under \u201cLarva Migrans\u201d (all parasitic diseases that affect the population of most of the Southern Hemisphere). To those of us dedicated to the study of female genital mutilation (FGM), it is almost insulting that \u201cClitoris\u201d remains undescribed. The reasons behind this absence can be traced back in history. Across the ages, the word \u201cclitoris,\u201d its significance, and the organ\u2019s function as a sexual organ have been controversial [2]. By not defining it, the MeSH repository follows the historical trend of blurring, erasing, and sweeping away the concept, image, and reminiscences of the clitoris [2]. We could write to the MeSH section staff and propose a definition. However, if we scrutinize each one of the ethnic groups in the world, we will come to different conclusions on what \u201cclitoris\u201d means. One can attempt to name a few. The clitoris is that part of the female genitalia that Rwandese men call rugongo and have to strike with the glans of the erect penis during sexual foreplay [3]. In KwaZulu-Natal, South Africa, the clitoris is that part of the body where women perform cuttings and rub \u201clove medicines\u201d on the scars, aiming to increase desirability [4]. Since Mosotho women in Lesotho are aware of the importance of the clitoris in sexual pleasure, some girls consider the clitoris to be a part of their body they would prefer to elongate\u2014instead of attempting to elongate their labia minora [5]. The clitoris is also what Somali girls have excised because it is thought of as the male part of the female body, which needs to be removed in order to humanize a woman [6]. This belief should not be foreign to Westerners; in 1561, the Italian botanist Gabrielo Fallopio established an analogy between the penis and the clitoris, and it was not until 1987 that somebody\u2014the psychologist Josephine Lowndes Sevely\u2014argued that these organs were not similar at all [2]! The clitoris is what more than 3 million girls are at risk to get mutilated, excised, circumcised, cut, scarred, nicked, pricked, or pierced every year [7]. Thousands of those girls live in Northern, high-income countries where recent migrations have brought these issues to light. This has highlighted the need for more evidence-based research to guide health practitioners in the treatment and provision of care for the victims of FGM [8,9]. \u201cGenital Mutilation, female\u201d can be found in PubMed, not as a MeSH descriptor but as an entry term\u2014a mere synonym of what MeSH considers a similar term, the descriptor \u201cCircumcision, Female.\u201d A total of 712 articles are indexed tagged under this descriptor in PubMed. The search (\u201cCircumcision, Female\u201d[Mesh]) AND \u201cClitoris\u201d[Mesh]) gives only 40 results. The MeSH definition of \u201cCircumcision, Female\u201d agrees with the WHO definition of the non-MeSH descriptor \u201cFemale Genital Mutilation\u201d [1,7]. Nevertheless, many scholars advocate that the word \u201ccircumcision\u201d not be used indiscriminately as a synonym of \u201cmutilation.\u201d Putting aside all of its diverse cultural connotations, it cannot be denied that the clitoris is a part of the female genital anatomy. Anatomically, it is an erectile organ composed of cavernous bodies and a glans clitoridis. Microscopically, in vivo dissection followed by histomorphological evaluation of the cavernous erectile tissues of the clitoris has demonstrated the role that the number and characteristics of its smooth muscle cells and its intricate vascular network can play in female sexual arousal response [10]. Functionally, it plays a key role in enhancing female orgasm [2]. The clitoris exists for the scholars aiming to increase the evidence on FGM. It exists for the decision makers working to table new laws against FGM in the parliaments, design health interventions to tackle its gyno-obstetrical complications, and fund campaigns to eradicate FGM. And it exists for the health practitioners caring for the victims of the cultural norms which dictate that their clitoris must be removed [8,9]. Hence, in justice to the estimated hundreds of millions of women in the world who have undergone FGM and also to the millions at risk, the MeSH descriptor \u201cClitoris\u201d deserves to be properly described.", "label": 1}
{"paperId": "88ed818b44ac91d0e410c2444b785ae33db490f5", "externalIds": {"PubMedCentral": "9216524", "DBLP": "journals/biodb/GrissaJOJ22", "DOI": "10.1093/database/baac019", "CorpusId": 245048201, "PubMed": "35348648"}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/88ed818b44ac91d0e410c2444b785ae33db490f5", "title": "Diseases 2.0: a weekly updated database of disease\u2013gene associations from text mining and data integration", "abstract": "The scientific knowledge about which genes are involved in which diseases grows rapidly, which makes it difficult to keep up with new publications and genetics datasets. The DISEASES database aims to provide a comprehensive overview by systematically integrating and assigning confidence scores to evidence for disease\u2013gene associations from curated databases, genome-wide association studies (GWAS), and automatic text mining of the biomedical literature. Here, we present a major update to this resource, which greatly increases the number of associations from all these sources. This is especially true for the text-mined associations, which have increased by at least 9-fold at all confidence cutoffs. We show that this dramatic increase is primarily due to adding full-text articles to the text corpus, secondarily due to improvements to both the disease and gene dictionaries used for named entity recognition, and only to a very small extent due to the growth in number of PubMed abstracts. DISEASES now also makes use of a new GWAS database, TIGA, which considerably increased the number of GWAS-derived disease\u2013gene associations. DISEASES itself is also integrated into several other databases and resources, including GeneCards/MalaCards, Pharos/TCRD, and the Cytoscape stringApp. All data in DISEASES is updated on a weekly basis and is available via a web interface at https://diseases.jensenlab.org, from where it can also be downloaded under open licenses.", "label": 1}
