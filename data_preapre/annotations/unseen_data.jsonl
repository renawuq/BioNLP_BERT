{"paperId": "5b57067ee5088b5faa111137c3cb33cd28a8fe46", "externalIds": {"ArXiv": "2011.01504", "MAG": "3094868181", "DBLP": "journals/corr/abs-2011-01504", "CorpusId": 226237525}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/5b57067ee5088b5faa111137c3cb33cd28a8fe46", "title": "BioNerFlair: biomedical named entity recognition using flair embedding and sequence tagger", "abstract": "Motivation: The proliferation of Biomedical research articles has made the task of information retrieval more important than ever. Scientists and Researchers are having difficulty in finding articles that contain information relevant to them. Proper extraction of biomedical entities like Disease, Drug/chem, Species, Gene/protein, can considerably improve the filtering of articles resulting in better extraction of relevant information. Performance on BioNer benchmarks has progressively improved because of progression in transformers-based models like BERT, XLNet, OpenAI, GPT2, etc. These models give excellent results; however, they are computationally expensive and we can achieve better scores for domain-specific tasks using other contextual string-based models and LSTM-CRF based sequence tagger. Results: We introduce BioNerFlair, a method to train models for biomedical named entity recognition using Flair plus GloVe embeddings and Bidirectional LSTM-CRF based sequence tagger. With almost the same generic architecture widely used for named entity recognition, BioNerFlair outperforms previous state-of-the-art models. I performed experiments on 8 benchmarks datasets for biomedical named entity recognition. Compared to current state-of-the-art models, BioNerFlair achieves the best F1-score of 90.17 beyond 84.72 on the BioCreative II gene mention (BC2GM) corpus, best F1-score of 94.03 beyond 92.36 on the BioCreative IV chemical and drug (BC4CHEMD) corpus, best F1-score of 88.73 beyond 78.58 on the JNLPBA corpus, best F1-score of 91.1 beyond 89.71 on the NCBI disease corpus, best F1-score of 85.48 beyond 78.98 on the Species-800 corpus, while near best results was observed on BC5CDR-chem, BC3CDR-disease, and LINNAEUS corpus."}
{"paperId": "594232d8cecfd0f2cbbb2698649594c0fff39c2f", "externalIds": {"MAG": "1992754166", "DOI": "10.1109/BSEC.2013.6618492", "CorpusId": 30101997}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/594232d8cecfd0f2cbbb2698649594c0fff39c2f", "title": "Energy-based architecture for classification of publication figures", "abstract": "We present an implementation of the experimental and theoretical results obtained in the analysis of text and image content of biomedical publications. Particularly, we propose a novel optical recognition system using an adaptive algorithm for the classification and analysis of highly heterogeneous images in research papers. When compared with conventional algorithms, our technology substantially increases the probability of detection and classification of images buried in text or obscured by other images. We report successful testing of the new architecture using PubMed publications."}
{"paperId": "4116ead5bc5472ea4fdf97b443fdaf6a1b31c2df", "externalIds": {"DBLP": "journals/access/Lopez-GarciaJRA21", "DOI": "10.1109/ACCESS.2021.3080085", "CorpusId": 235077408}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/4116ead5bc5472ea4fdf97b443fdaf6a1b31c2df", "title": "Transformers for Clinical Coding in Spanish", "abstract": "Automatic clinical coding is an essential task in the process of extracting relevant information from unstructured documents contained in electronic health records (EHRs). However, most research in the development of computer-based methods for clinical coding focuses on texts written in English due to the limited availability of medical linguistic resources in languages other than English. With nearly 500 million native speakers, there is a worldwide interest in processing healthcare texts in Spanish. In this study, we systematically analyzed transformer-based models for automatic clinical coding in Spanish. Using a transfer-learning-based approach, the three existing transformer architectures that support the Spanish language, namely, multilingual BERT (mBERT), BETO and XLM-RoBERTa (XLM-R), were first pretrained on a corpus of real-world oncology clinical cases with the goal of adapting transformers to the particularities of Spanish medical texts. The resulting models were fine-tuned on three distinct clinical coding tasks, following a multilabel sentence classification strategy. For each analyzed transformer, the domain-specific version outperformed the original general domain model across those tasks. Moreover, the combination of the developed strategy with an ensemble approach leveraging the predictive capacities of the three distinct transformers yielded the best obtained results, with MAP scores of 0.662, 0.544 and 0.884 on CodiEsp-D, CodiEsp-P and Cantemist-Coding shared tasks, which remarkably improved the previous state-of-the-art performance by 11.6%, 10.3% and 4.4%, respectively. We publicly release the mBERT, BETO and XLMR transformers adapted to the Spanish clinical domain at https://github.com/guilopgar/ClinicalCodingTransformerES, providing the clinical natural language processing community with advanced deep learning methods for performing medical coding and other tasks in the Spanish clinical domain."}
{"paperId": "430d8b0b176ce2d780a20053ccd9cd2b72da9b7d", "externalIds": {"DBLP": "journals/corr/abs-1805-01646", "ArXiv": "1805.01646", "MAG": "2801213160", "CorpusId": 24141378}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/430d8b0b176ce2d780a20053ccd9cd2b72da9b7d", "title": "Cross-lingual Candidate Search for Biomedical Concept Normalization", "abstract": "Biomedical concept normalization links concept mentions in texts to a semantically equivalent concept in a biomedical knowledge base. This task is challenging as concepts can have different expressions in natural languages, e.g. paraphrases, which are not necessarily all present in the knowledge base. Concept normalization of non-English biomedical text is even more challenging as non-English resources tend to be much smaller and contain less synonyms. To overcome the limitations of non-English terminologies we propose a cross-lingual candidate search for concept normalization using a character-based neural translation model trained on a multilingual biomedical terminology. Our model is trained with Spanish, French, Dutch and German versions of UMLS. The evaluation of our model is carried out on the French Quaero corpus, showing that it outperforms most teams of CLEF eHealth 2015 and 2016. Additionally, we compare performance to commercial translators on Spanish, French, Dutch and German versions of Mantra. Our model performs similarly well, but is free of charge and can be run locally. This is particularly important for clinical NLP applications as medical documents underlay strict privacy restrictions."}
{"paperId": "ebecc56f7e1a9b954c7d472306eca0326250998f", "externalIds": {"MAG": "2786191679", "DBLP": "journals/ieicet/LiHZHR18", "DOI": "10.1587/TRANSINF.2017EDP7232", "CorpusId": 37476671}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/ebecc56f7e1a9b954c7d472306eca0326250998f", "title": "An Active Transfer Learning Framework for Protein-Protein Interaction Extraction", "abstract": "SUMMARY Protein-Protein Interaction Extraction (PPIE) from biomedical literatures is an important task in biomedical text mining and has achieved great success on public datasets. However, in real-world applications, the existing PPI extraction methods are limited to label e \ufb00 ort. Therefore, transfer learning method is applied to reduce the cost of manual labeling. Current transfer learning methods su \ufb00 er from negative transfer and lower performance. To tackle this problem, an improved TrAdaBoost algo-rithm is proposed, that is, relative distribution is introduced to initialize the weights of TrAdaBoost to overcome the negative transfer caused by domain di \ufb00 erences. To make further improvement on the performance of transfer learning, an approach combining active learning with the improved TrAd-aBoost is presented. The experimental results on publicly available PPI corpora show that our method outperforms TrAdaBoost and SVM when the labeled data is insu \ufb03 cient,and on document classi\ufb01cation corpora, it also illustrates that the proposed approaches can achieve better performance than TrAdaBoost and TPTSVM in \ufb01nal, which veri\ufb01es the e \ufb00 ectiveness of our methods."}
{"paperId": "2966e82ec5f89f23ec7636acc00c9ee74d491968", "externalIds": {"PubMedCentral": "6014134", "DBLP": "journals/biodb/LimK18", "MAG": "2809349863", "DOI": "10.1093/database/bay060", "CorpusId": 13676496, "PubMed": "29961818"}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/2966e82ec5f89f23ec7636acc00c9ee74d491968", "title": "Chemical\u2013gene relation extraction using recursive neural network", "abstract": "Abstract In this article, we describe our system for the CHEMPROT task of the BioCreative VI challenge. Although considerable research on the named entity recognition of genes and drugs has been conducted, there is limited research on extracting relationships between them. Extracting relations between chemical compounds and genes from the literature is an important element in pharmacological and clinical research. The CHEMPROT task of BioCreative VI aims to promote the development of text mining systems that can be used to automatically extract relationships between chemical compounds and genes. We tested three recursive neural network approaches to improve the performance of relation extraction. In the BioCreative VI challenge, we developed a tree-Long Short-Term Memory networks (tree-LSTM) model with several additional features including a position feature and a subtree containment feature, and we also applied an ensemble method. After the challenge, we applied additional pre-processing steps to the tree-LSTM model, and we tested the performance of another recursive neural network model called Stack-augmented Parser Interpreter Neural Network (SPINN). Our tree-LSTM model achieved an F-score of 58.53% in the BioCreative VI challenge. Our tree-LSTM model with additional pre-processing and the SPINN model obtained F-scores of 63.7 and 64.1%, respectively. Database URL: https://github.com/arwhirang/recursive_chemprot"}
{"paperId": "0f97f0624594fb5ca840a0f1c9a52231922f470a", "externalIds": {"MAG": "2795540478", "DOI": "10.1080/15476286.2018.1460016", "CorpusId": 4599451, "PubMed": "29619882"}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/0f97f0624594fb5ca840a0f1c9a52231922f470a", "title": "ELLPMDA: Ensemble learning and link prediction for miRNA-disease association prediction", "abstract": "ABSTRACT Recently, accumulating evidences have indicated miRNAs play critical roles in the progression and development of various human complex diseases, which pointed out that identifying miRNA-disease association could enable us to understand diseases at miRNA level. Thus, revealing more and more potential miRNA-disease associations is a vital topic in biomedical domain. However, it will be extremely expensive and time-consuming if we examine all the possible miRNA-disease pairs. Therefore, more accurate and efficient methods are being highly requested to detect potential miRNA-disease associations. In this study, we developed a computational model of Ensemble Learning and Link Prediction for miRNA-Disease Association prediction (ELLPMDA) to achieve this goal. By integrating miRNA functional similarity, disease semantic similarity, miRNA-disease association and Gaussian profile kernel similarity for miRNAs and diseases, we constructed a similarity network and utilized ensemble learning to combine rank results given by three classic similarity-based algorithms. To evaluate the performance of ELLPMDA, we exploited global and local Leave-One-Out Cross Validation (LOOCV), 5-fold Cross Validation (CV) and three kinds of case studies. As a result, the AUCs of ELLPMDA is 0.9181, 0.8181 and 0.9193+/\u22120.0002 in global LOOCV, local LOOCV and 5-fold CV, respectively, which significantly exceed almost all the previous methods. Moreover, in three distinct kinds of case studies for Kidney Neoplasms, Lymphoma, Prostate Neoplasms, Colon Neoplasms and Esophageal Neoplasms, 88%, 92%, 86%, 98% and 98% out of the top 50 predicted miRNAs has been confirmed, respectively. Besides, ELLPMDA is based on global similarity measure and applicable to new diseases without any known related miRNAs."}
{"paperId": "ca742e5c1a680b1969f5fbb4dfd0a730c785eded", "externalIds": {"MAG": "70606898", "CorpusId": 40731344, "PubMed": "21347073"}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/ca742e5c1a680b1969f5fbb4dfd0a730c785eded", "title": "Discovering peripheral arterial disease cases from radiology notes using natural language processing.", "abstract": "As part of the Electronic Medical Records and Genomics Network, we applied, extended and evaluated an open source clinical Natural Language Processing system, Mayo's Clinical Text Analysis and Knowledge Extraction System, for the discovery of peripheral arterial disease cases from radiology reports. The manually created gold standard consisted of 223 positive, 19 negative, 63 probable and 150 unknown cases. Overall accuracy agreement between the system and the gold standard was 0.93 as compared to a named entity recognition baseline of 0.46. Sensitivity for the positive, probable and unknown cases was 0.93-0.96, and for the negative cases was 0.72. Specificity and negative predictive value for all categories were in the 90's. The positive predictive value for the positive and unknown categories was in the high 90's, for the negative category was 0.84, and for the probable category was 0.63. We outline the main sources of errors and suggest improvements."}
{"paperId": "37112eae96347fd0fb5970e31130534f9232048e", "externalIds": {"MAG": "2065274778", "DBLP": "journals/corr/abs-2004-01185", "DOI": "10.1117/12.2007192", "CorpusId": 206396264, "PubMed": "29170580"}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/37112eae96347fd0fb5970e31130534f9232048e", "title": "Introducing anisotropic Minkowski functionals and quantitative anisotropy measures for local structure analysis in biomedical imaging", "abstract": "The ability of Minkowski Functionals to characterize local structure in different biological tissue types has been demonstrated in a variety of medical image processing tasks. We introduce anisotropic Minkowski Functionals (AMFs) as a novel variant that captures the inherent anisotropy of the underlying gray-level structures. To quantify the anisotropy characterized by our approach, we further introduce a method to compute a quantitative measure motivated by a technique utilized in MR diffusion tensor imaging, namely fractional anisotropy. We showcase the applicability of our method in the research context of characterizing the local structure properties of trabecular bone micro-architecture in the proximal femur as visualized on multi-detector CT. To this end, AMFs were computed locally for each pixel of ROIs extracted from the head, neck and trochanter regions. Fractional anisotropy was then used to quantify the local anisotropy of the trabecular structures found in these ROIs and to compare its distribution in different anatomical regions. Our results suggest a significantly greater concentration of anisotropic trabecular structures in the head and neck regions when compared to the trochanter region (p < 10-4). We also evaluated the ability of such AMFs to predict bone strength in the femoral head of proximal femur specimens obtained from 50 donors. Our results suggest that such AMFs, when used in conjunction with multi-regression models, can outperform more conventional features such as BMD in predicting failure load. We conclude that such anisotropic Minkowski Functionals can capture valuable information regarding directional attributes of local structure, which may be useful in a wide scope of biomedical imaging applications."}
{"paperId": "b39435346d91f6e3b71f7f995a5f6df12a98b184", "externalIds": {"DOI": "10.25881/18110193_2023_3_30", "CorpusId": 269101448}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/b39435346d91f6e3b71f7f995a5f6df12a98b184", "title": "ALGORITHM FOR UMLS METATHESAURUS CONCEPTS SPECIFICITY ESTIMATION USING EXAMPLE OF ANALYSIS OF THE SEMANTIC MODEL DESCRIBING AXIAL SPONDYLOARTHRITIS DIFFERENTIAL DIAGNOSTICS", "abstract": ". Background. Early axial spondyloarthritis (axSpA) diagnostics is a difficult task requiring clinical decision support (CDS) making. Currently, there is a big unstructured data applicable in CDS systems development. Semantic data analysis is a complex issue to solve, and unified tools for named entity recognition are required. The biggest data source for biomedical text annotation is the Unified Medical Language System (UMLS) Metathesaurus. It includes more than 11 million atomic terms for writing of 4.6 million concepts. The main issue in UMLS using for medical text analysis is a presence of numerous unspecified (generic) terms without any clinical value. Their application leads to significant decrease of searching results. That is why tools for automatic specificity degree estimation are needed to be developed. Aim. To develop an algorithm for specificity degree estimation for UMLS metathesaurus concepts (using example of axial spondyloarthritis). Methods. English clinical abstracts have been used as data source for automatic UMLS named entity recognition. They have been extracted using free search engine PubMed followed by integration into single electronic corpus. Then each of 24276 texts in corpus has been labeled (affiliated with one of diagnosis in differential list for axSpA) and used for UMLS concepts mapping. A total of 8260 UMLS concepts have been recognized. Each term received an expert binary label of relative specificity. Results. Rules for concepts specificity degree estimation have been developed based on comparison of 4 parameters: mean length of hierarchical chain, total count of direct relationships, TF-IDF score and count of hierarchical relationships with child concepts UMLS. These rules have been integrated into the total algorithm for UMLS concepts specificity degree estimation. Its accuracy was 99,1% for test data sample for paired comparisons. But its accuracy for solid comparison of all extracted concepts was 74,2%, which less than desirable for substantiation of this algorithm use for automatically terms big sets cutbacks. That is why some limitations for developed algorithm have been outlined."}
{"paperId": "1400adc26880405468fba432d00360edb8ce7aeb", "externalIds": {"ACL": "2020.crac-1.12", "CorpusId": 227230324}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/1400adc26880405468fba432d00360edb8ce7aeb", "title": "Enhanced Labelling in Active Learning for Coreference Resolution", "abstract": "In this paper we describe our attempt to increase the amount of information that can be retrieved through active learning sessions compared to previous approaches. We optimise the annotator\u2019s labelling process using active learning in the context of coreference resolution. Using simulated active learning experiments, we suggest three adjustments to ensure the labelling time is spent as efficiently as possible. All three adjustments provide more information to the machine learner than the baseline, though a large impact on the F1 score over time is not observed. Compared to previous models, we report a marginal F1 improvement on the final coreference models trained using for two out of the three approaches tested when applied to the English OntoNotes 2012 Coreference Resolution data. Our best-performing model achieves 58.01 F1, an increase of 0.93 F1 over the baseline model."}
{"paperId": "0a7a35dee8e6e856be8ecb9c3893a78d4fd87b9f", "externalIds": {"MAG": "2783717580", "DBLP": "conf/icsai/Lin17a", "DOI": "10.1109/ICSAI.2017.8248539", "CorpusId": 24574012}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/0a7a35dee8e6e856be8ecb9c3893a78d4fd87b9f", "title": "Terminological ontology learning based on LDA", "abstract": "Ontology has extensive application in many fields, such as retrieval, information extraction and artificial intelligence et al. In this paper we describe a new approach about automatic learning terminological ontologies. this method make use fo the LDA model as concepts and builds relationship such concepts to learn ontologies. The method presents two measures, CP measure and L1 norm measure respectively, of computing semantic similarity between topics to organize these topics into hierarchy structure and forms the new ontology. Moreover, we design a method to determine the size of new ontology that is automatically created from text corpora, which can quantify the quality of the learned ontology in a natural manner. We evaluate our approach through GENIA corpus which is a text collections of biomedical literature. And the experiment results demonstrate the validity and efficiency of proposed method."}
{"paperId": "634e8a148fbe96cd611c09bdddc85de4bdd8a52d", "externalIds": {"ACL": "2023.acl-long.739", "DBLP": "journals/corr/abs-2212-10823", "ArXiv": "2212.10823", "DOI": "10.48550/arXiv.2212.10823", "CorpusId": 254926992}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/634e8a148fbe96cd611c09bdddc85de4bdd8a52d", "title": "Continual Contrastive Finetuning Improves Low-Resource Relation Extraction", "abstract": "Relation extraction (RE), which has relied on structurally annotated corpora for model training, has been particularly challenging in low-resource scenarios and domains. Recent literature has tackled low-resource RE by self-supervised learning, where the solution involves pretraining the entity pair embedding by RE-based objective and finetuning on labeled data by classification-based objective. However, a critical challenge to this approach is the gap in objectives, which prevents the RE model from fully utilizing the knowledge in pretrained representations. In this paper, we aim at bridging the gap and propose to pretrain and finetune the RE model using consistent objectives of contrastive learning. Since in this kind of representation learning paradigm, one relation may easily form multiple clusters in the representation space, we further propose a multi-center contrastive loss that allows one relation to form multiple clusters to better align with pretraining. Experiments on two document-level RE datasets, BioRED and Re-DocRED, demonstrate the effectiveness of our method. Particularly, when using 1% end-task training data, our method outperforms PLM-based RE classifier by 10.5% and 6.1% on the two datasets, respectively."}
{"paperId": "46cfca8d9167f747638bca8e93047c3aa7f485f6", "externalIds": {"DBLP": "journals/information/KesikuCG22", "DOI": "10.3390/info13100499", "CorpusId": 253012448}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/46cfca8d9167f747638bca8e93047c3aa7f485f6", "title": "Natural Language Processing Techniques for Text Classification of Biomedical Documents: A Systematic Review", "abstract": "The classification of biomedical literature is engaged in a number of critical issues that physicians are expected to answer. In many cases, these issues are extremely difficult. This can be conducted for jobs such as diagnosis and treatment, as well as efficient representations of ideas such as medications, procedure codes, and patient visits, as well as in the quick search of a document or disease classification. Pathologies are being sought from clinical notes, among other sources. The goal of this systematic review is to analyze the literature on various problems of classification of medical texts of patients based on criteria such as: the quality of the evaluation metrics used, the different methods of machine learning applied, the different data sets, to highlight the best methods in this type of problem, and to identify the different challenges associated. The study covers the period from 1 January 2016 to 10 July 2022. We used multiple databases and archives of research articles, including Web Of Science, Scopus, MDPI, arXiv, IEEE, and ACM, to find 894 articles dealing with the subject of text classification, which we were able to filter using inclusion and exclusion criteria. Following a thorough review, we selected 33 articles dealing with biological text categorization issues. Following our investigation, we discovered two major issues linked to the methodology and data used for biomedical text classification. First, there is the data-centric challenge, followed by the data quality challenge."}
{"paperId": "76b99439d524ae1813c30edc4bcad487a30a1f8c", "externalIds": {"ArXiv": "2308.03279", "DBLP": "journals/corr/abs-2308-03279", "DOI": "10.48550/arXiv.2308.03279", "CorpusId": 260682557}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/76b99439d524ae1813c30edc4bcad487a30a1f8c", "title": "UniversalNER: Targeted Distillation from Large Language Models for Open Named Entity Recognition", "abstract": "Large language models (LLMs) have demonstrated remarkable generalizability, such as understanding arbitrary entities and relations. Instruction tuning has proven effective for distilling LLMs into more cost-efficient models such as Alpaca and Vicuna. Yet such student models still trail the original LLMs by large margins in downstream applications. In this paper, we explore targeted distillation with mission-focused instruction tuning to train student models that can excel in a broad application class such as open information extraction. Using named entity recognition (NER) for case study, we show how ChatGPT can be distilled into much smaller UniversalNER models for open NER. For evaluation, we assemble the largest NER benchmark to date, comprising 43 datasets across 9 diverse domains such as biomedicine, programming, social media, law, finance. Without using any direct supervision, UniversalNER attains remarkable NER accuracy across tens of thousands of entity types, outperforming general instruction-tuned models such as Alpaca and Vicuna by over 30 absolute F1 points in average. With a tiny fraction of parameters, UniversalNER not only acquires ChatGPT's capability in recognizing arbitrary entity types, but also outperforms its NER accuracy by 7-9 absolute F1 points in average. Remarkably, UniversalNER even outperforms by a large margin state-of-the-art multi-task instruction-tuned systems such as InstructUIE, which uses supervised NER examples. We also conduct thorough ablation studies to assess the impact of various components in our distillation approach. We release the distillation recipe, data, and UniversalNER models to facilitate future research on targeted distillation."}
{"paperId": "b574ec199b2b1a7a18d856a37ae8862db644465f", "externalIds": {"MAG": "107258648", "ACL": "W10-1911", "DBLP": "conf/bionlp/ChowdhuryL10", "CorpusId": 3852572}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/b574ec199b2b1a7a18d856a37ae8862db644465f", "title": "Disease Mention Recognition with Specific Features", "abstract": "Despite an increasing amount of research on biomedical named entity recognition, there has been not enough work done on disease mention recognition. Difficulty of obtaining adequate corpora is one of the key reasons which hindered this particular research. Previous studies argue that correct identification of disease mentions is the key issue for further improvement of the disease-centric knowledge extraction tasks. In this paper, we present a machine learning based approach that uses a feature set tailored for disease mention recognition and outperforms the state-of-the-art results. The paper also discusses why a feature set for the well studied gene/protein mention recognition task is not necessarily equally effective for other biomedical semantic types such as diseases."}
{"paperId": "087d19037086020275bfb780df8cf1893ee62e97", "externalIds": {"DBLP": "journals/bioinformatics/ZhangZLWYD18", "MAG": "2765742249", "PubMedCentral": "6030919", "DOI": "10.1093/bioinformatics/btx659", "CorpusId": 2957401, "PubMed": "29077847"}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/087d19037086020275bfb780df8cf1893ee62e97", "title": "Drug\u2013drug interaction extraction via hierarchical RNNs on sequence and shortest dependency paths", "abstract": "Motivation Adverse events resulting from drug\u2010drug interactions (DDI) pose a serious health issue. The ability to automatically extract DDIs described in the biomedical literature could further efforts for ongoing pharmacovigilance. Most of neural networks\u2010based methods typically focus on sentence sequence to identify these DDIs, however the shortest dependency path (SDP) between the two entities contains valuable syntactic and semantic information. Effectively exploiting such information may improve DDI extraction. Results In this article, we present a hierarchical recurrent neural networks (RNNs)\u2010based method to integrate the SDP and sentence sequence for DDI extraction task. Firstly, the sentence sequence is divided into three subsequences. Then, the bottom RNNs model is employed to learn the feature representation of the subsequences and SDP, and the top RNNs model is employed to learn the feature representation of both sentence sequence and SDP. Furthermore, we introduce the embedding attention mechanism to identify and enhance keywords for the DDI extraction task. We evaluate our approach using the DDI extraction 2013 corpus. Our method is competitive or superior in performance as compared with other state\u2010of\u2010the\u2010art methods. Experimental results show that the sentence sequence and SDP are complementary to each other. Integrating the sentence sequence with SDP can effectively improve the DDI extraction performance. Availability and implementation The experimental data is available at https://github.com/zhangyijia1979/hierarchical\u2010RNNs\u2010model\u2010for\u2010DDI\u2010extraction. Contact zhyj@dlut.edu.cn or michel.dumontier@maastrichtuniversity.nl. Supplementary information Supplementary data are available at Bioinformatics online."}
{"paperId": "227d0ec1231b951c06c8dc2992e4dcdd5cd62248", "externalIds": {"ACL": "2023.clinicalnlp-1.40", "DBLP": "conf/acl-clinicalnlp/BlankemeierZTKG23", "DOI": "10.18653/v1/2023.clinicalnlp-1.40", "CorpusId": 259833841}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/227d0ec1231b951c06c8dc2992e4dcdd5cd62248", "title": "Interactive Span Recommendation for Biomedical Text", "abstract": "Motivated by the scarcity of high-quality labeled biomedical text, as well as the success of data programming, we introduce KRISS-Search. By leveraging the Unified Medical Language Systems (UMLS) ontology, KRISS-Search addresses an interactive few-shot span recommendation task that we propose. We first introduce unsupervised KRISS-Search and show that our method outperforms existing methods in identifying spans that are semantically similar to a given span of interest, with >50% AUPRC improvement relative to PubMedBERT. We then introduce supervised KRISS-Search, which leverages human interaction to improve the notion of similarity used by unsupervised KRISS-Search. Through simulated human feedback, we demonstrate an enhanced F1 score of 0.68 in classifying spans as semantically similar or different in the low-label setting, outperforming PubMedBERT by 2 F1 points. Finally, supervised KRISS-Search demonstrates competitive or superior performance compared to PubMedBERT in few-shot biomedical named entity recognition (NER) across five benchmark datasets, with an average improvement of 5.6 F1 points. We envision KRISS-Search increasing the efficiency of programmatic data labeling and also providing broader utility as an interactive biomedical search engine."}
{"paperId": "1b806d23d6e1daee1a7fa8df12b009e5c64bee59", "externalIds": {"DBLP": "conf/bionlp/SushilSD21", "ACL": "2021.bionlp-1.5", "DOI": "10.18653/v1/2021.bionlp-1.5", "CorpusId": 235097555}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/1b806d23d6e1daee1a7fa8df12b009e5c64bee59", "title": "Are we there yet? Exploring clinical domain knowledge of BERT models", "abstract": "We explore whether state-of-the-art BERT models encode sufficient domain knowledge to correctly perform domain-specific inference. Although BERT implementations such as BioBERT are better at domain-based reasoning than those trained on general-domain corpora, there is still a wide margin compared to human performance on these tasks. To bridge this gap, we explore whether supplementing textual domain knowledge in the medical NLI task: a) by further language model pretraining on the medical domain corpora, b) by means of lexical match algorithms such as the BM25 algorithm, c) by supplementing lexical retrieval with dependency relations, or d) by using a trained retriever module, can push this performance closer to that of humans. We do not find any significant difference between knowledge supplemented classification as opposed to the baseline BERT models, however. This is contrary to the results for evidence retrieval on other tasks such as open domain question answering (QA). By examining the retrieval output, we show that the methods fail due to unreliable knowledge retrieval for complex domain-specific reasoning. We conclude that the task of unsupervised text retrieval to bridge the gap in existing information to facilitate inference is more complex than what the state-of-the-art methods can solve, and warrants extensive research in the future."}
{"paperId": "9ee289dbda34e13e0e35df9b343738b107fd7ce6", "externalIds": {"MAG": "2252165061", "ACL": "W14-1104", "DBLP": "conf/acl-louhi/ZhaoN14", "DOI": "10.3115/v1/W14-1104", "CorpusId": 7725722}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/9ee289dbda34e13e0e35df9b343738b107fd7ce6", "title": "Domain Adaptation with Active Learning for Coreference Resolution", "abstract": "In the literature, most prior work on coreference resolution centered on the newswire domain. Although a coreference resolution system trained on the newswire domain performs well on newswire texts, there is a huge performance drop when it is applied to the biomedical domain. In this paper, we present an approach integrating domain adaptation with active learning to adapt coreference resolution from the newswire domain to the biomedical domain. We explore the effect of domain adaptation, active learning, and target domain instance weighting for coreference resolution. Experimental results show that domain adaptation with active learning and target domain instance weighting achieves performance on MEDLINE abstracts similar to a system trained on coreference annotation of only target domain training instances, but with a greatly reduced number of target domain training instances that we need to annotate."}
{"paperId": "218e7323c030041e025d6d35ca5cd8cce2088eda", "externalIds": {"MAG": "2902363747", "DBLP": "conf/wmt/HuckSHF18", "ACL": "W18-6446", "DOI": "10.18653/v1/W18-6446", "CorpusId": 53233185}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/218e7323c030041e025d6d35ca5cd8cce2088eda", "title": "LMU Munich\u2019s Neural Machine Translation Systems at WMT 2018", "abstract": "We present the LMU Munich machine translation systems for the English\u2013German language pair. We have built neural machine translation systems for both translation directions (English\u2192German and German\u2192English) and for two different domains (the biomedical domain and the news domain). The systems were used for our participation in the WMT18 biomedical translation task and in the shared task on machine translation of news. The main focus of our recent system development efforts has been on achieving improvements in the biomedical domain over last year\u2019s strong biomedical translation engine for English\u2192German (Huck et al., 2017a). Considerable progress has been made in the latter task, which we report on in this paper."}
{"paperId": "d46b75da1120d949076975ee340232b92faa918b", "externalIds": {"DBLP": "journals/bib/WangC22", "DOI": "10.1093/bib/bbac292", "CorpusId": 250622757, "PubMed": "35849099"}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/d46b75da1120d949076975ee340232b92faa918b", "title": "Predicting miRNA-disease associations based on graph attention networks and dual Laplacian regularized least squares", "abstract": "Increasing biomedical evidence has proved that the dysregulation of miRNAs is associated with human complex diseases. Identification of disease-related miRNAs is of great importance for disease prevention, diagnosis and remedy. To reduce the time and cost of biomedical experiments, there is a strong incentive to develop efficient computational methods to infer potential miRNA-disease associations. Although many computational approaches have been proposed to address this issue, the prediction accuracy needs to be further improved. In this study, we present a computational framework MKGAT to predict possible associations between miRNAs and diseases through graph attention networks (GATs) using dual Laplacian regularized least squares. We use GATs to learn embeddings of miRNAs and diseases on each layer from initial input features of known miRNA-disease associations, intra-miRNA similarities and intra-disease similarities. We then calculate kernel matrices of miRNAs and diseases based on Gaussian interaction profile (GIP) with the learned embeddings. We further fuse the kernel matrices of each layer and initial similarities with attention mechanism. Dual Laplacian regularized least squares are finally applied for new miRNA-disease association predictions with the fused miRNA and disease kernels. Compared with six state-of-the-art methods by 5-fold cross-validations, our method MKGAT receives the highest AUROC value of 0.9627 and AUPR value of 0.7372. We use MKGAT to predict related miRNAs for three cancers and discover that all the top 50 predicted results in the three diseases are confirmed by existing databases. The excellent performance indicates that MKGAT would be a useful computational tool for revealing disease-related miRNAs."}
{"paperId": "8ba999d716a17fc2448c6bdb5d8eec98e0b98e7e", "externalIds": {"MAG": "3087685590", "DOI": "10.6919/ICJE.202001_6(1).0028", "CorpusId": 226671176}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/8ba999d716a17fc2448c6bdb5d8eec98e0b98e7e", "title": "Named Entity Recognition Based on Character-level Language Models and Attention Mechanism", "abstract": "As a basic task in the field of natural language processing, named entity recognition plays an important role in text data processing tasks. Extracting features from the original text can be considered as the first step in the identification of named entities, but on this basic issue, traditional research still stays at the coarser granularity of words. Unlike traditional research, this paper focuses on finer granularity-character-level named entity recognition research. In order to fully extract the character-level feature representation from the character-level language model, this paper uses CNN and BiLSTM to perform feature extraction together, and introduces the attention mechanism to achieve more effective combination of character features and word features, then combines with BiLSTM-CRF to construct a complete end-to-end deep learning model (At- BiLSTM-CNNs-CRF). The experimental results show that its recognition ability exceeds most deep learning models."}
{"paperId": "6f159da950e0776309c4c14430f042284ed6c718", "externalIds": {"ACL": "2022.semeval-1.203", "DBLP": "conf/semeval/NguyenH22", "DOI": "10.18653/v1/2022.semeval-1.203", "CorpusId": 250390969}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/6f159da950e0776309c4c14430f042284ed6c718", "title": "DANGNT-SGU at SemEval-2022 Task 11: Using Pre-trained Language Model for Complex Named Entity Recognition", "abstract": "In this paper, we describe a system that we built to participate in the SemEval 2022 Task 11: MultiCoNER Multilingual Complex Named Entity Recognition, specifically the track Mono-lingual in English. To construct this system, we used Pre-trained Language Models (PLMs). Especially, the Pre-trained Model base on BERT is applied for the task of recognizing named entities by fine-tuning method. We performed the evaluation on two test datasets of the shared task: the Practice Phase and the Evaluation Phase of the competition."}
{"paperId": "254798f2f55448d06d5726e72f2e92a6db54b759", "externalIds": {"DBLP": "journals/jasis/ZouTA20", "MAG": "3001680139", "DOI": "10.1002/asi.24334", "CorpusId": 213409354}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/254798f2f55448d06d5726e72f2e92a6db54b759", "title": "Unified deep neural network for segmentation and labeling of multipanel biomedical figures", "abstract": "Recent efforts in biomedical visual question answering (VQA) research rely on combined information gathered from the image content and surrounding text supporting the figure. Biomedical journals are a rich source of information for such multimodal content indexing. For multipanel figures in these journals, it is critical to develop automatic figure panel splitting and label recognition algorithms to associate individual panels with text metadata in the figure caption and the body of the article. Challenges in this task include large variations in figure panel layout, label location, size, contrast to background, and so on. In this work, we propose a deep convolutional neural network, which splits the panels and recognizes the panel labels in a single step. Visual features are extracted from several layers at various depths of the backbone neural network and organized to form a feature pyramid. These features are fed into classification and regression networks to generate candidates of panels and their labels. These candidates are merged to create the final panel segmentation result through a beam search algorithm. We evaluated the proposed algorithm on the ImageCLEF data set and achieved better performance than the results reported in the literature. In order to thoroughly investigate the proposed algorithm, we also collected and annotated our own data set of 10,642 figures. The experiments, trained on 9,642 figures and evaluated on the remaining 1,000 figures, show that combining panel splitting and panel label recognition mutually benefit each other."}
{"paperId": "8c68dd92e4ea60dd5cda57ed43299b2b013afa41", "externalIds": {"DBLP": "conf/bionlp/LeamanL14", "MAG": "2251872110", "ACL": "W14-3404", "DOI": "10.3115/v1/W14-3404", "CorpusId": 9164895}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/8c68dd92e4ea60dd5cda57ed43299b2b013afa41", "title": "Automated Disease Normalization with Low Rank Approximations", "abstract": "While machine learning methods for named entity recognition (mention-level detection) have become common, machine learning methods have rarely been applied to normalization (concept-level identification). Recent research introduced a machine learning method for normalization based on pairwise learning to rank. This method, DNorm, uses a linear model to score the similarity between mentions and concept names, and has several desirable properties, including learning term variation directly from training data. In this manuscript we employ a dimensionality reduction technique based on low-rank matrix approximation, similar to latent semantic indexing. We compare the performance of the low rank method to previous work, using disease name normalization in the NCBI Disease Corpus as the test case, and demonstrate increased performance as the matrix rank increases. We further demonstrate a significant reduction in the number of parameters to be learned and discuss the implications of this result in the context of algorithm scalability."}
{"paperId": "1d871d47a8269e5f2a9896fe461ea9d62a60491f", "externalIds": {"MAG": "2360236096", "CorpusId": 63553784}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/1d871d47a8269e5f2a9896fe461ea9d62a60491f", "title": "The Comparison Of the Biomedical Named Entity Recognition Models Based On Machine Learning", "abstract": "A great number of biomedical texts have offered enough information for people. Yet the lack of good tools prevents people from getting information and knowledge from them. NER plays a very important role in information retrieval, information extraction, knowledge discovery and so on. Based on the bio-entity recognition task at JNLPBA, this paper focuses on the introduction to the NER models based on machine learning usually used in biomedical texts. It presents a general comparison and discussion in them, and also provides some relative information."}
{"paperId": "8438f1614bd991cbf0edf9d6bda0364a9c14d466", "externalIds": {"MAG": "1885997810", "DBLP": "conf/amia/XuDG09", "CorpusId": 30950454, "PubMed": "20351945"}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/8438f1614bd991cbf0edf9d6bda0364a9c14d466", "title": "Unsupervised Method for Extracting Machine Understandable Medical Knowledge from a Large Free Text Collection", "abstract": "Definitions of medical concepts (e.g diseases, drugs) are essential background knowledge for researchers, clinicians and health care consumers. However, the rapid growth of biomedical research requires that such knowledge continually needs updating. To address this problem, we have developed an unsupervised pattern learning approach that extracts disease and drug definitions from automatically structured randomized clinical trial (RCT) abstracts. In addition, each extracted definition is semantically classified without relying on external medical knowledge. When used to identify definitions from 100 manually annotated RCT abstracts, our medical definition knowledge base has precision of 0.97, recall of 0.93, F1 of 0.94 and semantic classification accuracy of 0.96."}
{"paperId": "87e3c7e94afda108a049c157d93c72fbe920c35b", "externalIds": {"ACL": "P15-1058", "DBLP": "conf/acl/WeissenbornHXU15", "MAG": "2250718062", "DOI": "10.3115/v1/P15-1058", "CorpusId": 15813261}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/87e3c7e94afda108a049c157d93c72fbe920c35b", "title": "Multi-Objective Optimization for the Joint Disambiguation of Nouns and Named Entities", "abstract": "In this paper, we present a novel approach to joint word sense disambiguation (WSD) and entity linking (EL) that combines a set of complementary objectives in an extensible multi-objective formalism. During disambiguation the system performs continuous optimization to find optimal probability distributions over candidate senses. The performance of our system on nominal WSD as well as EL improves state-ofthe-art results on several corpora. These improvements demonstrate the importance of combining complementary objectives in a joint model for robust disambiguation."}
{"paperId": "e1d38510e9027ee98ba5630361036e406bb0e915", "externalIds": {"MAG": "2580531752", "DOI": "10.1109/ICTER.2016.7829913", "CorpusId": 33085226}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/e1d38510e9027ee98ba5630361036e406bb0e915", "title": "An automated method to extract information in the biomedical literature about interactions between drugs", "abstract": "Text mining techniques are useful in extracting hidden information about the biomedical interactions such as Protein-Protein, Drug-Drug and Protein-Drug. Recently, there is an increased interest in automated methods due to the vast growth in the volume of published text regarding biomedical interactions. This work mainly focuses on extraction of Drug-Drug interactions (DDIs) in biomedical research articles from well-known databases such as DrugBank and MedLine. The proposed approach is developed based on feature engineering through natural language processing (NLP) techniques such as bag-of-words approach, tokenization, part-of-speech (POS) tagging, lemmatization and so on. This uncomplicated and easy to implement set of features are combined into a feature vector which is used to train a machine learning model. The effectiveness of the proposed approach was measured by conducting several experiments on the \u201cDDI Extraction 2013\u201d corpus. The system showed encouraging F-measure value of 76.9%."}
{"paperId": "4275a582cde36c063252b1f0e930b3c0efe9aa90", "externalIds": {"MAG": "3205829967", "DBLP": "journals/ijitwe/YanHK22", "DOI": "10.4018/ijitwe.288039", "CorpusId": 244073216}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/4275a582cde36c063252b1f0e930b3c0efe9aa90", "title": "Extracting Entity Synonymous Relations via Context-Aware Permutation Invariance", "abstract": "Discovering entity synonymous relations is an important work for many entity-based applications. Existing entity synonymous relation extraction approaches are mainly based on lexical patterns or distributional corpus-level statistics, ignoring the context semantics between entities. For example, the contexts around ''apple'' determine whether ''apple'' is a kind of fruit or Apple Inc. In this paper, an entity synonymous relation extraction approach is proposed using context-aware permutation invariance. Specifically, a triplet network is used to obtain the permutation invariance between the entities to learn whether two given entities possess synonymous relation. To track more synonymous features, the relational context semantics and entity representations are integrated into the triplet network, which can improve the performance of extracting entity synonymous relations. The proposed approach is implemented on three real-world datasets. Experimental results demonstrate that the approach performs better than the other compared approaches on entity synonymous relation extraction task."}
{"paperId": "399cbcf0187197c8c371fcca1bd78cd3e529621c", "externalIds": {"PubMedCentral": "10651400", "DOI": "10.4258/hir.2023.29.4.286", "CorpusId": 265105841, "PubMed": "37964451"}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/399cbcf0187197c8c371fcca1bd78cd3e529621c", "title": "Named Entity Recognition in Electronic Health Records: A Methodological Review", "abstract": "Objectives A substantial portion of the data contained in Electronic Health Records (EHR) is unstructured, often appearing as free text. This format restricts its potential utility in clinical decision-making. Named entity recognition (NER) methods address the challenge of extracting pertinent information from unstructured text. The aim of this study was to outline the current NER methods and trace their evolution from 2011 to 2022. Methods We conducted a methodological literature review of NER methods, with a focus on distinguishing the classification models, the types of tagging systems, and the languages employed in various corpora. Results Several methods have been documented for automatically extracting relevant information from EHRs using natural language processing techniques such as NER and relation extraction (RE). These methods can automatically extract concepts, events, attributes, and other data, as well as the relationships between them. Most NER studies conducted thus far have utilized corpora in English or Chinese. Additionally, the bidirectional encoder representation from transformers using the BIO tagging system architecture is the most frequently reported classification scheme. We discovered a limited number of papers on the implementation of NER or RE tasks in EHRs within a specific clinical domain. Conclusions EHRs play a pivotal role in gathering clinical information and could serve as the primary source for automated clinical decision support systems. However, the creation of new corpora from EHRs in specific clinical domains is essential to facilitate the swift development of NER and RE models applied to EHRs for use in clinical practice."}
{"paperId": "eb1cc140b14d0a8f5f789ba26e5e497a9776dd7e", "externalIds": {"CorpusId": 30300780}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/eb1cc140b14d0a8f5f789ba26e5e497a9776dd7e", "title": "Annotating chemicals , diseases and their interactions in biomedical literature", "abstract": "Community-run formal evaluations and manually annotated text corpora are critically important for advancing biomedical text mining research. Recently in BioCreative V, a new challenge was organized for the tasks of disease named entity recognition (DNER) and chemical-induced disease (CID) relation extraction. Given the nature of both tasks, a test collection is required to contain both disease/chemical annotations and relation annotations in the same set of articles. Despite previous efforts in biomedical corpus construction, none were found to be sufficient for the task. Thus, we developed our own corpus during the challenge by inviting a team of expert annotators from both MeSH and the Comparative Toxicogenomics Database (CTD), who performed manual annotation of entities (diseases/chemicals) and relations, respectively. To ensure high annotation quality and productivity, detailed annotation guidelines and automatic annotation tools were provided. The resulting corpus consists of 1,500 PubMed articles with 4,409 annotated chemicals, 5,818 diseases, and 3,116 chemical-disease interactions. Each annotation includes both the mention text spans and normalized concept identifiers (MeSH was used as the controlled vocabulary). To ensure accuracy, the entities were captured independently by two annotators; the average inter-annotator agreement (IAA) scores are 88.75% and 96.31% for the disease and chemicals, respectively, in the test set according to the Jaccard similarity coefficient. Our corpus was successfully used for the BioCreative V challenge tasks and should serve as a valuable resource for the text-mining research community."}
{"paperId": "771276afd7d079ec72d1ecce33ffd6f0fb5aa2ae", "externalIds": {"MAG": "3138979178", "DOI": "10.3390/ASI4010023", "CorpusId": 233660408}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/771276afd7d079ec72d1ecce33ffd6f0fb5aa2ae", "title": "A Comparative Analysis of Active Learning for Biomedical Text Mining", "abstract": "An enormous amount of clinical free-text information, such as pathology reports, progress reports, clinical notes and discharge summaries have been collected at hospitals and medical care clinics. These data provide an opportunity of developing many useful machine learning applications if the data could be transferred into a learn-able structure with appropriate labels for supervised learning. The annotation of this data has to be performed by qualified clinical experts, hence, limiting the use of this data due to the high cost of annotation. An underutilised technique of machine learning that can label new data called active learning (AL) is a promising candidate to address the high cost of the label the data. AL has been successfully applied to labelling speech recognition and text classification, however, there is a lack of literature investigating its use for clinical purposes. We performed a comparative investigation of various AL techniques using ML and deep learning (DL)-based strategies on three unique biomedical datasets. We investigated random sampling (RS), least confidence (LC), informative diversity and density (IDD), margin and maximum representativeness-diversity (MRD) AL query strategies. Our experiments show that AL has the potential to significantly reducing the cost of manual labelling. Furthermore, pre-labelling performed using AL expediates the labelling process by reducing the time required for labelling."}
{"paperId": "db90127b3fdb45466f0930440bf01aaebbfa1f5c", "externalIds": {"ACL": "2020.louhi-1.12", "MAG": "3103341697", "DBLP": "conf/acl-louhi/Wright-BettnerL20", "DOI": "10.18653/v1/2020.louhi-1.12", "CorpusId": 226283778}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/db90127b3fdb45466f0930440bf01aaebbfa1f5c", "title": "Defining and Learning Refined Temporal Relations in the Clinical Narrative", "abstract": "We present refinements over existing temporal relation annotations in the Electronic Medical Record clinical narrative. We refined the THYME corpus annotations to more faithfully represent nuanced temporality and nuanced temporal-coreferential relations. The main contributions are in re-defining CONTAINS and OVERLAP relations into CONTAINS, CONTAINS-SUBEVENT, OVERLAP and NOTED-ON. We demonstrate that these refinements lead to substantial gains in learnability for state-of-the-art transformer models as compared to previously reported results on the original THYME corpus. We thus establish a baseline for the automatic extraction of these refined temporal relations. Although our study is done on clinical narrative, we believe it addresses far-reaching challenges that are corpus- and domain- agnostic."}
{"paperId": "eb13873a4e4348b23ba436188e02aa509b5a6a54", "externalIds": {"DBLP": "conf/ichi/XieZLLG21", "DOI": "10.1109/ICHI52183.2021.00091", "CorpusId": 238994346}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/eb13873a4e4348b23ba436188e02aa509b5a6a54", "title": "Self-supervised extractive text summarization for biomedical literatures", "abstract": "In this study, we propose a self-supervised approach to extractive text summarization for biomedical literature. The approach uses abstracts to find the most informative content in the article, then generate a summary for training a classification model. The Sentences in the abstract and literature were first embedded using BERT. A similarity-based model was then applied to label the informative sentences for training the classifier. We used logistic regression as our classification model and used the features of sentence embedding for the classification. The results showed the feasibility of employing the abstract to perform self-supervised training of a classification model to generate extractive summarization. This approach can enable automatic generation of one or two-page executive summaries of biomedical literature to keep clinicians and biomedical researchers up to date with the latest development"}
{"paperId": "c189ee5794fc966a637154478d985d92da040306", "externalIds": {"DBLP": "journals/corr/abs-2204-08997", "ArXiv": "2204.08997", "PubMedCentral": "9848052", "DOI": "10.1093/bioinformatics/btac817", "CorpusId": 248239674, "PubMed": "36539203"}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/c189ee5794fc966a637154478d985d92da040306", "title": "A benchmark for automatic medical consultation system: frameworks, tasks and datasets", "abstract": "Abstract Motivation In recent years, interest has arisen in using machine learning to improve the efficiency of automatic medical consultation and enhance patient experience. In this article, we propose two frameworks to support automatic medical consultation, namely doctor\u2013patient dialogue understanding and task-oriented interaction. We create a new large medical dialogue dataset with multi-level fine-grained annotations and establish five independent tasks, including named entity recognition, dialogue act classification, symptom label inference, medical report generation and diagnosis-oriented dialogue policy. Results We report a set of benchmark results for each task, which shows the usability of the dataset and sets a baseline for future studies. Availability and implementation Both code and data are available from https://github.com/lemuria-wchen/imcs21. Supplementary information Supplementary data are available at Bioinformatics online."}
{"paperId": "6416b5a45d52cf1b4cdb1b6683e7d9768914db20", "externalIds": {"CorpusId": 2523438}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/6416b5a45d52cf1b4cdb1b6683e7d9768914db20", "title": "Glutathione S-Transferase M 1 , M 3 , P 1 , and T 1 Genetic Polymorphisms and Susceptibility to Breast Cancer 1", "abstract": "This study was undertaken to examine if glutathioneStransferase (GST)M1, M3, P1, andT1 genotypes affected breast cancer risk in Finnish women. The study population consisted of 483 incident breast cancer cases and 482 healthy population controls. Genotyping analyses were performed by PCR-based methods, and odds ratios (ORs) and 95% confidence intervals (CIs) were calculated by unconditional logistic regression adjusting for known or suspected risk factors for breast cancer. When the genes were studied separately, the only significant finding was betweenGSTM1 null genotype and postmenopausal breast cancer risk (OR, 1.49; 95% CI, 1.03\u20132.15). Conversely, when the potential combined effects of the at-risk genotypes were examined, significant associations were observed only among premenopausal women. Although only a moderate risk of breast cancer was seen for premenopausal women concurrently carrying the GSTM3*B allele containing genotypes and theGSTP1Ile/ Ile genotype (OR, 2.07; 95% CI, 1.02\u20134.18), the risk rose steeply if they simultaneously lacked theGSTT1gene (OR, 9.93, 95% CI, 1.10\u201390.0). A borderline significant increase in the risk of breast cancer was also seen for premenopausal women with the combination ofGSTM1 null, GSTP1Ile/Ile, and GSTT1null genotypes (OR, 3.96; 95% CI, 0.99\u201315.8). Our findings support the view that GST genotypes contribute to the individual breast cancer risk, especially in certain combinations. Introduction Breast cancer is both the prevailing malignancy and the most common cause of cancer death among women in Western countries (1, 2). The major risk factors for breast cancer are mainly related to reproductive events that influence lifetime levels of hormones (3, 4). The carcinogenicity of estrogen has been linked not only to its mitotic activity but also to the role of catechol estrogens as carcinogenic metabolites (5). Quinones, the further oxidized metabolites, are the ultimate reactive electrophiles capable of DNA binding if not inactivated by glutathione conjugation (6). There is also substantial evidence on the role of oxidative stress in relation to breast cancer risk (7\u20139). Reactive oxygen species may be generated through a number of mechanisms, including the redox cycling of quinones and semiquinones in the metabolism of estradiol (10). A large proportion of breast cancer cases cannot, however, be explained by the above mentioned risk factors. Identification of susceptibility factors that predispose individuals to breast cancer if they are exposed to particular environmental agents might give further insight into the etiology of this malignancy. It has been suggested that up to 80% of human cancers arise as a consequence of environmental exposure (11). The first line of defense is provided by the ability to metabolize and detoxify exogenous toxins (12). Therefore, inherited capacity for these metabolic activation and/or detoxification reactions may regulate individual susceptibility to environmentally induced diseases like cancer. GSTs are a superfamily of enzymes that are potentially important in regulating susceptibility to cancer because of their ability to metabolize reactive electrophilic intermediates to usually less reactive and more water soluble glutathione conjugates (13). To date, four polymorphic families of cytosolic soluble GSTs ( a, m, p, andu) of potential effect in this context have been identified in humans (13, 14). The absence of GSTM1 and GSTT1 enzyme activities in about 50% and 10\u201325% of Caucasians, respectively, is caused by homozygous deletion (null genotypes) of the corresponding genes (15). In GSTM3gene, theGSTM3*Awild type andGSTM3*B variant allele differ from each other by a deletion of three bp in intron 6 resulting in the generation of a recognition sequence for the YY1 transcription factor in the latter. The functional consequences of this are still unclear, but both negative and positive regulatory effects have been suggested (16, 17). Relatively little is known about the role of GSTM3 in the metabolism of harmful agents, except having overlapping substrate specificity with GSTM1 (13). For GSTP1 gene, two variant alleles, GSTP1*B and GSTP1*C, have been detected in addition to the wild-type Received 9/1/00; revised 1/3/01; accepted 1/10/01. The costs of publication of this article were defrayed in part by the payment of page charges. This article must therefore be hereby marked advertisementin accordance with 18 U.S.C. Section 1734 solely to indicate this fact. 1 Supported by the Academy of Finland, the Finnish Konkordia Foundation, and EVO funds from Kuopio University Hospital. 2 To whom requests for reprints should be addressed, at Molecular Epidemiology Group, Department of Industrial Hygiene and Toxicology, Finnish Institute of Occupational Health, Topeliuksenkatu 41 a A, FIN-00250 Helsinki, Finland. Phone: 358-9-4747-2204; Fax: 358-9-4747-2110; E-mail: Ari.Hirvonen@occuphealth.fi. 3 The abbreviations used are: GST, Glutathione S-transferase; OR, odds ratio; CI, confidence interval; WHR, waist-to-hip ratio; BMI, body-mass index. 229 Vol. 10, 229\u2013236, March 2001 Cancer Epidemiology, Biomarkers & Prevention on November 6, 2017. \u00a9 2001 American Association for Cancer Research. cebp.aacrjournals.org Downloaded from alleleGSTP1*A(18). In both variant alleles, a point mutation at nucleotide 313 results in a single amino acid change from isoleucine (Ile) to valine (Val) at codon 105. This residue lies in close proximity to the hydrophobic binding site for electrophilic substrates (19), and the Val 105 variant allele has been demonstrated to exhibit altered specific activity and affinity for electrophilic substrates (20). The GSTM1genotype has been related to the individual breast cancer risk in several recent studies (21), some of which suggested an association between GSTM1null genotype and breast cancer risk in postmenopausal women (22, 23), whereas others found no association (24\u201329). In contrast toGSTM1, there is little data on the potential role of GSTP1andGSTT1genotypes in breast cancer risk, and no studies have yet been reported on GSTM3and breast cancer. Two recent studies (29, 30) revealed no significant association between theGSTP1genotypes and breast cancer proneness, although one study (23) suggested a trend for increasing risk with higher numbers of GSTP1Val alleles. Similarly, three recent studies found no association between the GSTT1null genotype and the breast cancer risk (23, 26, 29), but one study (31) suggested a remarkably lower risk for premenopausal women lacking theGSTT1gene. There are several potential reasons for the inconsistencies in the outcomes of the above studies; they may arise from an inadequate number of study subjects, unknown menopausal status, or the lack of information or population differences on the other risk factors known to confer breast cancer risk. Moreover, because GSTs are known to have overlapping substrate specificities, deficiencies of GST isoenzymes may be compensated by other isoforms. Simultaneous determination of all of the relevant genotypes for a given exposure may, therefore, be a prerequisite for reliable interpretation of the results. We investigated the potential role of all of the four polymorphic GSTgenes in susceptibility to breast cancer in a Finnish Caucasian study population consisting of 483 incident breast cancer patients and 482 population controls. Materials and Methods Study Population. This study is an extension of Kuopio Breast Cancer Study, a prospective study that follows the protocol of the International Collaborative Study of Breast and Colorectal Cancer coordinated by the European Institute of Oncology in Milan. Women with a suspect breast lump and living in the study catchment area between 1990 and 1995 were invited to Kuopio University Hospital for additional examinations and final diagnosis. They were asked to participate in the study at the first hospital examination and were interviewed by a trained study nurse before any diagnostic procedures. The recruitment protocol missed 51 women later diagnosed with breast cancer, all of who were private patients who did not enter the hospital by the standard procedure. Furthermore, 11 cases were missed during the nurses\u2019 one-month strike in 1995. According to comparison with the Finnish Cancer Registry, only 26 breast cancer cases were treated elsewhere. Five hundred and sixteen of the women who agreed to participate in the study and 12 of the women who had refused to participate in the study were finally diagnosed with breast cancer. Thus, the participation rate of the cases was 98%. Healthy controls were drawn from the Finnish National Population Register covering the catchment area of the cases. They were initially contacted by a letter explaining the study protocol and later called up by a research nurse. In all, 514 controls were interviewed in parallel with the cases. The participation rate for population controls was 72%. Detailed data on socioeconomic background, reproduction history, medical history, family history of breast cancer, current alcohol intake, smoking, and body-size indicators (height, weight, waist, and hip circumferences) were recorded (32). All of the blood samples were collected before diagnosis and stored at220\u00b0C before DNA extraction. For this study, DNA sample was available for 486 cases and 492 controls. Four population controls were excluded from the study because they had earlier breast cancer diagnosis, and two were excluded because of their non-Finnish origin. In addition, three cases and four controls were excluded because genotype data could not be obtained for them. Thus the final study population consisted of 483 histologically confirmed breast cancer cases and 482 population controls; all of them were Finnish Caucasians. Genotyping Analyses.Genomic DNA (100 ng), extracted from lymphocytes by standard techniques, was used as template in the genotyping analyses performed blinded to the c"}
{"paperId": "23dc7a1fb8837f9c3fb04f616d017f7687f4a467", "externalIds": {"DBLP": "conf/wmt/ChoiSRK22", "ACL": "2022.wmt-1.83", "CorpusId": 256460974}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/23dc7a1fb8837f9c3fb04f616d017f7687f4a467", "title": "SRT\u2019s Neural Machine Translation System for WMT22 Biomedical Translation Task", "abstract": "This paper describes the Samsung Research\u2019s Translation system (SRT) submitted to the WMT22 biomedical translation task in two language directions: English to Spanish and Spanish to English. To improve the overall quality, we adopt the deep transformer architecture and employ the back-translation strategy for monolingual corpus. One of the issues in the domain translation is to translate domain-specific terminologies well. To address this issue, we apply the soft-constrained terminology translation based on biomedical terminology dictionaries. In this paper, we provide the performance of our system with WMT20 and WMT21 biomedical testsets. Compared to the best model in WMT20 and WMT21, our system shows equal or better performance. According to the official evaluation results in terms of BLEU scores, our systems get the highest scores in both directions."}
{"paperId": "66bda495f4bba7afc0dafca63fd098558d410feb", "externalIds": {"DBLP": "conf/ranlp/Preiss21", "ACL": "2021.ranlp-1.126", "DOI": "10.26615/978-954-452-072-4_126", "CorpusId": 244071275}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/66bda495f4bba7afc0dafca63fd098558d410feb", "title": "Predicting Informativeness of Semantic Triples", "abstract": "Many automatic semantic relation extraction tools extract subject-predicate-object triples from unstructured text. However, a large quantity of these triples merely represent background knowledge. We explore using full texts of biomedical publications to create a training corpus of informative and important semantic triples based on the notion that the main contributions of an article are summarized in its abstract. This corpus is used to train a deep learning classifier to identify important triples, and we suggest that an importance ranking for semantic triples could also be generated."}
{"paperId": "f79fe4b4d39f1aa74bb5e16e7e014c436da183f1", "externalIds": {"DBLP": "conf/icnidc/SunL21", "DOI": "10.1109/IC-NIDC54101.2021.9660484", "CorpusId": 245708330}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/f79fe4b4d39f1aa74bb5e16e7e014c436da183f1", "title": "Domain Adaptation for Medical Semantic Textual Similarity", "abstract": "Semantic textual similarity is a common task to determine whether two sentences in a pair own the same meaning. In the medical domain, the annotated data is limited and sparse, which brings great difficulty to obtain accurate semantic information from it. In this paper, we propose a two-stream model to adapt knowledge learned from other domains to the medical domain. To optimize and reduce the computation, we further compress the proposed model by knowledge distillation. Experimental results show that our proposed method achieves better performance than the baseline methods."}
{"paperId": "53dec7a5ffd7bdc9e78448e4494413762f30d802", "externalIds": {"CorpusId": 16527801}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/53dec7a5ffd7bdc9e78448e4494413762f30d802", "title": "Building Patterns for Biomedical Event Extraction", "abstract": "Generally, Event Extraction is to identify any instance of a particular class of events in a natural language text, to extract the relevant arguments of the event, and to represent the extracted information into a structured form.1Let us define Event on the binary relation between two entities for special event verbs which are predefined by biologists. Here, Entity means biomedical entities such as proteins, genes, cells, tissues, etc. According to the definition of event, our event extraction system considers only such sentences which contain at least one event verb and two entities. The training consists of two procedures (Figure 1). First, the preprocessor involves chunking, named entity tagging, dependency relation tagging and sentence normalization with special items for building patterns. Special items are entities, event verbs, non-event verbs, prepositions, relatives, conjunctions and symbols. Second, all possible candidate events are extracted from the training corpus and the corresponding patterns are also generated. At this time, we utilize the following assumptions: one event can be described by one or more patterns in the whole documents and one pattern also can be generated by one or more events. Therefore, the event and the pattern information has reciprocal relation. We use the event score (Equation 1) to measure the reliability of extracted events and the pattern score (Equation 2) to measure the reliability of extracted patterns. The scores are iteratively updated in a co-updating method. Updating the event score causes reranking of candidate events and the iteration is continued until the ranking of events is no longer changed. The result of the training is a set of generated patterns and their scores. The events in training corpus are also extracted as the by-product of the training."}
{"paperId": "640bbec28cd16c2c986215a354d2fbabfa058501", "externalIds": {"ArXiv": "2402.10527", "DBLP": "journals/corr/abs-2402-10527", "DOI": "10.48550/arXiv.2402.10527", "CorpusId": 267740295}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/640bbec28cd16c2c986215a354d2fbabfa058501", "title": "Zero-shot sampling of adversarial entities in biomedical question answering", "abstract": "The increasing depth of parametric domain knowledge in large language models (LLMs) is fueling their rapid deployment in real-world applications. In high-stakes and knowledge-intensive tasks, understanding model vulnerabilities is essential for quantifying the trustworthiness of model predictions and regulating their use. The recent discovery of named entities as adversarial examples in natural language processing tasks raises questions about their potential guises in other settings. Here, we propose a powerscaled distance-weighted sampling scheme in embedding space to discover diverse adversarial entities as distractors. We demonstrate its advantage over random sampling in adversarial question answering on biomedical topics. Our approach enables the exploration of different regions on the attack surface, which reveals two regimes of adversarial entities that markedly differ in their characteristics. Moreover, we show that the attacks successfully manipulate token-wise Shapley value explanations, which become deceptive in the adversarial setting. Our investigations illustrate the brittleness of domain knowledge in LLMs and reveal a shortcoming of standard evaluations for high-capacity models."}
{"paperId": "9309e03c5ea14eb1306fc832f3000ee89411b939", "externalIds": {"DBLP": "journals/corr/abs-2401-07009", "ArXiv": "2401.07009", "DOI": "10.48550/arXiv.2401.07009", "CorpusId": 266998914}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/9309e03c5ea14eb1306fc832f3000ee89411b939", "title": "Joint Extraction of Uyghur Medicine Knowledge with Edge Computing", "abstract": "Medical knowledge extraction methods based on edge computing deploy deep learning models on edge devices to achieve localized entity and relation extraction. This approach avoids transferring substantial sensitive data to cloud data centers, effectively safeguarding the privacy of healthcare services. However, existing relation extraction methods mainly employ a sequential pipeline approach, which classifies relations between determined entities after entity recognition. This mode faces challenges such as error propagation between tasks, insufficient consideration of dependencies between the two subtasks, and the neglect of interrelations between different relations within a sentence. To address these challenges, a joint extraction model with parameter sharing in edge computing is proposed, named CoEx-Bert. This model leverages shared parameterization between two models to jointly extract entities and relations. Specifically, CoEx-Bert employs two models, each separately sharing hidden layer parameters, and combines these two loss functions for joint backpropagation to optimize the model parameters. Additionally, it effectively resolves the issue of entity overlapping when extracting knowledge from unstructured Uyghur medical texts by considering contextual relations. Finally, this model is deployed on edge devices for real-time extraction and inference of Uyghur medical knowledge. Experimental results demonstrate that CoEx-Bert outperforms existing state-of-the-art methods, achieving accuracy, recall, and F1 scores of 90.65\\%, 92.45\\%, and 91.54\\%, respectively, in the Uyghur traditional medical literature dataset. These improvements represent a 6.45\\% increase in accuracy, a 9.45\\% increase in recall, and a 7.95\\% increase in F1 score compared to the baseline."}
{"paperId": "dbfc044a9ee9a36ba307fe6ea850ba5233bcc619", "externalIds": {"DOI": "10.1258/ebm.2011.011f05", "CorpusId": 38508329, "PubMed": "21714146"}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/dbfc044a9ee9a36ba307fe6ea850ba5233bcc619", "title": "A small regulatory core that discriminates the gene expression profiles of cancer points to a \u2018Medusa\u2019 structure of the genomic network", "abstract": "Over the past decades, researchers seeking to understand molecular mechanisms underlying various diseases, notably cancer, have taken advantage of DNA microarrays to interrogate tissue specimen of patients for the expression status of thousands of genes at once. Jointly, such gene expression status of each gene in the genome, measured as the level of their transcripts, constitutes the gene expression profile. Since each of the tens of thousands of genes can be switched on or off, a gene expression profile contains complex information, akin to a huge bar code with tens of thousands of digits for every sample. While microarray data were initially used by gene hunters to identify novel genes, such as those which are only active in samples of particular cancer tissues, researchers have later learned to employ sophisticated computational tools to classify these bar codes into subgroups and to find subgroup-specific signatures. In cancer research such statistical analysis of gene expression patterns can serve to identify new cancer subtypes and help classify patients more accurately. However, there is only so much that such brute force computational pattern recognition can offer. Biologists also would like to understand: Where the particular gene expression pattern comes from? How does the cell know how to \u2018write\u2019 the long bar code, defining the expression level of gene after gene, across tens of thousands of genes, in such a reliable manner to encode cell types and cancer cell phenotypes? Although not often asked by computational biologists using statistical analysis to extract information, this is a central and basic biological question. A team of researchers at Harvard Medical School\u2019s Children\u2019s Hospital led by Sui Huang (who is now at the University of Calgary) have analyzed gene expression profiles with precisely this question in mind. In the work published on page 628 of this issue of Experimental Biology and Medicine, Dr Huang and his students, Guo, Feng and Trivedi, offer a first step towards understanding the source of the stable pattern of gene expression profiles by testing whether gene expression profiles are indeed established by a gene regulatory network that has the structure of a \u2018medusa,\u2019 with a command and control \u2018head\u2019 and an enslaved periphery, as proposed by theoreticians. \u2018We tend to take gene expression profiles for granted \u2013 much like the forensic examiner looks at finger prints without ever asking how they are produced in development,\u2019 Dr Huang says. The expression of a gene is regulated by particular types of proteins, the transcription factors (TFs), of which there are 2000 or so in the human genome. Thus, obviously, the entire gene expression profile, the tens of thousands digit bar code, is determined by the collective activity of these TFs. Since they also control the expression of each other, this subset of TF genes forms a \u2018core network\u2019 of mutual regulation. In addition, they must also control the \u2018non-TF\u2019 work horse proteins of the cell, such as cytoskeletal proteins or metabolic enzymes which are also regulated by TFs (as are all genes) but do not regulate the expression of other genes. In this elementary picture, the pattern of the gene expression bar code would be determined essentially by the core network which represents the medusa head and controls the peripheral, regulated but not-regulating genes, the medusa arms (tentacles). If the entire gene expression profile, the bar code that characterizes the phenotype of cell types, is controlled by the core of a just few thousands genes rather than the entire genome of tens of thousands of genes, then as Dr Huang explains \u2018this would have practical consequences beyond theoretical biology, for it would facilitate gene expression pattern based disease characterisation and diagnosis by allowing efficient computation focused on the regulatory core.\u2019 Huang\u2019s team has now used a set of gene expression profiles of lung cancer tissues from a group of patients to show that the expression patterns are consistent with a medusa network. They found using various statistical tests that instead of the entire set of almost 10,000 genes available on the DNA microarrays less than a thousand TF genes were sufficient to classify the patient lung cancer samples according to the diagnosed cancer types. The subset of a few hundred TFs performed as well or better than the set of nearly 10,000 genes that represent much of the genome. The effect persisted after correction for gene number and expression levels. Conversely, metabolic genes that would correspond to the subordinate arms of the medusa, and hence should have minimal influence on the gene expression profile, performed most poorly in the same comparison. Interestingly, Huang and his group also found that microRNAs, a class of regulatory transcripts that do not encode for proteins but contain nucleotide sequence complementary to protein coding transcripts that allow them to specifically target the latter and prevent translation into proteins, were even more powerful than TFs. Since microRNAs are part of the regulatory core, this was not entirely surprising. But why did they perform so much better than TFs? As Huang explains, continuing to draw the analogy of"}
{"paperId": "a24ef0cc13f3641ed15708471244b630a179d044", "externalIds": {"MAG": "2419247925", "DBLP": "conf/acl/ShivadeRP16", "ArXiv": "1606.02638", "ACL": "P16-1118", "DOI": "10.18653/v1/P16-1118", "CorpusId": 16775562}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/a24ef0cc13f3641ed15708471244b630a179d044", "title": "Addressing Limited Data for Textual Entailment Across Domains", "abstract": "We seek to address the lack of labeled data (and high cost of annotation) for textual entailment in some domains. To that end, we first create (for experimental purposes) an entailment dataset for the clinical domain, and a highly competitive supervised entailment system, ENT, that is effective (out of the box) on two domains. We then explore self-training and active learning strategies to address the lack of labeled data. With self-training, we successfully exploit unlabeled data to improve over ENT by 15% F-score on the newswire domain, and 13% F-score on clinical data. On the other hand, our active learning experiments demonstrate that we can match (and even beat) ENT using only 6.6% of the training data in the clinical domain, and only 5.8% of the training data in the newswire domain."}
{"paperId": "93626c85865dd3fffed73b1cf8299ec739aad9dd", "externalIds": {"MAG": "2887442125", "DOI": "10.13020/D6CX04", "CorpusId": 56965311}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/93626c85865dd3fffed73b1cf8299ec739aad9dd", "title": "Semantic Relatedness and Similarity Reference Standards for Medical Terms", "abstract": "1. MayoSRS.csv: A set of 101 medical concept pairs manually rater by medical coders for semantic relatedness. \n \n2. MiniMayoSRS.csv: A subset of 29 medical concept pairs manually rater by medical coders for semantic relatedness with high inter-rater agreement. \n \n3. UMNSRS_similarity.csv: A set of 566 UMLS concept pairs manually rated for semantic similarity using a continuous response scale. \n \n4. UMNSRS_relatedenss.csv: A set of 588 UMLS concept pairs manually rated for semantic relatedness using a continuous response scale. \n \n5. UMNSRS_similarity_mod449_word2vec.csv: Modification of the UMNSRS-Similarity dataset to exclude control samples and those pairs that did not match text in clinical, biomedical and general English corpora. Exact modifications are detailed in the referenced paper. The resulting dataset contains 449 pairs. \n \n6. UMNSRS_relatedness_mod458_word2vec.csv: Modification of the UMNSRS-Similarity dataset to exclude control samples and those pairs that did not match text in clinical, biomedical and general English corpora. Exact modifications are detailed in the referenced paper. The resulting dataset contains 458 pairs."}
{"paperId": "938c961875763eef6ca08639dbd5cc5005931e93", "externalIds": {"MAG": "2154595239", "DOI": "10.1002/path.1711620203", "CorpusId": 44701848, "PubMed": "2250198"}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/938c961875763eef6ca08639dbd5cc5005931e93", "title": "The polymerase chain reaction: Miracle or mirage? A critical review of its uses and limitations in diagnosis and research", "abstract": "Since publication of the polymerase chain reaction (PCR) technique in 1985 (Saiki et al. Science 1985; 230: 1350\u20131354), there has been an explosion of reports on its use in medicine and science. We critically review its use both as a diagnostic technique and as a research tool, and show the pathologist how to evaluate PCR data and how to avoid the pitfalls of overinterpretation. We discuss the value of PCR in the characterization of genetic defects, prenatal diagnosis, carrier testing, H LA typing, detecting micro\u2010organisms, identifying activated oncogenes, and in the characterization of leukaemias and lymphomas, and summarize the main applications in biomedical research."}
{"paperId": "aa0312b080da7e3e821c59d5ebc81058b4a7ba30", "externalIds": {"DBLP": "journals/talip/MimaAM06", "MAG": "2045315960", "DOI": "10.1145/1131348.1131354", "CorpusId": 17433436}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/aa0312b080da7e3e821c59d5ebc81058b4a7ba30", "title": "Terminology-based knowledge mining for new knowledge discovery", "abstract": "In this article we present an integrated knowledge-mining system for the domain of biomedicine, in which automatic term recognition, term clustering, information retrieval, and visualization are combined. The primary objective of this system is to facilitate knowledge acquisition from documents and aid knowledge discovery through terminology-based similarity calculation and visualization of automatically structured knowledge. This system also supports the integration of different types of databases and simultaneous retrieval of different types of knowledge. In order to accelerate knowledge discovery, we also propose a visualization method for generating similarity-based knowledge maps. The method is based on real-time terminology-based knowledge clustering and categorization and allows users to observe real-time generated knowledge maps, graphically. Lastly, we discuss experiments using the GENIA corpus to assess the practicality and applicability of the system."}
{"paperId": "b2958aaf41a251e3aca11ca8e633dc71e15ebe81", "externalIds": {"CorpusId": 145030843}, "semanticScholarUrl": "https://www.semanticscholar.org/paper/b2958aaf41a251e3aca11ca8e633dc71e15ebe81", "title": "The 22 nd Annual Conference of the Japanese Society for Artificial Intelligence , 2008-1-Classifying biomedical text abstracts using binary and multi-class Support Vector Machine", "abstract": "Text classification systems on biomedical literature aim to select relevant articles that match query keywords from large corpora. For this purpose, systems for finding relevant documents must be able to identify terms related to the search in the abstracts and also must distinguish between relevant and irrelevant results. Lately, many researchers attempt to find more applicable ways for classifying biomedical text articles in order to help users find relevant articles on the web. Due to this reason, our focus is on the problem of identifying relevant and irrelevant documents based on binary and multi-class classification in biomedical texts, especially for text biomedical abstracts. For our experiments, we have randomly downloaded and collected 400 paper abstracts of four diseases, including cancer, hepatitis, HIV/AIDS and thyroid from Medline database. Then, we have tested and compared the performance of binary classification and multi-class classification using LIBSVM. The results obtained in our experiments demonstrate that the accuracy of binary classification on the average 80.89% (with scaling) and 86.92% (without scaling), meanwhile multi-class classification on the average 75.73% (with scaling) and 85.25% (without scaling) for our biomedical text data with four categories of diseases. We observe that the choice of percentage for training and testing dataset has little influence on the classification accuracy."}
