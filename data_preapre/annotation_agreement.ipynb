{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae4d1126",
   "metadata": {},
   "source": [
    "## My annotation \n",
    "\n",
    "Starting from annotated the first 50 paper and last 30 paper from the raw data file using the data_prepare.py which is a python script allow you work on annotation. And store the result into annotations/annotated_50.jsonl and annotations/annotated_last30.jsonl\n",
    "\n",
    "Now, merge both of my annotated_50.jsonl and annotated_last30.jsonl file into one file. Ensure first 50 go into first and last 30 next form measuring annotation aggrement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "430b1c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_annotations.py\n",
    "\n",
    "import json\n",
    "\n",
    "ANNOTATED_50_FILE = \"annotations/annotated_50.jsonl\"\n",
    "ANNOTATED_LAST30_FILE = \"annotations/annotated_last30.jsonl\"\n",
    "MERGED_OUTPUT_FILE = \"annotations/merged_annotations.jsonl\"\n",
    "\n",
    "def read_jsonl_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "def write_jsonl_file(file_path, data):\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# Read the annotated files\n",
    "first_50_annotations = read_jsonl_file(ANNOTATED_50_FILE)\n",
    "last_30_annotations = read_jsonl_file(ANNOTATED_LAST30_FILE)\n",
    "\n",
    "# Merge the annotations\n",
    "merged_annotations = first_50_annotations + last_30_annotations\n",
    "\n",
    "# Write the merged annotations to the output file\n",
    "write_jsonl_file(MERGED_OUTPUT_FILE, merged_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf91f62",
   "metadata": {},
   "source": [
    "## Get other annotations\n",
    "\n",
    "Goal: measure annotation agreement between my annotationed and annotated from other (HK / QC)\n",
    "\n",
    "#### Step: \n",
    "1. Extract the first 50 and last 30 annotated result from the provided xlsx file. \n",
    "2. Covert other annotated from sheet format into a papers.jsonl file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac0ceb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paperId': 'd88f70c59b02bba47b3b25b36598917e130b950a', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/d88f70c59b02bba47b3b25b36598917e130b950a', 'title': 'Drug-Drug Interaction Extraction via Convolutional Neural Networks', 'abstract': 'Drug-drug interaction (DDI) extraction as a typical relation extraction task in natural language processing (NLP) has always attracted great attention. Most state-of-the-art DDI extraction systems are based on support vector machines (SVM) with a large number of manually defined features. Recently, convolutional neural networks (CNN), a robust machine learning method which almost does not need manually defined features, has exhibited great potential for many NLP tasks. It is worth employing CNN for DDI extraction, which has never been investigated. We proposed a CNN-based method for DDI extraction. Experiments conducted on the 2013 DDIExtraction challenge corpus demonstrate that CNN is a good choice for DDI extraction. The CNN-based DDI extraction method achieves an F-score of 69.75%, which outperforms the existing best performing method by 2.75%.', 'externalIds': {'MAG': 2264517602.0, 'DBLP': 'journals/cmmm/LiuTCW16', 'PubMedCentral': 4752975.0, 'DOI': '10.1155/2016/6918381', 'CorpusId': 20993322, 'PubMed': 26941831.0}, 'label': 1}\n",
      "{'paperId': 'bc9a0045398fa6c8486b6c208011ab9f65220427', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/bc9a0045398fa6c8486b6c208011ab9f65220427', 'title': 'Building a Multilingual Lexical Resource for Named Entity Disambiguation, Translation and Transliteration', 'abstract': 'In this paper, we present HeiNER, the multilingual Heidelberg Named Entity Resource. HeiNER contains 1,547,586 disambiguated English Named Entities together with translations and transliterations to 15 languages. Our work builds on the approach described in (Bunescu and Pasca, 2006), yet extends it to a multilingual dimension. Translating Named Entities into the various target languages is carried out by exploiting crosslingual information contained in the online encyclopedia Wikipedia. In addition, HeiNER provides linguistic contexts for every NE in all target languages which makes it a valuable resource for multilingual Named Entity Recognition, Disambiguation and Classification. The results of our evaluation against the assessments of human annotators yield a high precision of 0.95 for the NEs we extract from the English Wikipedia. These source language NEs are thus very reliable seeds for our multilingual NE translation method.', 'externalIds': {'MAG': 1571200267.0, 'DBLP': 'conf/lrec/WentlandKSH08', 'CorpusId': 1304185, 'ACL': 'L08-1584'}, 'label': 0}\n",
      "{'paperId': '07788cd9c6693d2cefce6714f21e3988cac1150f', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/07788cd9c6693d2cefce6714f21e3988cac1150f', 'title': 'NEREL: A Russian Dataset with Nested Named Entities, Relations and Events', 'abstract': 'In this paper, we present NEREL, a Russian dataset for named entity recognition and relation extraction. NEREL is significantly larger than existing Russian datasets: to date it contains 56K annotated named entities and 39K annotated relations. Its important difference from previous datasets is annotation of nested named entities, as well as relations within nested entities and at the discourse level. NEREL can facilitate development of novel models that can extract relations between nested named entities, as well as relations on both sentence and document levels. NEREL also contains the annotation of events involving named entities and their roles in the events. The NEREL collection is available via https://github.com/nerel-ds/NEREL.', 'externalIds': {'DBLP': 'conf/ranlp/LoukachevitchAB21', 'DOI': '10.26615/978-954-452-072-4_100', 'CorpusId': 237397713, 'ACL': '2021.ranlp-1.100', 'ArXiv': 2108.13112}, 'label': 0}\n",
      "{'paperId': '652ff4eb452423ff3b2a94ee9130e39a24c28a00', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/652ff4eb452423ff3b2a94ee9130e39a24c28a00', 'title': 'Assessing equitable use of large language models for clinical decision support in real-world settings: fine-tuning and internal-external validation using electronic health records from South Asia', 'abstract': 'Objective Fair and safe Large Language Models (LLMs) hold the potential for clinical task-shifting which, if done reliably, can benefit over-burdened healthcare systems, particularly for resource-limited settings and traditionally overlooked populations. However, this powerful technology remains largely understudied in real-world contexts, particularly in the global South. This study aims to assess if openly available LLMs can be used equitably and reliably for processing medical notes in real-world settings in South Asia. Methods We used publicly available medical LLMs to parse clinical notes from a large electronic health records (EHR) database in Pakistan. ChatGPT, GatorTron, BioMegatron, BioBert and ClinicalBERT were tested for bias when applied to these data, after fine-tuning them to a) publicly available clinical datasets I2B2 and N2C2 for medical concept extraction (MCE) and emrQA for medical question answering (MQA), and b) the local EHR dataset. For MCE models were applied to clinical notes with 3-label and 9-label formats and for MQA were applied to medical questions. Internal and external validation performance was measured for a) and b) using F1, precision, recall, and accuracy for MCE and BLEU and ROUGE-L for MQA. Results LLMs not fine-tuned to the local EHR dataset performed poorly, suggesting bias, when externally validated on it. Fine-tuning the LLMs to the local EHR data improved model performance. Specifically, the 3- label precision, recall, F1 score, and accuracy for the dataset improved by 21-31%, 11-21%, 16-27%, and 6-10% amongst GatorTron, BioMegatron, BioBert and ClinicalBERT. As an exception, ChatGPT performed better on the local EHR dataset by 10% for precision and 13% for each of recall, F1 score, and accuracy. 9-label performance trends were similar. Conclusions Publicly available LLMs, predominantly trained in global north settings, were found to be biased when used in a real-world clinical setting. Fine-tuning them to local data and clinical contexts can help improve their reliable and equitable use in resource-limited settings. Close collaboration between clinical and technical experts can ensure responsible and unbiased powerful tech accessible to resource-limited, overburdened settings used in ways that are safe, fair, and beneficial for all.', 'externalIds': {'DOI': '10.1101/2024.06.05.24308365', 'CorpusId': 270255271}, 'label': 1}\n",
      "{'paperId': '544f8c8e1dade4525ab2992e099715acb9e8ca01', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/544f8c8e1dade4525ab2992e099715acb9e8ca01', 'title': 'Classification from Full Text: A Comparison of Canonical Sections of Scientific Papers', 'abstract': 'The accelerating growth in biomedical literature has stimulated activity on automated classification of and information extraction from this literature. The work described here attempts to improve on an earlier classification study associating biological articles to GO codes. It demonstrates the need, under particular assumptions, for more access to full text articles and for the use of Part-of-Speech tagging.', 'externalIds': {'MAG': 2044391799.0, 'DBLP': 'conf/bionlp/SinclairW04', 'DOI': '10.3115/1567594.1567608', 'CorpusId': 16811149, 'ACL': 'W04-1212'}, 'label': 1}\n",
      "{'paperId': '43d172a6d288e85c59a44655368f9af85490c800', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/43d172a6d288e85c59a44655368f9af85490c800', 'title': 'PPPred: Classifying Protein-phenotype Co-mentions Extracted from Biomedical Literature', 'abstract': 'The MEDLINE database provides an extensive source of scientific articles and heterogeneous biomedical information in the form of unstructured text. One of the most important knowledge present within articles are the relations between human proteins and their phenotypes, which can stay hidden due to the exponential growth of publications. This has presented a range of opportunities for the development of computational methods to extract these biomedical relations from the articles. However, currently, no such method exists for the automated extraction of relations involving human proteins and human phenotype ontology (HPO) terms. In our previous work, we developed a comprehensive database composed of all co-mentions of proteins and phenotypes. In this study, we present a supervised machine learning approach called PPPred (Protein-Phenotype Predictor) for classifying the validity of a given sentence-level co-mention. Using an in-house developed gold standard dataset, we demonstrate that PPPred significantly outperforms several baseline methods. This two-step approach of co-mention extraction and classification constitutes a complete biomedical relation extraction pipeline for extracting protein-phenotype relations. CCS CONCEPTS \\x95Computing methodologies ? Information extraction; Supervised learning by classification; \\x95Applied computing ?Bioinformatics;', 'externalIds': {'MAG': 2947205688.0, 'DBLP': 'conf/bcb/ShahriRRK19', 'DOI': '10.1101/654475', 'CorpusId': 190872871}, 'label': 1}\n",
      "{'paperId': '7dce3c780c85c41ff9dfe7511962ecddb2291ab8', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/7dce3c780c85c41ff9dfe7511962ecddb2291ab8', 'title': 'Structured Learning for Temporal Relation Extraction from Clinical Records', 'abstract': 'We propose a scalable structured learning model that jointly predicts temporal relations between events and temporal expressions (TLINKS), and the relation between these events and the document creation time (DCTR). We employ a structured perceptron, together with integer linear programming constraints for document-level inference during training and prediction to exploit relational properties of temporality, together with global learning of the relations at the document level. Moreover, this study gives insights in the results of integrating constraints for temporal relation extraction when using structured learning and prediction. Our best system outperforms the state-of-the art on both the CONTAINS TLINK task, and the DCTR task.', 'externalIds': {'MAG': 2608829447.0, 'DBLP': 'conf/eacl/MoensL17', 'DOI': '10.18653/V1/E17-1108', 'CorpusId': 17894632, 'ACL': 'E17-1108'}, 'label': 0}\n",
      "{'paperId': '9c025e17c3fd857b3ed3370456d0a43389e6570f', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/9c025e17c3fd857b3ed3370456d0a43389e6570f', 'title': 'Context-Sensitive Medical Information Retrieval', 'abstract': 'Substantial medical data such as pathology reports, operative reports, discharge summaries, and radiology reports are stored in textual form. Databases containing free-text medical narratives often need to be searched to find relevant information for clinical and research purposes. Terms that appear in these documents tend to appear in different contexts. The con-text of negation, a negative finding, is of special importance, since many of the most frequently described findings are those denied by the patient or subsequently \"ruled out.\" Hence, when searching free-text narratives for patients with a certain medical condition, if negation is not taken into account, many of the retrieved documents will be irrelevant. The purpose of this work is to develop a methodology for automated learning of negative context patterns in medical narratives and test the effect of context identification on the performance of medical information retrieval. The algorithm presented significantly improves the performance of information retrieval done on medical narratives. The precision im-proves from about 60%, when using context-insensitive retrieval, to nearly 100%. The impact on recall is only minor. In addition, context-sensitive queries enable the user to search for terms in ways not otherwise available', 'externalIds': {'MAG': 2343724232.0, 'DBLP': 'conf/medinfo/AverbuchKBMR04', 'DOI': '10.3233/978-1-60750-949-3-282', 'CorpusId': 17676347, 'PubMed': 15360819.0}, 'label': 1}\n",
      "{'paperId': '5b6be8682e11bb0187bc79b0781c134bc27802dc', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/5b6be8682e11bb0187bc79b0781c134bc27802dc', 'title': 'Relation extraction methods for biomedical literature', 'abstract': 'Protein-protein interactions (PPIs) play an important role in understanding biological processes. Although recent research in text mining has achieved a significant progress in automatic PPI extraction from literature, performance of existing systems still needs to be improved. In this chapter, we present a novel algorithm for extracting PPIs from literature which consists of two phases. First, we automatically categorize the data into subsets based on its syntactic properties and extract candidate PPI pairs from these subsets. Second, we apply support vector machines (SVM) to classify candidate PPI pairs using features specific for each subset. We obtain promising results on five benchmark datasets: AIMed, BioInfer, HPRD50, IEPA, and LLL with F-scores ranging from 60% to 84%, which are comparable to the state-of-the-art PPI extraction systems. Furthermore, our system achieves the best performance on cross-corpora evaluation and comparative performance in terms of speed.', 'externalIds': {'CorpusId': 268298305}, 'label': 1}\n",
      "{'paperId': '169523e2a6be4b21e544212383c4f1ce2593f05e', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/169523e2a6be4b21e544212383c4f1ce2593f05e', 'title': 'UDel: Named Entity Recognition and Reference Regeneration from Surface Text', 'abstract': 'This report describes the methods and results of a system developed for the GREC Named Entity Recognition and GREC Named Entity Regeneration Challenges 2010. We explain our process of automatically annotating surface text, as well as how we use this output to select improved referring expressions for named entities.', 'externalIds': {'MAG': 1885537185.0, 'DBLP': 'conf/inlg/SparksGMK10', 'CorpusId': 13340006, 'ACL': 'W10-4232'}, 'label': 0}\n",
      "{'paperId': '1dd018dc97be9d1a8305e23fb97a1473b638ff74', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/1dd018dc97be9d1a8305e23fb97a1473b638ff74', 'title': 'ELAD: An Entity Linking Based Affiliation Disambiguation Framework', 'abstract': 'The number of papers has exploded as more and more people and more types of institutions participating in scientific research. At the same time, institution name disambiguation (IND) is getting more sophisticated, which is critical for research assessment, scholar alignment, etc. Previous knowledge-based and rule-based methods require knowledge and rules prepared in advance, which cannot cope with growing and changing data and learning rules, especially for data with a long period and abundant sources. This paper proposes an automatic learning framework to solve the problem, which is based on entity linking, entity type recognition, candidate generation, and result selection. Experiments show that precision and recall is much higher than the traditional method, ELAD learns more knowledge from the knowledge graph, and it can deal with ever-changing and ever-increasing data. What\\x92s more, it solves many problems that cannot be solved by traditional methods: the connection between institution entities, mistakes correction, and the reduction of manual and pre-prepared knowledge. At last, for the case study, we develop two applications based on ELAD which proves its reliability.', 'externalIds': {'MAG': 3015323854.0, 'DBLP': 'journals/access/ShaoCYW20', 'DOI': '10.1109/ACCESS.2020.2986826', 'CorpusId': 216244186}, 'label': 0}\n",
      "{'paperId': '026f123a3e8820e93a52311ca3221c7de5a61b74', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/026f123a3e8820e93a52311ca3221c7de5a61b74', 'title': 'A Method of Named Entity Disambiguation Based on Chinese Wikipedia', 'abstract': 'In this paper,a statistical model is proposed for Chinese named entity disambiguation by making use of rich links information and various types of page information in Chinese Wikipedia.The text and Wikipedia features are combined effectively in this model by different means.At the same time,the word sense options contained in Wikipedia disambiguation pages of the related named entity are considered as candidate named entities.In the experiment,the accuracy 87.5% can be obtained on a small test set.The experimental results show that the proposed method is feasible and effective.', 'externalIds': {'MAG': 2385510523.0, 'CorpusId': 63624881}, 'label': 0}\n",
      "{'paperId': '358ca777d9992bdc06fdcc1940e3b18a8da68878', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/358ca777d9992bdc06fdcc1940e3b18a8da68878', 'title': 'Inter-sentence Relation Extraction with Document-level Graph Convolutional Neural Network', 'abstract': 'Inter-sentence relation extraction deals with a number of complex semantic relationships in documents, which require local, non-local, syntactic and semantic dependencies. Existing methods do not fully exploit such dependencies. We present a novel inter-sentence relation extraction model that builds a labelled edge graph convolutional neural network model on a document-level graph. The graph is constructed using various inter- and intra-sentence dependencies to capture local and non-local dependency information. In order to predict the relation of an entity pair, we utilise multi-instance learning with bi-affine pairwise scoring. Experimental results show that our model achieves comparable performance to the state-of-the-art neural models on two biochemistry datasets. Our analysis shows that all the types in the graph are effective for inter-sentence relation extraction.', 'externalIds': {'MAG': 2963014179.0, 'DBLP': 'conf/acl/SahuCMA19', 'DOI': '10.18653/v1/P19-1423', 'CorpusId': 184487889, 'ACL': 'P19-1423', 'ArXiv': 1906.04684}, 'label': 0}\n",
      "{'paperId': 'b0b31c242318ba1211a19c867a596679b60bf563', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/b0b31c242318ba1211a19c867a596679b60bf563', 'title': 'MeSH Up: effective MeSH text classification for improved document retrieval', 'abstract': \"Motivation: Controlled vocabularies such as the Medical Subject Headings (MeSH) thesaurus and the Gene Ontology (GO) provide an efficient way of accessing and organizing biomedical information by reducing the ambiguity inherent to free-text data. Different methods of automating the assignment of MeSH concepts have been proposed to replace manual annotation, but they are either limited to a small subset of MeSH or have only been compared with a limited number of other systems. Results: We compare the performance of six MeSH classification systems [MetaMap, EAGL, a language and a vector space model-based approach, a K-Nearest Neighbor (KNN) approach and MTI] in terms of reproducing and complementing manual MeSH annotations. A KNN system clearly outperforms the other published approaches and scales well with large amounts of text using the full MeSH thesaurus. Our measurements demonstrate to what extent manual MeSH annotations can be reproduced and how they can be complemented by automatic annotations. We also show that a statistically significant improvement can be obtained in information retrieval (IR) when the text of a user's query is automatically annotated with MeSH concepts, compared to using the original textual query alone. Conclusions: The annotation of biomedical texts using controlled vocabularies such as MeSH can be automated to improve text-only IR. Furthermore, the automatic MeSH annotation system we propose is highly scalable and it generates improvements in IR comparable with those observed for manual annotations. Contact: trieschn@ewi.utwente.nl Supplementary information: Supplementary data are available at Bioinformatics online.\", 'externalIds': {'DBLP': 'journals/bioinformatics/TrieschniggPLJKR09', 'PubMedCentral': 2682526.0, 'DOI': '10.1093/bioinformatics/btp249', 'CorpusId': 9716979, 'PubMed': 19376821.0}, 'label': 1}\n",
      "{'paperId': '0e95a845d6fa9dfed63ce52f793bc376d6feb5a6', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/0e95a845d6fa9dfed63ce52f793bc376d6feb5a6', 'title': 'Improved Bayesian Based Method for Classifying Disease Documents', 'abstract': 'Naïve Bayes has been proved to be decently competitive learning and classification approach in many fields and still been actively researched. We propose a Bayesian based classification method for biomedical disease-related documents. The proposed method relies on the difference in class distribution between the presence vs absence of the attributes. Specifically, in a simple inductive learning setting, the difference in class probability between the presence vs absence of feature fj can be a good metric for the contribution of fj in predicting the class. The proposed method works well with biomedical text abstracts as attribute values (feature count) of word features are not high. We found that heavy medical terms tends to occur with fairly low frequencies in these abstracts but have significant contribution in determining the class and the subject of the document. Therefore, this technique is suitable for biomedical text mining because it gives rise to terms with low per-document frequency and such terms play a good role in predicting the class in biomedical texts. The evaluation is conducted with seven datasets and compared to the Bayesian method as our baseline using accuracy and AUC with encouraging results, and the proposed method outperformed the baseline significantly. Moreover, we investigated the effect of low average frequency terms and their contribution in classification accuracy.', 'externalIds': {'MAG': 2567101426.0, 'DOI': '10.1109/WSCAR.2016.26', 'CorpusId': 15188517}, 'label': 1}\n",
      "{'paperId': '11c960208ecd2a391081c923c231ef193336016d', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/11c960208ecd2a391081c923c231ef193336016d', 'title': 'Bring Biomedical Ontologies to Personalized Healthcare: A Smart Inquiry Framework', 'abstract': \"High-quality inquiry (i.e. history taking) is the foundation of accurate diagnosis. Traditionally, inquiry occurs between doctors and patients, requiring lots of time and patience, but often receiving a lot of complaints. This paper proposes a smart inquiry framework, aiming for interacting with patient readily by mining personalized questions from biomedical big data. In other words, the patient can tell his feelings at any time and place, then the system will ask you simple questions, just like an experienced and very kind doctor. What you should do is answering Yes or No. Finally, you will get a preliminary suggestion. There are two key technologies in this paper: 1) training a probability graph from the medical big data, as the whole framework's knowledge base, 2) based on the recommendation algorithm, designing an automatic question answering system, to guide the patients speaking out other more symptoms from the initial feeling. The new proposed framework can serve everyone with low cost and high efficiency, helping them to dynamically sort out and record the state of the body. This will play a fundamental role in the field of personalized healthcare.\", 'externalIds': {'MAG': 2508939750.0, 'DBLP': 'conf/chase/ZhangBS16', 'DOI': '10.1109/CHASE.2016.32', 'CorpusId': 5040854}, 'label': 1}\n",
      "{'paperId': 'b8df5bcabd43a1b9e8a159bc8249e33408112faa', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/b8df5bcabd43a1b9e8a159bc8249e33408112faa', 'title': 'Improving Few-Shot Domain Transfer for Named Entity Disambiguation with Pattern Exploitation', 'abstract': ',', 'externalIds': {'DBLP': 'conf/emnlp/BlairB22', 'DOI': '10.18653/v1/2022.findings-emnlp.506', 'CorpusId': 256631069}, 'label': 2}\n",
      "{'paperId': 'fa56e8dadd16a897cd89d701b8a9a7285ee0f3d4', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/fa56e8dadd16a897cd89d701b8a9a7285ee0f3d4', 'title': 'UB Health Miners@SMM4H\\x9222: Exploring Pre-processing Techniques To Classify Tweets Using Transformer Based Pipelines.', 'abstract': 'Here we discuss our implementation of two tasks in the Social Media Mining for Health Applications (SMM4H) 2022 shared tasks \\x96 classification, detection, and normalization of Adverse Events (AE) mentioned in English tweets (Task 1) and classification of English tweets self-reporting exact age (Task 4). We have explored different methods and models for binary classification, multi-class classification and named entity recognition (NER) for these tasks. We have also processed the provided dataset for noise, imbalance, and creative language expression from data. Using diverse NLP methods we classified tweets for mentions of adverse drug effects (ADEs) and self-reporting the exact age in the tweets. Further, extracted reactions from the tweets and normalized these adverse effects to a standard concept ID in the MedDRA vocabulary.', 'externalIds': {'DBLP': 'conf/coling/KhatriSDS22', 'CorpusId': 252819301, 'ACL': '2022.smm4h-1.32'}, 'label': 1}\n",
      "{'paperId': '2d5d2038d87fd9270622284a828e6b3b5cd41417', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/2d5d2038d87fd9270622284a828e6b3b5cd41417', 'title': 'EARA: Improving Biomedical Semantic Textual Similarity with Entity-Aligned Attention and Retrieval Augmentation', 'abstract': ',', 'externalIds': {'DBLP': 'conf/emnlp/XiongYLWC0T23', 'DOI': '10.18653/v1/2023.findings-emnlp.586', 'CorpusId': 266176243}, 'label': 2}\n",
      "{'paperId': '11eab492b442db28b859ec4c8cfe8241f51e479e', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/11eab492b442db28b859ec4c8cfe8241f51e479e', 'title': 'A Meta-Path-Based Prediction Method for Disease Comorbidities', 'abstract': \"The simultaneous presence of diseases worsens the prognosis of patients and makes their treatment difficult. Identifying the co-occurrence of diseases is key to improving the situation of patients and designing effective therapeutic strategies. On the one hand, the increasing availability of clinical information opens new ways to unveil hidden relationships between diseases. On the other hand, heterogeneous information networks have been used in recent years to discover novel knowledge from disease data, including symptoms, genes or drugs. The use of meta-paths allows the complex semantics of the relationships between the different types of nodes to be included in heterogeneous networks. In this study, we propose a system to predict disease comorbidities through the use of meta-paths in a heterogeneous network of diseases and symptoms, built from textual sources of public access. The results obtained improve those of similar studies based on biological data, and the predictions calculated for diabetes and Crohn's disease are supported by medical literature. Both the used data and the obtained prediction model are publicly accessible.\", 'externalIds': {'DBLP': 'conf/cbms/ValleSGZRG21', 'DOI': '10.1109/CBMS52027.2021.00022', 'CorpusId': 236096666}, 'label': 1}\n",
      "{'paperId': 'e62324cceeca146d0f295bd0cb8910ef46f46e87', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/e62324cceeca146d0f295bd0cb8910ef46f46e87', 'title': 'PTENLoss Does Not Predict for Response to RAD 001 ( Everolimus ) in a Glioblastoma Orthotopic XenograftTest Panel', 'abstract': 'Purpose:Hyperactivation of the phosphatidylinositol 3-kinase/Akt signaling through disruption of PTEN function is common inglioblastomamultiforme, and these genetic changes are predicted to enhance sensitivity to mammalian target of rapamycin (mTOR) inhibitors such as RAD001 (everolimus). Experimental Design: To test whether PTEN loss could be used as a predictive marker for mTOR inhibitor sensitivity, the response of 17 serially transplantable glioblastoma multiforme xenografts was evaluated in an orthotopic therapy evaluationmodel. Of these17 xenograft lines, 7 have either genomic deletion or mutation of PTEN. Results: Consistent with activation of Akt signaling, there was a good correlation between loss of PTEN function and elevated levels of Akt phosphorylation. However, of the 7 lines with disrupted PTEN function, only 1 tumor line (GBM10) was significantly sensitive to RAD001therapy (25% prolongation inmedian survival), whereas1of10 xenograft lines with wild-type PTENwas significantly sensitive to RAD001 (GS22; 34% prolongation in survival). Relative to placebo, 5 days of RAD001treatment was associated with a marked 66% reduction in theMIB1 proliferation index in the sensitive GBM10 line (deleted PTEN) comparedwith a 25% and 7% reduction in MIB1labeling index in the insensitive GBM14 (mutant PTEN) and GBM15 (wild-type PTEN) lines, respectively. Consistent with a cytostatic antitumor effect, bioluminescent imaging of luciferasetransduced intracranial GBM10 xenografts showed slowed tumor growth without significant tumor regression during RAD001therapy. Conclusion:These data suggest that loss of PTEN function is insufficient to adequately predict responsiveness to mTOR inhibitors in glioblastoma multiforme. The mammalian target of rapamycin (mTOR) is an important modulator of mitogenic signaling in both normal and tumor cells, and small-molecule inhibitors of mTOR have shown promising activity in several tumor types (1\\x963). mTOR functions to integrate mitogenic signals with the nutrient status of the cell to promote cell growth and proliferation only under adequate nutrient conditions. mTOR signals to multiple components of the protein translation machinery to promote the translation of a subset of mRNA transcripts with complex 5¶-untranslated regions (reviewed in ref. 4). Many of these gene products are important for driving tumor cell growth, proliferation, and angiogenesis, and the antitumor effects of mTOR inhibitors are predominantly linked to disruption of these processes. Mitogenic activation of mTOR signaling is controlled in part through the phosphatidylinositol 3-kinase (PI3K)/Akt signaling pathway. Akt-mediated phosphorylation of both mTOR itself and the mTOR inhibitory molecule TSC2 can promote activation of mTOR signaling (5\\x968). The PI3K/Akt signaling pathway is commonly hyperactivated in glioblastoma multiforme through functional loss of the PTEN tumor suppressor protein. In keeping with the hypothesis that constitutive hyperactivity within a signaling pathway results in hypersensitivity to pathway inhibition, several studies in isogenic tumor models have shown that loss of PTEN function results in increased sensitivity to mTOR inhibitors (9 \\x96 11). These observations have prompted several groups to propose clinical trials in which only those patients with tumors lacking PTEN Cancer Therapy: Preclinical Authors\\x92 Affiliations: Departments of Radiation Oncology, Neurosurgery, Neurology, Oncology, and Laboratory Medicine and Pathology and Division of Biostatistics, Mayo Clinic, Rochester, Minnesota; Novartis Institute for BioMedical Research, Basel, Switzerland; and Department of Neurological Surgery and Brain Tumor Research Center, University of California-San Francisco, San Francisco, California Received 9/10/07; revised1/10/08; accepted1/30/08. Grant support: NIH grants NS49720 and CA097257 (C.D. James) and CA108961, CA25224, and CA114740 (J.N. Sarkaria, E. Galanis, and C. Giannini); American Cancer Society Research Scholar Grant (J.N. Sarkaria); and Accelerate Brain Cancer Cure (J.N. Sarkaria and C.D. James). The costs of publication of this article were defrayed in part by the payment of page charges.This article must therefore be hereby marked advertisement in accordance with18 U.S.C. Section1734 solely to indicate this fact. Note: Supplementary data for this article are available at Clinical Cancer Research Online (http://clincancerres.aacrjournals.org/). Requests for reprints: Jann N. Sarkaria, 200 First Street, SW, Rochester, MN 55905. Phone: 507-266-3877; Fax: 502-284-3906; E-mail: sarkaria.jann@ mayo.edu. F2008 American Association for Cancer Research. doi:10.1158/1078-0432.CCR-07-4152 www.aacrjournals.org Clin Cancer Res 2008;14(12) June15, 2008 3993 Research. on June 9, 2017. © 2008 American Association for Cancer clincancerres.aacrjournals.org Downloaded from function would be treated with a mTOR inhibitor-based regimen. However, other factors, such as energy deprivation and amino acid starvation, are also important mediators of mTOR activity (12\\x9620), and given these data, it is not clear whether PTEN status is a major factor that influences in vivo responses to mTOR inhibitors in patient tumors. We have reported previously the development of a panel of glioblastoma multiforme xenografts established from patient samples and passaged serially in the flank of nude mice, and we have used this panel for assessing the influence of epidermal growth factor receptor (EGFR) amplification status and PTEN status on responsiveness to the EGFR inhibitor erlotinib (21). To understand more fully whether PTEN status would be a useful predictor of response to therapy with the mTOR inhibitor RAD001 (everolimus), we correlated the molecular status of PTEN within our xenograft lines with the extent of survival prolongation for orthotopic tumors established from these lines following therapy with RAD001. The results of this study suggest that loss of PTEN function is insufficient to predict RAD001 sensitivity. Materials andMethods Cell culture assays. Established gliomas cell lines differing in PTEN status (PTEN-/-: LN401, BS125II.2, BS153, and U87; PTEN+/+: LN229, LN427, LN751, and LN428) were plated into 96-well plates, incubated overnight, and then treated with graded concentrations of RAD001. After 4 days of incubation at 37jC, cells were fixed onto the plates with 6% glutaraldehyde. After washing in water, cells were stained with methylene blue, washed, and incubated with 3% hydrochloric acid and absorbance was measured at 650 nm. The IC50 values (RAD001 concentration that reduces methylene blue staining by 50%) for each line were calculated using Softmax 1.2.0 software. U87 and U251 cells also plated and treated with RAD001 as described above and then pulsed with [H]thymidine for 2 h. Cells were harvested by trypsinization, transferred onto glass filters, and lysed in distilled water. Filter-bound radioactivity was determined by liquid scintillation', 'externalIds': {'CorpusId': 29256242}, 'label': 0}\n",
      "{'paperId': 'a178afaae690ecb70622457f4569bd517e12c5cc', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/a178afaae690ecb70622457f4569bd517e12c5cc', 'title': \"Classifying Biomedical Text Abstracts based on Hierarchical 'Concept' Structure\", 'abstract': 'Classifying biomedical literature is a difficult and challenging task, especially when a large number of biomedical articles should be organized into a hierarchical structure. In this paper, we present an approach for classifying a collection of biomedical text abstracts downloaded from Medline database with the help of ontology alignment. To accomplish our goal, we construct two types of hierarchies, the OHSUMED disease hierarchy and the Medline abstract disease hierarchies from the OHSUMED dataset and the Medline abstracts, respectively. Then, we enrich the OHSUMED disease hierarchy before adapting it to ontology alignment process for finding probable concepts or categories. Subsequently, we compute the cosine similarity between the vector in probable concepts (in the \"enriched\" OHSUMED disease hierarchy) and the vector in Medline abstract disease hierarchies. Finally, we assign category to the new Medline abstracts based on the similarity score. The results obtained from the experiments show the performance of our proposed approach for hierarchical classification is slightly better than the performance of the multi-class flat classification.', 'externalIds': {'MAG': 1653392063.0, 'CorpusId': 45513692}, 'label': 1}\n",
      "{'paperId': '524ff6265b7b0a5b4d78c43a8a0790c6079123e3', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/524ff6265b7b0a5b4d78c43a8a0790c6079123e3', 'title': 'Automating Biomedical Abstract Screening using Network Embedding', 'abstract': ': Systematic review (SR) is an essential process to identify, evaluate, and summarize the ?ndings of all relevant individual studies concerning health-related questions. However, conducting a SR is labor-intensive, as identifying relevant studies is a daunting process that entails multiple researchers screening thousands of articles for relevance. Automating evidence synthesis using machine learning models has been proposed but primarily focuses on the text and ignores additional features like citation information. Recent work demonstrated that citation embeddings can out-perform the text itself, suggesting that better network representation may expedite SRs. Yet, how to utilize the rich information in heterogeneous information networks for network embeddings is understudied. Also, the lack of a uni?ed source that includes the metadata of biomedical literature makes the research more challenging. To deal with this problem, we propose four works. First, we propose a model that exploits three representations, documents, topics, and citation networks to show the e?ectiveness of the additional features. Second, we introduce the PubMed Graph Benchmark, one of the largest heterogeneous networks to date, which aggregates the rich meta-data into a uni?ed source that includes abstracts, authors, citations, MeSH terms, etc. Third, we propose a heterogeneous network embedding model that uses a community-based multi-view graph convolutional network for learning better embeddings for evidence synthesis. Lastly, we propose a hierarchical network embedding model that uses the Poincare embedding model on the MeSH tree and the citation network.', 'externalIds': {'CorpusId': 262091998}, 'label': 1}\n",
      "{'paperId': '7f8b9397184a5daa0178c569206546610d1d3a7a', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/7f8b9397184a5daa0178c569206546610d1d3a7a', 'title': 'Data-Driven Information Extraction from Chinese Electronic Medical Records', 'abstract': 'Objective This study aims to propose a data-driven framework that takes unstructured free text narratives in Chinese Electronic Medical Records (EMRs) as input and converts them into structured time-event-description triples, where the description is either an elaboration or an outcome of the medical event. Materials and Methods Our framework uses a hybrid approach. It consists of constructing cross-domain core medical lexica, an unsupervised, iterative algorithm to accrue more accurate terms into the lexica, rules to address Chinese writing conventions and temporal descriptors, and a Support Vector Machine (SVM) algorithm that innovatively utilizes Normalized Google Distance (NGD) to estimate the correlation between medical events and their descriptions. Results The effectiveness of the framework was demonstrated with a dataset of 24,817 de-identified Chinese EMRs. The cross-domain medical lexica were capable of recognizing terms with an F1-score of 0.896. 98.5% of recorded medical events were linked to temporal descriptors. The NGD SVM description-event matching achieved an F1-score of 0.874. The end-to-end time-event-description extraction of our framework achieved an F1-score of 0.846. Discussion In terms of named entity recognition, the proposed framework outperforms state-of-the-art supervised learning algorithms (F1-score: 0.896 vs. 0.886). In event-description association, the NGD SVM is superior to SVM using only local context and semantic features (F1-score: 0.874 vs. 0.838). Conclusions The framework is data-driven, weakly supervised, and robust against the variations and noises that tend to occur in a large corpus. It addresses Chinese medical writing conventions and variations in writing styles through patterns used for discovering new terms and rules for updating the lexica.', 'externalIds': {'MAG': 1890275775.0, 'PubMedCentral': 4546596.0, 'DOI': '10.1371/journal.pone.0136270', 'CorpusId': 2520161, 'PubMed': 26295801.0}, 'label': 1}\n",
      "{'paperId': '5dfcc1f19a22c3bc081f2ff4410eb1efc7061838', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/5dfcc1f19a22c3bc081f2ff4410eb1efc7061838', 'title': 'Nested Named Entity Recognition with Partially-Observed TreeCRFs', 'abstract': 'Named entity recognition (NER) is a well-studied task in natural language processing. However, the widely-used sequence labeling framework is difficult to detect entities with nested structures. In this work, we view nested NER as constituency parsing with partially-observed trees and model it with partially-observed TreeCRFs. Specifically, we view all labeled entity spans as observed nodes in a constituency tree, and other spans as latent nodes. With the TreeCRF we achieve a uniform way to jointly model the observed and the latent nodes. To compute the probability of partial trees with partial marginalization, we propose a variant of the Inside algorithm, the Masked Inside algorithm, that supports different inference operations for different nodes (evaluation for the observed, marginalization for the latent, and rejection for nodes incompatible with the observed) with efficient parallelized implementation, thus significantly speeding up training and inference. Experiments show that our approach achieves the state-of-the-art (SOTA) F1 scores on the ACE2004, ACE2005 dataset, and shows comparable performance to SOTA models on the GENIA dataset. We release the code at https://github.com/FranxYao/Partially-Observed-TreeCRFs.', 'externalIds': {'MAG': 3111946788.0, 'DBLP': 'journals/corr/abs-2012-08478', 'DOI': '10.1609/aaai.v35i14.17519', 'CorpusId': 229180995, 'ArXiv': 2012.08478}, 'label': 0}\n",
      "{'paperId': 'c3d92f37c9c2d164d95dcfdeb181dfa758f60437', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/c3d92f37c9c2d164d95dcfdeb181dfa758f60437', 'title': 'BioNLP Shared Task 2013: Supporting Resources', 'abstract': 'This paper describes the technical contribution of the supporting resources provided for the BioNLP Shared Task 2013. Following the tradition of the previous two BioNLP Shared Task events, the task organisers and several external groups sought to make system development easier for the task participants by providing automatically generated analyses using a variety of automated tools. Providing analyses created by different tools that address the same task also enables extrinsic evaluation of the tools through the evaluation of their contributions to the event extraction task. Such evaluation can improve understanding of the applicability and benefits of specific tools and representations. The supporting resources described in this paper will continue to be publicly available from the shared task homepage http://2013.bionlp-st.org/', 'externalIds': {'MAG': 2916147465.0, 'DBLP': 'conf/bionlp/StenetorpGHCDLW13', 'CorpusId': 9610093, 'ACL': 'W13-2013'}, 'label': 1}\n",
      "{'paperId': '02ec859969d4c4dda92abb4bfff95ade96227be2', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/02ec859969d4c4dda92abb4bfff95ade96227be2', 'title': 'An Empirical Study of UMLS Concept Extraction from Clinical Notes using Boolean Combination Ensembles', 'abstract': 'Our objective in this study is to investigate the behavior of Boolean operators on combining annotation output from multiple Natural Language Processing (NLP) systems across multiple corpora and to assess how filtering by aggregation of Unified Medical Language System (UMLS) Metathesaurus concepts affects system performance for Named Entity Recognition (NER) of UMLS concepts. We used three corpora annotated for UMLS concepts: 2010 i2b2 VA challenge set (31,161 annotations), Multi-source Integrated Platform for Answering Clinical Questions (MiPACQ) corpus (17,457 annotations including UMLS concept unique identifiers), and Fairview Health Services corpus (44,530 annotations). Our results showed that for UMLS concept matching, Boolean ensembling of the MiPACQ corpus trended towards higher performance over individual systems. Use of an approximate grid-search can help optimize the precision-recall tradeoff and can provide a set of heuristics for choosing an optimal set of ensembles.', 'externalIds': {'DBLP': 'journals/corr/abs-2108-02255', 'CorpusId': 236924530, 'ArXiv': 2108.02255}, 'label': 1}\n",
      "{'paperId': '5a8c3728285be5a7e23383e4438df759a5f09289', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/5a8c3728285be5a7e23383e4438df759a5f09289', 'title': 'Extracting evidence of supplement-drug interactions from literature', 'abstract': 'To improve discovery of dietary supplement safety information, we demonstrate an automated method for extracting evidence of supplement-drug interactions (SDIs) from scientific text. To address the lack of labeled data in this domain, we use labels of the closely related task of identifying drug-drug interactions (DDIs) for supervision. We fine-tune the contextualized word representations of BERT-large using labeled data from the PDDI corpus. We process 22M abstracts from PubMed using this model, and extract evidence for 55946 unique interactions between 1923 supplements and 2727 drugs (precision: 0.74, accuracy: 0.83), demonstrating that learning the task of DDI classification transfers successfully to the related problem of SDI classification. We implement a freely-available public interface this http URL to browse and search evidence sentences extracted by our model.', 'externalIds': {'MAG': 2973865639.0, 'DBLP': 'journals/corr/abs-1909-08135', 'CorpusId': 202660640, 'ArXiv': 1909.08135}, 'label': 1}\n",
      "{'paperId': '2c75545d594e5544a1538aa05eb641e91e1bf45f', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/2c75545d594e5544a1538aa05eb641e91e1bf45f', 'title': 'Extracting Kinship from Obituary to Enhance Electronic Health Records for Genetic Research', 'abstract': 'Claims database and electronic health records database do not usually capture kinship or family relationship information, which is imperative for genetic research. We identify online obituaries as a new data source and propose a special named entity recognition and relation extraction solution to extract names and kinships from online obituaries. Built on 1,809 annotated obituaries and a novel tagging scheme, our joint neural model achieved macro-averaged precision, recall and F measure of 72.69%, 78.54% and 74.93%, and micro-averaged precision, recall and F measure of 95.74%, 98.25% and 96.98% using 57 kinships with 10 or more examples in a 10-fold cross-validation experiment. The model performance improved dramatically when trained with 34 kinships with 50 or more examples. Leveraging additional information such as age, death date, birth date and residence mentioned by obituaries, we foresee a promising future of supplementing EHR databases with comprehensive and accurate kinship information for genetic research.', 'externalIds': {'MAG': 2972890185.0, 'DBLP': 'conf/smm4h/HeWMZHLY19', 'DOI': '10.18653/v1/W19-3201', 'CorpusId': 203432068, 'ACL': 'W19-3201'}, 'label': 1}\n",
      "{'paperId': '48685f26b32d199e6a4d80f6c61e62cc9738e403', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/48685f26b32d199e6a4d80f6c61e62cc9738e403', 'title': 'Two Strong Baselines for the BioNLP 2009 Event Extraction Task', 'abstract': 'This paper presents two strong baselines for the BioNLP 2009 shared task on event extraction. First we re-implement a rule-based approach which allows us to explore the task and the effect of domain-adapted parsing on it. We then replace the rule-based component with support vector machine classifiers and achieve performance near the state-of-the-art without using any external resources. The good performances achieved and the relative simplicity of both approaches make them reproducible baselines. We conclude with suggestions for future work with respect to the task representation.', 'externalIds': {'MAG': 2173988953.0, 'DBLP': 'conf/bionlp/Vlachos10', 'CorpusId': 3878510, 'ACL': 'W10-1901'}, 'label': 1}\n",
      "{'paperId': 'b7d2db37e8af746b9324ff4c647123e92b59f5ba', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/b7d2db37e8af746b9324ff4c647123e92b59f5ba', 'title': 'Biomedical Argument Mining Based on Sequential Multi-Task Learning', 'abstract': 'Biomedical argument mining aims to automatically identify and extract the argumentative structure in biomedical text. It helps to determine not only what positions people adopt, but also why they hold such opinions, which provides valuable insights into medical decision making. Generally, biomedical argument mining consists of three subtasks: argument component identification, argument component classification and relation identification. Current approaches employ conventional multi-task learning framework for jointly addressing the latter two subtasks, and achieve some success. However, explicit sequential dependency between these two subtasks is ignored, which is crucial for accurate biomedical argument mining. Moreover, relation identification is conducted solely based on the argument component pair without considering its potentially valuable context. Therefore, in this paper, a novel sequential multi-task learning approach is proposed for biomedical argument mining. Specifically, to model explicit sequential dependency between argument component classification and relation identification, an information transfer strategy is employed to capture the information of argument component type that is transferred to relation identification. Furthermore, graph convolutional network is employed to model dependency relation among the related argument component pairs. The proposed method has been evaluated on a benchmark dataset and the experimental results show that the proposed method outperforms the state-of-the-art methods.', 'externalIds': {'DBLP': 'journals/tcbb/SiSZRL23', 'DOI': '10.1109/TCBB.2022.3173447', 'CorpusId': 248833021, 'PubMed': 35576420.0}, 'label': 1}\n",
      "{'paperId': 'f80523f8aac26806971343eb1a3cc9d8099d8e86', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/f80523f8aac26806971343eb1a3cc9d8099d8e86', 'title': 'Exploring variation across biomedical subdomains', 'abstract': 'Previous research has demonstrated the importance of handling differences between domains such as \"newswire\" and \"biomedicine\" when porting NLP systems from one domain to another. In this paper we identify the related issue of subdomain variation, i.e., differences between subsets of a domain that might be expected to behave homogeneously. Using a large corpus of research articles, we explore how subdomains of biomedicine vary across a variety of linguistic dimensions and discover that there is rich variation. We conclude that an awareness of such variation is necessary when deploying NLP systems for use in single or multiple subdomains.', 'externalIds': {'MAG': 1608193633.0, 'DBLP': 'conf/coling/LippincottSSK10', 'CorpusId': 42212, 'ACL': 'C10-1078'}, 'label': 1}\n",
      "{'paperId': 'eb9fb8385c5824b029633c0cb68a8fb8573380ad', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/eb9fb8385c5824b029633c0cb68a8fb8573380ad', 'title': 'Relation Extraction: Perspective from Convolutional Neural Networks', 'abstract': 'Up to now, relation extraction systems have made extensive use of features generated by linguistic analysis modules. Errors in these features lead to errors of relation detection and classification. In this work, we depart from these traditional approaches with complicated feature engineering by introducing a convolutional neural network for relation extraction that automatically learns features from sentences and minimizes the dependence on external toolkits and resources. Our model takes advantages of multiple window sizes for filters and pre-trained word embeddings as an initializer on a non-static architecture to improve the performance. We emphasize the relation extraction problem with an unbalanced corpus. The experimental results show that our system significantly outperforms not only the best baseline systems for relation extraction but also the state-of-the-art systems for relation classification.', 'externalIds': {'MAG': 2251622960.0, 'DBLP': 'conf/naacl/NguyenG15', 'DOI': '10.3115/v1/W15-1506', 'CorpusId': 12585424, 'ACL': 'W15-1506'}, 'label': 0}\n",
      "{'paperId': '1cd3be6144ecf29f4434727a7a577245baafb3e8', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/1cd3be6144ecf29f4434727a7a577245baafb3e8', 'title': 'Counts@IITK at SemEval-2021 Task 8: SciBERT Based Entity And Semantic Relation Extraction For Scientific Data', 'abstract': 'This paper presents the system for SemEval 2021 Task 8 (MeasEval). MeasEval is a novel span extraction, classification, and relation extraction task focused on finding quantities, attributes of these quantities, and additional information, including the related measured entities, properties, and measurement contexts. Our submitted system, which placed fifth (team rank) on the leaderboard, consisted of SciBERT with [CLS] token embedding and CRF layer on top. We were also placed first in Quantity (tied) and Unit subtasks, second in MeasuredEntity, Modifier and Qualifies subtasks, and third in Qualifier subtask.', 'externalIds': {'DBLP': 'conf/semeval/GangwarJSM21', 'DOI': '10.18653/v1/2021.semeval-1.175', 'CorpusId': 233025340, 'ACL': '2021.semeval-1.175', 'ArXiv': 2104.01364}, 'label': 0}\n",
      "{'paperId': 'ca4c3a01c67c048b9ff654c208f28b91f2aa923a', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/ca4c3a01c67c048b9ff654c208f28b91f2aa923a', 'title': 'RKNNMDA: Ranking-based KNN for MiRNA-Disease Association prediction', 'abstract': 'ABSTRACT Cumulative verified experimental studies have demonstrated that microRNAs (miRNAs) could be closely related with the development and progression of human complex diseases. Based on the assumption that functional similar miRNAs may have a strong correlation with phenotypically similar diseases and vice versa, researchers developed various effective computational models which combine heterogeneous biologic data sets including disease similarity network, miRNA similarity network, and known disease-miRNA association network to identify potential relationships between miRNAs and diseases in biomedical research. Considering the limitations in previous computational study, we introduced a novel computational method of Ranking-based KNN for miRNA-Disease Association prediction (RKNNMDA) to predict potential related miRNAs for diseases, and our method obtained an AUC of 0.8221 based on leave-one-out cross validation. In addition, RKNNMDA was applied to 3 kinds of important human cancers for further performance evaluation. The results showed that 96%, 80% and 94% of predicted top 50 potential related miRNAs for Colon Neoplasms, Esophageal Neoplasms, and Prostate Neoplasms have been confirmed by experimental literatures, respectively. Moreover, RKNNMDA could be used to predict potential miRNAs for diseases without any known miRNAs, and it is anticipated that RKNNMDA would be of great use for novel miRNA-disease association identification.', 'externalIds': {'MAG': 2607159126.0, 'DOI': '10.1080/15476286.2017.1312226', 'CorpusId': 4964364, 'PubMed': 28421868.0}, 'label': 0}\n",
      "{'paperId': 'cf6b6a55e3e10fdb5590c66ef6056abe40c867e7', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/cf6b6a55e3e10fdb5590c66ef6056abe40c867e7', 'title': 'In Layman\\x92s Terms: Semi-Open Relation Extraction from Scientific Texts', 'abstract': 'Information Extraction (IE) from scientific texts can be used to guide readers to the central information in scientific documents. But narrow IE systems extract only a fraction of the information captured, and Open IE systems do not perform well on the long and complex sentences encountered in scientific texts. In this work we combine the output of both types of systems to achieve Semi-Open Relation Extraction, a new task that we explore in the Biology domain. First, we present the Focused Open Biological Information Extraction (FOBIE) dataset and use FOBIE to train a state-of-the-art narrow scientific IE system to extract trade-off relations and arguments that are central to biology texts. We then run both the narrow IE system and a state-of-the-art Open IE system on a corpus of 10K open-access scientific biological texts. We show that a significant amount (65%) of erroneous and uninformative Open IE extractions can be filtered using narrow IE extractions. Furthermore, we show that the retained extractions are significantly more often informative to a reader.', 'externalIds': {'MAG': 3025620128.0, 'DBLP': 'conf/acl/KruiperVCDK20', 'DOI': '10.18653/v1/2020.acl-main.137', 'CorpusId': 218674072, 'ACL': '2020.acl-main.137', 'ArXiv': 2005.07751}, 'label': 1}\n",
      "{'paperId': '3e5de204257ae81d54826c6b38b60493634a0dc7', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/3e5de204257ae81d54826c6b38b60493634a0dc7', 'title': 'ZooPhy: A bioinformatics pipeline for virus phylogeography and surveillance', 'abstract': 'ObjectiveWe will describe the ZooPhy system for virus phylogeography and public health surveillance [1]. ZooPhy is designed for public health personnel that do not have expertise in bioinformatics or phylogeography. We will show its functionality by performing case studies of different viruses of public health concern including influenza and rabies virus. We will also provide its URL for user feedback by ISDS delegates.IntroductionSequence-informed surveillance is now recognized as an important extension to the monitoring of rapidly evolving pathogens [2]. This includes phylogeography, a field that studies the geographical lineages of species including viruses [3] by using sequence data (and relevant metadata such as sampling location). This work relies on bioinformatics knowledge. For example, the user first needs to find a relevant sequence database, navigate through it, and use proper search parameters to obtain the desired data. They also must ensure that there is sufficient metadata such as collection date and sampling location. They then need to align the sequences and integrate everything into specific software for phylogeography. For example, BEAST [4] is a popular tool for discrete phylogeography. For proper use, the software requires knowledge of phylogenetics and utilization of BEAUti, its XML processing software. The user then needs to use other software, like TreeAnnotator [4], to produce a single (\\x93representative\\x94) maximum clade credibility (MCC) tree. Even then, the evolutionary spread of the virus can be difficult to interpret via a simple tree viewer. There is software (such as SpreaD3 [5]) for visualizing a tree within a geographic context, yet for novice users, it might not be easy to use. Currently, there are only a few systems designed to automate these types of tasks for virus surveillance and phylogeography.MethodsWe have developed ZooPhy, a pipeline for sequence-informed surveillance and phylogeography [1]. It is designed for health agency personnel that do not have expertise in bioinformatics or phylogeography. We created a large database of all virus sequences and metadata from GenBank [6] as well as a smaller database for selected viruses perceived to be of great interest for health agencies including: influenza (A, B, and C), Ebola, rabies, West Nile virus, and Zika virus.In Figure 1A, we show our front-end architecture, created in the style of the influenza research database [7], that enables the user to search by: virus, gene name, host, time-frame, and geography. We also allow users to upload their own list of GenBank accessions or unpublished sequences. Hitting \\x93Search\\x94 produces a Results tab which includes the metadata of the sequences. We provide a feature to randomly down-sample by a specified percentage or number. We also allow the user to download the metadata in CSV format or the unaligned sequences in FASTA format.The final tab, \"Run\", includes a text box for specifying an email in order to send job updates and final results on virus spread. We also enable for the user to study the influence of predictors on virus spread (via a generalized linear model). Currently, we have predictors such as temperature, great circle distance, population, and sample size for selected countries. We also offer experts the ability to specify advanced modeling parameters including the molecular clock type (strict vs. relaxed), coalescent tree prior, and chain length and sampling frequency for the Markov-chain Monte Carlo. When the user selects \\x93Start ZooPhy\\x94, a pre-processor eliminates incomplete or non-disjoint record locations and sends the rest for analysis.ResultsWhen initiated, the ZooPhy pipeline includes sequence alignment via Mafft [8] and creation of an XML template via BEASTGen for input into BEAST for discrete phylogeography. It then uses TreeAnnotator [3] to create an MCC tree from the posterior distribution of sampled trees. ZooPhy uses the MCC as input into SpreaD3 for a recreation of the time-estimated migration via a map. If the user selects the GLM option, the system runs an R script to calculate the Bayes factor of the inclusion probability for each predictor and draws a plot including the regression coefficient and its 95% Bayesian credible interval. We are currently working on new visualization techniques such as those demonstrated by Dudas et al. that combine time-oriented spread via a map and evolution on a phylogenetic tree annotated by discrete locations [9].ConclusionsRecent advances in phylodynamics, bioinformatics, and visualization have demonstrated the potential of pipelines to support surveillance. One example is NextStrain which can perform real-time virus phylodynamics [10]. The system has recently been added as an app to the Global Initiative on Sharing Avian Influenza Data (GISAID) database for influenza tracking using DNA sequences [11]. This presentation will highlight a pipeline for virus phylogeography designed for epidemiologists who are not experts in bioinformatics but wish to leverage virus sequence data as part of routine surveillance. We will describe the development and implementation of our system, ZooPhy, and use real-world case studies to demonstrate its functionality. We invite ISDS delegates to use the system via our web portal, https://zodo.asu.edu/zoophy/ and provide feedback on system utilization.References1. Scotch, M., et al., At the intersection of public-health informatics and bioinformatics: using advanced Web technologies for phylogeography. Epidemiology, 2010. 21(6), 764-768.2. Gardy, J.L. and N.J. Loman, Towards a genomics-informed, real-time, global pathogen surveillance system. Nat Rev Genet, 2018. 19: p. 9-20.3. Avise, J.C., Phylogeography : the history and formation of species. 2000, Cambridge, Mass.: Harvard University Press.4. Suchard, M.A., et al., Bayesian phylogenetic and phylodynamic data integration using BEAST 1.10. Virus Evol, 2018. 4.5. Bielejec, F., et al., SpreaD3: Interactive Visualization of Spatiotemporal History and Trait Evolutionary Processes. Mol Biol Evol, 2016. 33(8): p. 2167-9.6. Benson, D. A.,et al., GenBank. Nucleic Acids Res, 2018. 46, p. D41-D47.7. Zhang, Y., et al., Influenza Research Database: An integrated bioinformatics resource for influenza virus research. Nucleic Acids Res, 2017. 45: p. D466-D474.8. Katoh, K. and D.M. Standley, MAFFT: iterative refinement and additional methods. Methods Mol Biol, 2014. 1079: p. 131-46.9. Dudas, G., et al., Virus genomes reveal factors that spread and sustained the Ebola epidemic. Nature, 2017. 544(7650): p. 309-315.10. Hadfield, J., et al., Nextstrain: real-time tracking of pathogen evolution. Bioinformatics, 2018.11. NextFlu. 2018; Available from: https://www.gisaid.org/epiflu-applications/nextflu-app/.\\xa0', 'externalIds': {'MAG': 2947102967.0, 'PubMedCentral': 6606160.0, 'DOI': '10.5210/ojphi.v11i1.9729', 'CorpusId': 190871816}, 'label': 0}\n",
      "{'paperId': '411c6e5948bb50a9bad23581e2118aca14c24cd2', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/411c6e5948bb50a9bad23581e2118aca14c24cd2', 'title': 'Protein-protein Interaction Passage Extraction Using the Interaction Pattern Kernel Approach for the BioCreative 2015 BioC Track', 'abstract': 'Discovering the interactions between proteins mentioned in biomedical literatures is one of the core topics of text mining in the field of life science. In this paper, we propose a system under interaction pattern generation approach to capture frequent PPI patterns in text with the use of official BioC API and Semantic Class Labeling. We also present an interaction pattern tree kernel method that integrates the PPI pattern with convolution tree kernel to extract protein-protein interactions. Empirical evaluations on the LLL, IEPA, and HPRD50 corpora demonstrate that our method is effective and outperforms several well-known PPI extraction methods.', 'externalIds': {'MAG': 2781953834.0, 'CorpusId': 17878549}, 'label': 1}\n",
      "{'paperId': '9ab261817a91e3e9435607bbfc9b54157c7926c1', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/9ab261817a91e3e9435607bbfc9b54157c7926c1', 'title': 'Entity-based Claim Representation Improves Fact-Checking of Medical Content in Tweets', 'abstract': 'False medical information on social media poses harm to people\\x92s health. While the need for biomedical fact-checking has been recognized in recent years, user-generated medical content has received comparably little attention. At the same time, models for other text genres might not be reusable, because the claims they have been trained with are substantially different. For instance, claims in the SciFact dataset are short and focused: \\x93Side effects associated with antidepressants increases risk of stroke\\x94. In contrast, social media holds naturally-occurring claims, often embedded in additional context: \"\\x91If you take antidepressants like SSRIs, you could be at risk of a condition called serotonin syndrome\\x92 Serotonin syndrome nearly killed me in 2010. Had symptoms of stroke and seizure.\\x94 This showcases the mismatch between real-world medical claims and the input that existing fact-checking systems expect. To make user-generated content checkable by existing models, we propose to reformulate the social-media input in such a way that the resulting claim mimics the claim characteristics in established datasets. To accomplish this, our method condenses the claim with the help of relational entity information and either compiles the claim out of an entity-relation-entity triple or extracts the shortest phrase that contains these elements. We show that the reformulated input improves the performance of various fact-checking models as opposed to checking the tweet text in its entirety.', 'externalIds': {'DBLP': 'journals/corr/abs-2209-07834', 'DOI': '10.48550/arXiv.2209.07834', 'CorpusId': 252355558, 'ACL': '2022.argmining-1.18', 'ArXiv': 2209.07834}, 'label': 1}\n",
      "{'paperId': '10633b9c807e4418dc012414abf2e340c8d7edcf', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/10633b9c807e4418dc012414abf2e340c8d7edcf', 'title': 'Augmenting Biomedical Named Entity Recognition with General-domain Resources', 'abstract': 'Training a neural network-based biomedical named entity recognition (BioNER) model usually requires extensive and costly human annotations. While several studies have employed multi-task learning with multiple BioNER datasets to reduce human effort, this approach does not consistently yield performance improvements and may introduce label ambiguity in different biomedical corpora. We aim to tackle those challenges through transfer learning from easily accessible resources with fewer concept overlaps with biomedical datasets. In this paper, we proposed GERBERA, a simple-yet-effective method that utilized a general-domain NER dataset for training. Specifically, we performed multi-task learning to train a pre-trained biomedical language model with both the target BioNER dataset and the general-domain dataset. Subsequently, we fine-tuned the models specifically for the BioNER dataset. We systematically evaluated GERBERA on five datasets of eight entity types, collectively consisting of 81,410 instances. Despite using fewer biomedical resources, our models demonstrated superior performance compared to baseline models trained with multiple additional BioNER datasets. Specifically, our models consistently outperformed the baselines in six out of eight entity types, achieving an average improvement of 0.9% over the best baseline performance across eight biomedical entity types sourced from five different corpora. Our method was especially effective in amplifying performance on BioNER datasets characterized by limited data, with a 4.7% improvement in F1 scores on the JNLPBA-RNA dataset.', 'externalIds': {'CorpusId': 270560782, 'ArXiv': 2406.10671}, 'label': 1}\n",
      "{'paperId': 'ccfbf27f0960ea4ccdc8fe8ef7581d0d4bfc363e', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/ccfbf27f0960ea4ccdc8fe8ef7581d0d4bfc363e', 'title': 'Huawei\\x92s NMT Systems for the WMT 2019 Biomedical Translation Task', 'abstract': 'This paper describes Huawei\\x92s neural machine translation systems for the WMT 2019 biomedical translation shared task. We trained and fine-tuned our systems on a combination of out-of-domain and in-domain parallel corpora for six translation directions covering English\\x96Chinese, English\\x96French and English\\x96German language pairs. Our submitted systems achieve the best BLEU scores on English\\x96French and English\\x96German language pairs according to the official evaluation results. In the English\\x96Chinese translation task, our systems are in the second place. The enhanced performance is attributed to more in-domain training and more sophisticated models developed. Development of translation models and transfer learning (or domain adaptation) methods has significantly contributed to the progress of the task.', 'externalIds': {'MAG': 2971345087.0, 'DBLP': 'conf/wmt/PengLLL19', 'DOI': '10.18653/v1/W19-5420', 'CorpusId': 201739611, 'ACL': 'W19-5420'}, 'label': 1}\n",
      "{'paperId': '5287187e504d41db7975313d553f1483e6d45c11', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/5287187e504d41db7975313d553f1483e6d45c11', 'title': 'NTTD at the NTCIR-16 Real-MedNLP Task', 'abstract': 'The NTTD team participated in the Subtask1-CR-JA and Subtask1-RR-JA subtasks of the NTCIR-16 Real-MedNLP Task. This paper reports our approach to solve the NER (named entity recognition) problem when dealing with limited labeled medical documents. The documents are real Case-Report and Radiographic-Report data in Japanese. We first applied our recently developed annotation inconsistency detection tool to detect and correct inappropriate labels within the given training data. Then we applied data augmentation methods to create additional labeled data and combined the original and additional data as training data of our model. In this task, we fine-tuned Flair by the forementioned training data and acquired the results.', 'externalIds': {'CorpusId': 251542057}, 'label': 1}\n",
      "{'paperId': 'c9ba1646c3f592a717403a9d6db24fc4a096550e', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/c9ba1646c3f592a717403a9d6db24fc4a096550e', 'title': 'AJE: Attention Mechanism for Entity-relation Joint Extraction', 'abstract': 'Joint extraction of entities and relations is an significant issue of information extraction, which is very helpful for many downstream tasks, including knowledge base construction, question answering, and biomedical text diagnosis[1], etc. The common approach of existing models is to extract the subject and the relation first, then compute the subject and the relation to obtain the object, and finally, the triplet is judged. However, such an approach cannot efficiently handle of information extraction, and the results are not very good for Subject-Object Overlap (SOO) case. In this paper, a joint entity-relation extraction method AJE is proposed based on dot-product attention mechanism. The method first maps subject, object and relationship into three matrices of Q, K and V. After that, the attention weighting is achieved on these three matrices and the output vector is used to determine whether the triple is correct or not. The F1-score is used in experiments to show that the proposed model is more efficient than the current existing ones. It also has better results in handling other cases such as SOO, multi-triple problem, etc.', 'externalIds': {'DOI': '10.1088/1742-6596/2504/1/012020', 'CorpusId': 258998135}, 'label': 0}\n",
      "{'paperId': '2d8c9491dd40d1b65caf4467b1c512d5958935c3', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/2d8c9491dd40d1b65caf4467b1c512d5958935c3', 'title': 'Parallel Computation in Medical Imaging Applications', 'abstract': \"There is currently a rapidly growing interest in parallel computation application in various medical imaging and image processing fields. This trend is expected to continue growing as more sophisticated and challenging medical imaging, image processing, and high-order data visualization problems are being addressed. The ongoing cost drop in computational tools and their wide accessibility play a center role as well. Given its short history, this area is still not a well-defined scientific discipline. The selected topics and papers for this special issue shed more light on various aspects of this expanding field and its potential in accelerating medical imaging applications. \\n \\nThis special issue contains eleven papers covering various imaging modalities including MRI, CT, X-ray, US, and optical tomography. The papers demonstrated the potential of parallel computation in medical imaging and visualization in a wide range of applications including image reconstruction, image denoising, motion estimation, deformable registration, diffeomorphic mapping, and modeling. \\n \\nIn the paper entitled \\x93CUDA-accelerated geodesic ray-tracing for fiber tracking,\\x94 E. van Aart et al. present an accelerated algorithm for brain fiber tracking. Noninvasive diffusion weighted imaging followed by reconstructing the brain fiber structure provides a unique way to inspect the complex structures inside the brain in a microscopic level. However, these processes are computationally expensive. The proposed algorithm utilizes the parallel structure of a graphics processing unit in combination with the CUDA platform to substantially accelerate the execution time of the fiber tracking by a factor up to 40 times compared to a multithreaded CPU implementation. \\n \\nIn the paper entitled \\x93Efficient probabilistic and geometric anatomical mapping using particle mesh approximation on GPUs,\\x94 L. Ha et al. developed a new three-dimensional deformable registration algorithm for mapping brain datasets. The problem typically involves significant amount of computation time and thus became infeasible for practical purposes. The proposed registration method generates a mapping between anatomies represented as a multicompartment model. The implementation of the algorithm using particle mesh approximation on graphical processing units (GPUs) achieves the speed up of three orders of magnitudes compared to a CPU reference implementation, making it possible to use the technique in time-critical applications. \\n \\nIn the paper entitled \\x93Heterogeneous computing for vertebra detection and segmentation in X-ray images,\\x94 F. Lecron et al. address the low computational efficiency of the conventional active shape model (ACM) algorithm and exploit the potential acceleration achieved when ACM is implemented on a parallel computation architecture. The paper demonstrates a global speedup ranging from 3 to 22, in comparison with the CPU implementation. \\n \\nIn the paper entitled \\x93Mapping iterative medical imaging algorithm on cell accelerator,\\x94 M. Xu and P. Thulasiraman investigate the potential of parallel computation in accelerating the image algebraic reconstruction techniques which in one application may benefit image reconstruction on CT machines. The authors efficiently map the optimized algorithm on the cell broadband engine (BE) for improved performance over CPU version. The implementation on a cell BE is shown to be five times faster when compared to the performance on Sun Fire x4600, a shared memory machine. \\n \\nIn the paper entitled \\x93GPU-accelerated finite element method for modelling light transport in diffuse optical tomography,\\x94 M. Schweiger introduces a GPU-accelerated finite element solver for the computation of light transport in scattering media. Solutions are presented for both time-domain and frequency-domain problems. A comparison with a CPU-based implementation shows significant performance gains of the graphics-accelerated solution, with improvements of approximately a factor of 10 and 20 for double- and single-precision computations, respectively. \\n \\nIn the area of MRI reconstruction, the paper entitled \\x93High-performance 3D compressive sensing MRI reconstruction using many-core architectures,\\x94 by D. Kim et al., investigates how different throughput-oriented architectures can benefit compressed sensing (CS) MRI reconstruction algorithm and what levels of acceleration are feasible on different modern platforms. The authors demonstrate that a CUDA-based code running on a GPU can reconstruct a 256 × 160 × 80 volume from an 8-channel acquisition in as fast as 12 seconds, which is a significant improvement over the state of the art. This achievement may potentially bring CS methods even closer to clinical viability. \\n \\nIn the paper entitled \\x93True 4D image denoising on the GPU,\\x94 A. Eklund et al. show the implementation of a four-dimensional denoising algorithm on a GPU. The algorithm was applied to a 4D CT heart dataset of the resolution 512 × 512 × 445 × 20. The result is that the GPU can complete the denoising in as fast as 8 minutes. On the contrary, the CPU implementation requires about 50 minutes. The short processing time increases the clinical value of true 4D image denoising significantly. \\n \\nIn the field of simulation and phantom modeling, the paper entitled \\x93Patient specific dosimetry phantoms using multichannel LDDMM of the whole body,\\x94 by D. J. Tward et al., describes an accelerated automated procedure for creating detailed patient specific pediatric dosimetry phantoms from a small set of segmented organs in a child's CT scan. The algorithm involves full body mappings from adult template to pediatric images using multichannel large deformation diffeomorphic metric mapping with a parallel implementation. The performance of the algorithm was validated on a set of 24 male and 18 female pediatric patients. Running times for the various patients examined ranged from over 30 hours on a single processor to under 1 hour on 24 processors in parallel. \\n \\nIn the paper entitled \\x93Numerical solution of diffusion models in biomedical imaging on multicore processors,\\x94 L. D'Amore et al. address the solution of nonlinear partial differential equations (PDEs) of diffusion/advection type, underlying most problems in image analysis. As a case study, the paper addresses the segmentation of medical structures and performs a comparative study of numerical algorithms arising from using the semi-implicit and the fully implicit discretization schemes. Comparison criteria take into account both the accuracy and the efficiency of the algorithms including convergence, execution time, and parallel efficiency. This analysis is carried out in a multicore-based parallel computing environment. \\n \\nIn the paper entitled \\x93On the usage of GPUs for efficient motion estimation in medical image sequences,\\x94 J. Thiyagalingam et al. investigate the mapping of an enhanced motion estimation algorithm to novel GPU architectures. Using a database of three-dimensional ultrasound image sequences, the authors show that the mapping leads to substantial performance gains, up to a factor of 60 and can provide near-real-time performance. The paper also shows how architectural peculiarities of these devices can be best exploited in the benefit of algorithms, most specifically for addressing the challenges related to their access patterns and different memory configurations. The paper further evaluates the performance of the algorithm on three different GPU architectures and performs a comprehensive analysis of the results. \\n \\nIn the paper entitled \\x93Fast random permutation tests enable objective evaluation of methods for single subject fMRI analysis\\x94 by A. Eklund et al., it is shown that how the computational power of cost-efficient GPUs can be used to speed up random permutation tests. These tests are commonly involved in fMRI data analysis for identifying areas in the brain that are active. However, the computational burden with processing times ranging from hours to days has made them impractical for routine use in single-subject fMRI analysis. A test on GPU with 10000 permutations takes less than a minute, making statistical analysis of advanced detection methods in fMRI practically feasible. To exemplify the permutation-based approach, brain activity maps generated by the general linear model (GLM) and canonical correlation analysis (CCA) are compared at the same significance level.\", 'externalIds': {'MAG': 2031736760.0, 'DBLP': 'journals/ijbi/KadahAF11', 'PubMedCentral': 3296162.0, 'DOI': '10.1155/2011/840181', 'CorpusId': 1178933, 'PubMed': 22481901.0}, 'label': 0}\n",
      "{'paperId': 'bd98f9090b9c03fcb93ef51510d01d3fd059ba73', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/bd98f9090b9c03fcb93ef51510d01d3fd059ba73', 'title': 'What\\x92s in a gene name? Automated refinement of gene name dictionaries', 'abstract': 'Many approaches for named entity recognition rely on dictionaries gathered from curated databases (such as Entrez Gene for gene names.) Strategies for matching entries in a dictionary against arbitrary text use either inexact string matching that allows for known deviations, dictionaries enriched according to some observed rules, or a combination of both. Such refined dictionaries cover potential structural, lexical, orthographical, or morphological variations. In this paper, we present an approach to automatically analyze dictionaries to discover how names are composed and which variations typically occur. This knowledge can be constructed by looking at single entries (names and synonyms for one gene), and then be transferred to entries that show similar patterns in one or more synonyms. For instance, knowledge about words that are frequently missing in (or added to) a name (\"antigen\", \"protein\", \"human\") could automatically be extracted from dictionaries. This paper should be seen as a vision paper, though we implemented most of the ideas presented and show results for the task of gene name recognition. The automatically extracted name composition rules can easily be included in existing approaches, and provide valuable insights into the biomedical sub-language.', 'externalIds': {'MAG': 1988946940.0, 'DBLP': 'conf/bionlp/Hakenberg07', 'DOI': '10.3115/1572392.1572419', 'CorpusId': 11328858, 'ACL': 'W07-1020'}, 'label': 1}\n",
      "{'paperId': 'd624ae62649a9c20e3dabc57375b1d915161bbc7', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/d624ae62649a9c20e3dabc57375b1d915161bbc7', 'title': 'A Semantic Approach for the Homogeneous Identification of Events in Eight Patient Databases: A Contribution to the European eu-ADR Project', 'abstract': 'The overall objective of the eu-ADR project is the design, development, and validation of a computerised system that exploits data from electronic health records and biomedical databases for the early detection of adverse drug reactions. Eight different databases, containing health records of more than 30 million European citizens, are involved in the project. Unique queries cannot be performed across different databases because of their heterogeneity: Medical record and Claims databases, four different terminologies for coding diagnoses, and two languages for the information described in free text. The aim of our study was to provide database owners with a common basis for the construction of their queries. Using the UMLS, we provided a list of medical concepts, with their corresponding terms and codes in the four terminologies, which should be considered to retrieve the relevant information for the events of interest from the databases.', 'externalIds': {'MAG': 1500494212.0, 'DBLP': 'conf/mie/AvillachMJTPDTPCGMBHGHMPFSF09', 'DOI': '10.3233/978-1-60750-044-5-190', 'CorpusId': 13374884, 'PubMed': 19745295.0}, 'label': 1}\n",
      "{'paperId': 'fc3cc0eff910949dc56045e68f7c7a4d8b851edf', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/fc3cc0eff910949dc56045e68f7c7a4d8b851edf', 'title': 'Gene function prediction by mining biomedical literature', 'abstract': 'Tese de mestrado em Bioinformatica, apresentada a Universidade de Lisboa, atraves da Faculdade de Ciencias, 2004', 'externalIds': {'MAG': 2130594257.0, 'CorpusId': 85720772}, 'label': 2}\n",
      "{'paperId': '02a8bf543bb43038f8ab3bb9ca2f8103ae0a5be0', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/02a8bf543bb43038f8ab3bb9ca2f8103ae0a5be0', 'title': 'Research Paper: Rapidly Retargetable Approaches to De-identification in Medical Records', 'abstract': 'OBJECTIVE\\nThis paper describes a successful approach to de-identification that was developed to participate in a recent AMIA-sponsored challenge evaluation.\\n\\n\\nMETHOD\\nOur approach focused on rapid adaptation of existing toolkits for named entity recognition using two existing toolkits, Carafe and LingPipe.\\n\\n\\nRESULTS\\nThe \"out of the box\" Carafe system achieved a very good score (phrase F-measure of 0.9664) with only four hours of work to adapt it to the de-identification task. With further tuning, we were able to reduce the token-level error term by over 36% through task-specific feature engineering and the introduction of a lexicon, achieving a phrase F-measure of 0.9736.\\n\\n\\nCONCLUSIONS\\nWe were able to achieve good performance on the de-identification task by the rapid retargeting of existing toolkits. For the Carafe system, we developed a method for tuning the balance of recall vs. precision, as well as a confidence score that correlated well with the measured F-score.', 'externalIds': {'MAG': 2128004504.0, 'DBLP': 'journals/jamia/WellnerHMAMPYHH07', 'DOI': '10.1197/JAMIA.M2435', 'CorpusId': 24985266, 'PubMed': 17600096.0}, 'label': 1}\n",
      "{'paperId': '5b2bd05d33d52903d52fb1aab0af7958d340147e', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/5b2bd05d33d52903d52fb1aab0af7958d340147e', 'title': 'On MeSH: have female genitalia fallen into oblivion?', 'abstract': 'MeSH, or Medical Subject Headings, is the most reputable controlled vocabulary in the biomedical community. First introduced in 1963 by the U.S. National Library of Medicine (NLM), it consists today of 26,853 descriptors. Its use enables health information seekers to search and retrieve scientific articles from among the more than 20 million that are indexed in the NLM databases MEDLINE and PubMed [1]. Most descriptors are accompanied by a definition and are organized in a hierarchical tree that permits searching at various levels of specificity [1]. Medical specialties, study designs, diseases, anatomical body parts, and many chemical and pharmaceutical components share the privilege of existing as MeSH descriptors. The most intimate parts of the body\\x97penis, vagina, vulva, foreskin, anal canal, Bartholin\\x92s glands, breasts\\x97are well located, organized, enumerated, and defined in the MeSH repository. \\x93Labia minora\\x94 and \\x93labia majora,\\x94 however, do not yet appear in MeSH. \\x93Clitoris\\x94 does exist as a descriptor, though still undefined. Its tree number is A05.360.319.887.436: \\x93All MeSH Categories\\x94 > \\x93Anatomy category\\x94 > \\x93Urogenital System\\x94 > \\x93Genitalia\\x94 > \\x93Genitalia, Female\\x94 > \\x93Vulva\\x94 > \\x93Clitoris\\x94. It can also be linked to 23 other subheadings [1]. One must ask, why is the MeSH descriptor \\x93Clitoris\\x94 not defined? The MeSH Section staff is the board entitled with the task to update the controlled vocabulary. Any accusation that the undefined status of \\x93Clitoris\\x94 is due to MeSH being a primarily masculine institution oblivious to the idea of female genitalia would be unfounded, as four of the ten MeSH Section staff board are women [1]. Neither can we say that the MeSH section staff has not felt compelled to describe \\x93Clitoris\\x94 because the term has not drawn enough attention from the scholarly community. If one adds \\x93Clitoris\\x94 to the PubMed search builder, the database will retrieve 1,263 references. This figure is far from the 32,747 articles tagged under the MeSH descriptor \\x93Penis.\\x94 But it is a far larger number than the 336 articles tagged under the MeSH descriptor \\x93Onchocerciasis, Ocular\\x94 or the 443 under \\x93Anisakiasis,\\x94 and it is closer to the 1,288 tagged under \\x93Larva Migrans\\x94 (all parasitic diseases that affect the population of most of the Southern Hemisphere). To those of us dedicated to the study of female genital mutilation (FGM), it is almost insulting that \\x93Clitoris\\x94 remains undescribed. The reasons behind this absence can be traced back in history. Across the ages, the word \\x93clitoris,\\x94 its significance, and the organ\\x92s function as a sexual organ have been controversial [2]. By not defining it, the MeSH repository follows the historical trend of blurring, erasing, and sweeping away the concept, image, and reminiscences of the clitoris [2]. We could write to the MeSH section staff and propose a definition. However, if we scrutinize each one of the ethnic groups in the world, we will come to different conclusions on what \\x93clitoris\\x94 means. One can attempt to name a few. The clitoris is that part of the female genitalia that Rwandese men call rugongo and have to strike with the glans of the erect penis during sexual foreplay [3]. In KwaZulu-Natal, South Africa, the clitoris is that part of the body where women perform cuttings and rub \\x93love medicines\\x94 on the scars, aiming to increase desirability [4]. Since Mosotho women in Lesotho are aware of the importance of the clitoris in sexual pleasure, some girls consider the clitoris to be a part of their body they would prefer to elongate\\x97instead of attempting to elongate their labia minora [5]. The clitoris is also what Somali girls have excised because it is thought of as the male part of the female body, which needs to be removed in order to humanize a woman [6]. This belief should not be foreign to Westerners; in 1561, the Italian botanist Gabrielo Fallopio established an analogy between the penis and the clitoris, and it was not until 1987 that somebody\\x97the psychologist Josephine Lowndes Sevely\\x97argued that these organs were not similar at all [2]! The clitoris is what more than 3 million girls are at risk to get mutilated, excised, circumcised, cut, scarred, nicked, pricked, or pierced every year [7]. Thousands of those girls live in Northern, high-income countries where recent migrations have brought these issues to light. This has highlighted the need for more evidence-based research to guide health practitioners in the treatment and provision of care for the victims of FGM [8,9]. \\x93Genital Mutilation, female\\x94 can be found in PubMed, not as a MeSH descriptor but as an entry term\\x97a mere synonym of what MeSH considers a similar term, the descriptor \\x93Circumcision, Female.\\x94 A total of 712 articles are indexed tagged under this descriptor in PubMed. The search (\\x93Circumcision, Female\\x94[Mesh]) AND \\x93Clitoris\\x94[Mesh]) gives only 40 results. The MeSH definition of \\x93Circumcision, Female\\x94 agrees with the WHO definition of the non-MeSH descriptor \\x93Female Genital Mutilation\\x94 [1,7]. Nevertheless, many scholars advocate that the word \\x93circumcision\\x94 not be used indiscriminately as a synonym of \\x93mutilation.\\x94 Putting aside all of its diverse cultural connotations, it cannot be denied that the clitoris is a part of the female genital anatomy. Anatomically, it is an erectile organ composed of cavernous bodies and a glans clitoridis. Microscopically, in vivo dissection followed by histomorphological evaluation of the cavernous erectile tissues of the clitoris has demonstrated the role that the number and characteristics of its smooth muscle cells and its intricate vascular network can play in female sexual arousal response [10]. Functionally, it plays a key role in enhancing female orgasm [2]. The clitoris exists for the scholars aiming to increase the evidence on FGM. It exists for the decision makers working to table new laws against FGM in the parliaments, design health interventions to tackle its gyno-obstetrical complications, and fund campaigns to eradicate FGM. And it exists for the health practitioners caring for the victims of the cultural norms which dictate that their clitoris must be removed [8,9]. Hence, in justice to the estimated hundreds of millions of women in the world who have undergone FGM and also to the millions at risk, the MeSH descriptor \\x93Clitoris\\x94 deserves to be properly described.', 'externalIds': {'MAG': 2116937573.0, 'DOI': '10.1111/jsm.12264', 'CorpusId': 598879, 'PubMed': 23890102.0}, 'label': 0}\n",
      "{'paperId': '88ed818b44ac91d0e410c2444b785ae33db490f5', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/88ed818b44ac91d0e410c2444b785ae33db490f5', 'title': 'Diseases 2.0: a weekly updated database of disease\\x96gene associations from text mining and data integration', 'abstract': 'The scientific knowledge about which genes are involved in which diseases grows rapidly, which makes it difficult to keep up with new publications and genetics datasets. The DISEASES database aims to provide a comprehensive overview by systematically integrating and assigning confidence scores to evidence for disease\\x96gene associations from curated databases, genome-wide association studies (GWAS), and automatic text mining of the biomedical literature. Here, we present a major update to this resource, which greatly increases the number of associations from all these sources. This is especially true for the text-mined associations, which have increased by at least 9-fold at all confidence cutoffs. We show that this dramatic increase is primarily due to adding full-text articles to the text corpus, secondarily due to improvements to both the disease and gene dictionaries used for named entity recognition, and only to a very small extent due to the growth in number of PubMed abstracts. DISEASES now also makes use of a new GWAS database, TIGA, which considerably increased the number of GWAS-derived disease\\x96gene associations. DISEASES itself is also integrated into several other databases and resources, including GeneCards/MalaCards, Pharos/TCRD, and the Cytoscape stringApp. All data in DISEASES is updated on a weekly basis and is available via a web interface at https://diseases.jensenlab.org, from where it can also be downloaded under open licenses.', 'externalIds': {'DBLP': 'journals/biodb/GrissaJOJ22', 'PubMedCentral': 9216524.0, 'DOI': '10.1093/database/baac019', 'CorpusId': 245048201, 'PubMed': 35348648.0}, 'label': 1}\n",
      "{'paperId': 'c4cd040c2c21c4833ca6d122aec8055959f95e5b', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/c4cd040c2c21c4833ca6d122aec8055959f95e5b', 'title': 'Cost-effectiveness of a single inhaler triple therapy versus ICS/LABA in COPD', 'abstract': 'Background: IMPACT (InforMing the PAthway of COPD Treatment, NCT02164513), showed superior exacerbation reduction and lung function improvement with single inhaler, once-daily fluticasone furoate/umeclidinium/vilanterol (FF/UMEC/VI) 100/62.5/22?g vs once-daily FF/VI 100/22?g, for patients with moderate/severe COPD. Objectives: The cost-effectiveness of FF/UMEC/VI vs FF/VI was assessed, from a Canadian public payer perspective. Methods: A validated linked risk equation model (Briggs, Med Decis Making 37;4 2017), which predicts COPD disease progression, associated healthcare costs and health outcomes, was populated with baseline characteristics, efficacy and medication use from IMPACT. Canadian healthcare resource unit costs and drug costs were applied, with future costs and health outcomes discounted at 1.5% annually. Analysis was probabilistic, with a lifetime horizon and outputs including exacerbation rates, costs (2017 CAD), quality-adjusted life years (QALYs) gained and incremental cost effectiveness ratio (ICER) per QALY. Results: Compared with FF/VI, FF/UMEC/VI treatment resulted in fewer moderate and severe exacerbations (10.52 and 3.38 vs 11.13 and 3.48), mean (95% CI) incremental costs and QALYs of $2,598 ($2,010, $3,268) and 0.13 (0.09, 0.18), and an ICER of $19,649 per QALY ($15,406, $26,454). The probability of FF/UMEC/VI being cost-effective vs FF/VI was 100% at a willingness-to-pay threshold of $50,000 per QALY. Results were most sensitive to time horizon, and efficacy of treatment post-discontinuation. Conclusions: FF/UMEC/VI was predicted to improve health outcomes and to be a cost-effective option for treatment of moderate/severe COPD compared with FF/VI, in Canada.', 'externalIds': {'MAG': 2905859332.0, 'DOI': '10.1183/13993003.CONGRESS-2018.PA3154', 'CorpusId': 81393402}, 'label': 0}\n",
      "{'paperId': '89d3ddcfb237d68b55dbc1bb38fa0addd0ba9e74', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/89d3ddcfb237d68b55dbc1bb38fa0addd0ba9e74', 'title': 'Unintentional Pediatric Poisoning Exposures in an Emergency Department', 'abstract': 'Supplemental digital content is available in the text. Objectives The purpose of this study is to describe the demographics and clinical characteristics of patients referred to a pediatric emergency department (ED) for unintentional poisoning exposures by a poison control center (PCC) compared with patients/caregivers who self-refer. Methods The electronic data warehouse at a pediatric hospital was queried from October 1, 2014, to September 30, 2015, for unintentional poisoning-related ED visits and subsequent inpatient admissions. Eligible patients aged 18 years and younger were identified by International Classification of Diseases, Ninth Revision, Clinical Modification codes for pharmaceuticals, non-pharmaceuticalchemicals, fumes/vapors, foreign bodies, adverse food reactions, food poisoning, and bites/stings. Referral classification (PCC referral vs self-refer) was determined by PCC and hospital medical records. Descriptive statistics were used to characterize the patient demographics and ED visits by referral classification and age group. Simple and multiple logistic regression models examined the individual and combined impact of demographic and clinical characteristics on self-referral. Results Of the 705 patients identified, 84.4% presented as caregiver/self-referred compared with PCC-referred. As compared with those who self-referred, a higher percentage of patients who contacted the PCC before ED presentation were white (93.9% [89.4\\x9698.2%] vs 83.8% [80.7\\x9686.7%]) and had commercial insurance (62.7% [51.5\\x9669.5%] vs 53.0% [48.9\\x9657.0%]). Pharmaceutical (71.9%) and chemical (14.0%) exposures were the most common exposure types for PCC-referred patients whereas foreign bodies (54.3%) were the most common for self-referred patients. The largest predictors of self-referral were age, insurance, and exposure type. Conclusions Among patients presenting at 1 pediatric ED, disparities with PCC utilization exist among age groups, racial identification, and poison exposure type. Educational outreach interventions are needed to ensure optimal use of the PCC services by patients, caregivers, and health care professionals.', 'externalIds': {'MAG': 3011112299.0, 'DOI': '10.1097/PEC.0000000000002059', 'CorpusId': 212640457, 'PubMed': 32149986.0}, 'label': 0}\n",
      "{'paperId': '5755686983c9dee0167eb6cf79c3b3ae18dc8b26', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/5755686983c9dee0167eb6cf79c3b3ae18dc8b26', 'title': 'Multimodal Source Imaging: Basic Methods, Signal Processing Techniques, and Applications', 'abstract': 'Multimodal source imaging is an emerging field in biomedical engineering. Its central goal is to combine different imaging modalities in a single model or data representation, such that the combination provides an enhanced insight into the underlying physiological organ, compared to each modality separately. It requires advanced signal acquisition and processing techniques and has applications in cognitive neuroscience, clinical neuroscience and electrocardiology. Therefore, it belongs to the heart of biomedical engineering.', 'externalIds': {'DBLP': 'journals/tbe/HuiskampOM16', 'CorpusId': 42976702, 'PubMed': 27875124.0}, 'label': 0}\n",
      "{'paperId': 'bab4804ccdf79a74967282d2abebc330e7d2cc99', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/bab4804ccdf79a74967282d2abebc330e7d2cc99', 'title': 'The Prevalence of Drug-Resistant Tuberculosis in Mainland China: An Updated Systematic Review and Meta-Analysis', 'abstract': 'Background In recent years, drug resistant tuberculosis (DR-TB) particularly the emergence of multi-drug-resistant tuberculosis (MDR-TB) has become a major public health issue. The most recent study regarding the prevalence of drug-resistant tuberculosis in mainland China was a meta-analysis published in 2011, and the subjects from the included studies were mostly enrolled before 2008, thus making it now obsolete. Current data on the national prevalence of DR-TB is needed. This review aims to provide a comprehensive and up-to-date assessment of the status of DR-TB epidemic in mainland China. Methods A systematic review and meta-analysis of studies regarding the prevalence of drug-resistant tuberculosis in mainland China was performed. Pubmed/MEDLINE, EMBASE, the Cochrane central database, the Chinese Biomedical Literature Database and the China National Knowledge Infrastructure Database were searched for studies relevant to drug-resistant tuberculosis that were published between January 1, 2012 and May 18, 2015. Comprehensive Meta-Analysis (V2.2, Biostat) software was used to analyse the data. Results A total of fifty-nine articles, published from 2012 to 2015, were included in our review. The result of this meta-analysis demonstrated that among new cases, the rate of resistance to any drug was 20.1% (18.0%\\x9622.3%; n/N = 7203/34314) and among retreatment cases, the rate was 49.8% (46.0%\\x9653.6%; n/N = 4155/8291). Multi-drug resistance among new and retreatment cases was 4.8% (4.0%\\x965.7%; n/N = 2300/42946) and 26.3% (23.1%\\x9629.7%; n/N = 3125/11589) respectively. The results were significantly heterogeneous (p<0.001, I2 tests). Resistance to isoniazid was the most common resistance observed, and HRSE (H: isoniazid; R: rifampicin; S: streptomycin; E: ethambutol) was the most common form for MDR among both new and retreatment cases. Different drug resistance patterns were found by subgroup analysis according to geographic areas, subject enrolment time, and methods of drug susceptibility test (DST). Conclusions The prevalence of resistance to any drug evidently dropped for both new and retreatment cases, and multi-drug resistance declined among new cases but became more prevalent among retreatment cases compared to the data before 2008. Therefore, drug-resistant tuberculosis, particularly multi-drug-resistant tuberculosis among retreatment TB cases is a public health issue in China that requires a constant attention in order to prevent increase in MDR-TB cases.', 'externalIds': {'MAG': 2264877886.0, 'PubMedCentral': 4747587.0, 'DOI': '10.1371/journal.pone.0148041', 'CorpusId': 15113732, 'PubMed': 26859846.0}, 'label': 0}\n",
      "{'paperId': '9f4d85dcdd6cf34b0468372cd7b5cd39629727c4', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/9f4d85dcdd6cf34b0468372cd7b5cd39629727c4', 'title': 'Multilingual Multi-modal Embeddings for Natural Language Processing', 'abstract': 'We propose a novel discriminative model that learns embeddings from multilingual and multi-modal data, meaning that our model can take advantage of images and descriptions in multiple languages to improve embedding quality. To that end, we introduce a modification of a pairwise contrastive estimation optimisation function as our training objective. We evaluate our embeddings on an image-sentence ranking (ISR), a semantic textual similarity (STS), and a neural machine translation (NMT) task. We find that the additional multilingual signals lead to improvements on both the ISR and STS tasks, and the discriminative cost can also be used in re-ranking $n$-best lists produced by NMT models, yielding strong improvements.', 'externalIds': {'MAG': 2592831379.0, 'DBLP': 'journals/corr/CalixtoLC17a', 'CorpusId': 12152396, 'ArXiv': 1702.01101}, 'label': 0}\n",
      "{'paperId': 'a8a4867ae7b54e6dba3cb5e826ecd4ef83460c8f', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/a8a4867ae7b54e6dba3cb5e826ecd4ef83460c8f', 'title': 'Morphological Changes, Antibacterial Activity, and Cytotoxicity Characterization of Hydrothermally Synthesized Metal Ions-Incorporated Nanoapatites for Biomedical Application', 'abstract': 'The objective of this study was to prepare hydroxyapatite (HA) with potential antibacterial activity against gram-negative and gram-positive bacteria by incorporating different atomic ratios of Cu2+ (0.1\\x961.0%), Mg2+ (1.0\\x967.0%), and Zn2+ (1.0\\x967.0%) to theoretically replace Ca2+ ions during the hydrothermal synthesis of grown precipitated HA nanorods. This study highlights the role of comparing different metal ions on synthetic nanoapatite in regulating the antibacterial properties and toxicity. The comparisons between infrared spectra and between diffractograms have confirmed that metal ions do not affect the formation of HA phases. The results show that after doped Cu2+, Mg2+, and Zn2+ ions replace Ca2+, the ionic radius is almost the same, but significantly smaller than that of the original Ca2+ ions, and the substitution effect causes the lattice distance to change, resulting in crystal structure distortion and reducing crystallinity. The reduction in the length of the nanopatites after the incorporation of Cu2+, Mg2+, and Zn2+ ions confirmed that the metal ions were mainly substituted during the growth of the rod-shape nanoapatite Ca2+ distributed along the longitudinal site. The antibacterial results show that nanoapatite containing Cu2+ (0.1%), Mg2+ (3%), and Zn2+ (5\\x967%) has obvious and higher antibacterial activity against gram-positive bacteria Staphylococcus aureus within 2 days. The antibacterial effect against the gram-negative bacillus Escherichia coli is not as pronounced as against Staphylococcus aureus. The antibacterial effect of Cu2+ substituted Ca2+ with an atomic ratio of 0.1~1.0% is even better than that of Mg2+- and Zn2+- doped with 1~7% groups. In terms of cytotoxicity, nanoapatites with Cu2+ (~0.2%) exhibit cytotoxicity, whereas Mg2+- (1\\x965%) and Zn2+- (~1%) doped nanoapatites are biocompatible at low concentrations but become cytotoxic as ionic concentration increases. The results show that the hydrothermally synthesized nanoapatite combined with Cu2+ (0.2%), Mg2+ (3%), and Zn2+ (3%) exhibits low toxicity and high antibacterial activity, which provides a good prospect for bypassing antibiotics for future biomedical applications.', 'externalIds': {'PubMedCentral': 9315733.0, 'DOI': '10.3390/ph15070885', 'CorpusId': 250654017, 'PubMed': 35890183.0}, 'label': 0}\n",
      "{'paperId': '4ab43fdeaebdf64d813b7e1df3f282b3e1f62236', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/4ab43fdeaebdf64d813b7e1df3f282b3e1f62236', 'title': 'Intro to IE: Project Proposal', 'abstract': 'I will be conducting a novel application of entity recognition, entity typing, and relation mining for the task of classifying moral rhetoric in a large corpus of annotated Tweets. In a recent paper, Lin et al. (2017) conduct \\x93Entity linking\" to supplement established document classification methods to predict a Tweet\\x92s five moral labels. These moral labels, which are theoretically derived from Moral Foundations Theory (see Graham et al., 2013, for a synopsis), are a set of binary labels that apply at the document level. Each label, when active, signifies that a given \\x93moral concern\" is used by the writer of the particular text. There are five labels, corresponding to the five moral foundations: fairness, care, authority, loyalty, and purity. In Lin et al. (2017), the authors link entities in Tweets and link them to an external Knowledge Base (Wikipedia) and append the text of the linked entities\\x92 abstracts to the document. They achieve superior performance using this method, in comparison to purely text-based methods. In my project, I propose to improve this classification in two ways: (1) In terms of classification performance; (2) In terms of explainability. In this field, a key element of any predictive system is the ability to provide \\x93reasoning\" for each prediction, or a \\x93trail of evidence\" which influences the learner\\x92s decision. Such information can facilitate collaboration between NLP researchers and domain experts, allowing the latter to design schema for future IE given the evidence provided to them in text classification. The method I will be using for classification is an attention-based LSTM (e.g. Wang et al., 2016). To form a coherent set of features which offers explainability in the form of entities (and their types) rather than just words, I propose to conduct distantly-supervised entity recognition and typing in the style of Ren et al. (2015). This will supplement traditional features in text classification (word and character n-grams, word embeddings, syntactic feature mining). In terms of the knowledge bases I will use to conduct distant supervision of the entity recognition and typing, I will use both established (i.e. Wikipedia) KB as well as less traditional, more specialized schema. This latter category of KB include actorand eventontologies in the political science community, notably CAMEO (Schrodt et al., 2008). Additionally, I have been working on developing a schema for structuring \\x93political objects\", including persons, groups, events, and concepts, which will be applied at later stages of the project, time allowing. The data I am using for this project is a set of roughly 30,000 annotated Tweets. Each Tweet has multiple annotations for each of the 5 moral foundations. Evaluation will be done by comparing classification metrics (precision, recall, F-1, and accuracy) between several baselines and the proposed method. Those methods will be:', 'externalIds': {'CorpusId': 227536557}, 'label': 0}\n",
      "{'paperId': '3cfbcca8809b97bc0d27efb8442fb9bf5732efa7', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/3cfbcca8809b97bc0d27efb8442fb9bf5732efa7', 'title': 'O exercício físico como potencial redutor da cardiotoxicidade induzida por tratamentos antineoplásicos: revisão sistemática', 'abstract': 'Introducao: Atualmente o tratamento oncologico atingiu um patamar de alta fidedignidade no diagnostico e alta qualidade no tratamento, entretanto as comorbidades associadas ao tratamento se tornaram um problema para os sobreviventes. Dentre essas comorbidades a cardiotoxicidade e muito temida. O exercicio fisico vem se mostrando uma ferramenta eficaz no combate das comorbidades e os efeitos deleterios do tratamento antineoplasico. Objetivo: Essa revisao teve o intuito de realizar um levantamento da literatura sobre os possiveis efeitos beneficos do exercicio fisico para reduzir os efeitos deleterios da cardiotoxicidade. Metodos: As bases de dados pesquisadas foram Pubmed/Medline, Scielo e PEDro. Os descritores selecionados foram \\x93exercise\\x94, \\x93cardiotoxicity\\x94 e \\x93neoplasm\\x94 assim como o descritor nao controlado \\x93cancer\\x94 e as respectivas traducoes para o portugues. Resultados: Foram selecionados quatro artigos para fazer parte da revisao, publicados entre os anos de 2007 a 2013. Todos os artigos foram realizados na populacao com câncer de mama; dentre os resultados encontrados os diversos autores observaram efeitos positivos no VO 2 max, frequencia cardiaca de repouso, perfusao sanguinea tumoral, pressao arterial sistolica. Discussao: Os resultados encontrados vao ao encontro de outras revisoes sistematicas publicadas, que estudaram os efeitos do exercicio fisico nas variaveis cardiovasculares apos tratamento antineoplasico; estudos em modelos animais tambem vem mostrando que o exercicio fisico pode ser uma ferramenta eficaz no combate a cardiotoxicidade. Conclusao: E possivel identificar que o exercicio fisico se apresenta como potencial benfeitor no combate aos efeitos deleterios da cardiotoxicidade, alem de se demonstrar viavel e seguro, quando estruturado por profissionais da saude. ABSTRACT Physical exercise as potential reducer of cardiotoxicity induced by antineoplastic treatments: systematic review Introduction: Currently the oncological treatment has reached a new level of high reliability in diagnosis and high-quality treatment, however the comorbidities associated with the treatment have become a problem for the survivors. Among these comorbidities, cardiotoxicity is one of the most dangerous. Exercise has proven an effective tool in the struggle against the comorbidities and the deleterious effects of the anticancer treatment. Objective: This review aimed to conduct a survey in the literature about possible beneficial effects of physical exercise in reducing the deleterious effects of cardiotoxicity. Methods: The databases searched were PubMed/Medline, Scielo and PEDro. The selected keywords were \"exercise\", \"cardiotoxicity\", \"neoplasm\" and the uncontrolled keyword \"cancer\" and their respective translations to Portuguese. Results: Four articles were selected to be part of this review published between the years of 2007 and 2013. All studies were performed in the population with breast cancer; among the findings the authors observed positive effects on VO2peak, resting heart rate, tumor blood perfusion, systolic blood pressure. Discussion: The results are in line with other published systematic reviews that studied the effects of exercise on cardiovascular parameters after neoplasic treatment. Studies in animal models also show that exercise can be an effective tool to mitigate deleterious effects of cardiotoxicity. Conclusion: It is possible to identify that physical exercise can be presented as a potential benefactor against the harmful effects of cardiotoxicity, Exercise is also viable and secure when prescribed by health professionals.', 'externalIds': {'MAG': 2763727691.0, 'CorpusId': 57775291}, 'label': 0}\n",
      "{'paperId': 'b9f229a7491924404db36e91fcbd76449f3cec19', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/b9f229a7491924404db36e91fcbd76449f3cec19', 'title': 'Fine-Grained Emotional Paraphrasing along Emotion Gradients', 'abstract': 'Paraphrase generation, a.k.a. paraphrasing, is a common and important task in natural language processing. Emotional paraphrasing, which changes the emotion embodied in a piece of text while preserving its meaning, has many potential applications, e.g., moderating online dialogues and preventing cyberbullying. We introduce a new task of fine-grained emotional paraphrasing along emotion gradients, that is, altering the emotional intensities of the paraphrases in fine grain following smooth variations in affective dimensions while preserving the meanings of the originals. We propose a framework for addressing this task by fine-tuning text-to-text Transformers through multi-task training. We enhance several widely used paraphrasing corpus by annotating the input and target texts with their fine-grained emotion labels. With these labels, fine-tuning text-to-text Transformers on these corpus entails multi-task training. Evaluations of the fine-tuned Transformers on separate test sets show that including fine-grained emotion labels in the paraphrase task significantly improve the chance of obtaining high-quality paraphrases of the desired emotions, i.e., more than doubling the number of exact matches of desired emotions while achieving consistently better scores in paraphrase metrics such as BLEU, ROGUE, and METEOR.', 'externalIds': {'DBLP': 'journals/corr/abs-2212-03297', 'DOI': '10.48550/arXiv.2212.03297', 'CorpusId': 254366768, 'ArXiv': 2212.03297}, 'label': 0}\n",
      "{'paperId': 'b88e355e507ca374432c0c1be2a02dcf9f2121fb', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/b88e355e507ca374432c0c1be2a02dcf9f2121fb', 'title': 'Recognizing Characters From Google Street View Images', 'abstract': 'Recognizing arbitrary characters in unconstrained natural photographs is a hard problem. In this paper, we address an equally hard sub-problem in this domain-recognizing arbitrary single characters from Street View images. Similar problems, such as recognizing arbitrary multi-digits in street view images [Goodfellow, et al., 2013] and Recognizing Text in Google Street View Image [Lintern, et all., 2008], were well-investigated with decent solutions including localization, segmentation, image feature generation as well as applying machine learning models. In this paper, we propose a unified approach that integrates both localization and segmentation via the use of convolutional neural networks that operates directly on the image pixels. We have experimented with two main types of convolutional neural networks-a thin deep network like Google Network proposed in ILSVRC-2012 competition and a flat shallow network like Alex Network proposed in ILSVRC-2012 competition. We find that the performance of neural network solution works much better than the traditional approach of classification based on image features, while the performance of this approach increases little with the depth of the convolutional network. We evaluate this approach on the publicly available Chars74K dataset and achieve over 84% accuracy in recognizing individual characters in the street view images. Our work could serve as the first step for recognizing a sequence of characters of the text in natural scenes.', 'externalIds': {'CorpusId': 14721987}, 'label': 0}\n",
      "{'paperId': '517ad44dc152d73ac2d4a1e371b10c0a70fbaf4f', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/517ad44dc152d73ac2d4a1e371b10c0a70fbaf4f', 'title': 'All outputs in CentAUR are protected by Intellectual Property', 'abstract': 'Mamais, A., Chia, R., Beilina, A., Hauser, D. N., Hall, C., Lewis, P. A., Cookson, M. R. and Bandopadhyay, R. (2014) Arsenite stress down\\xadregulates phosphorylation and 14\\xad3\\xad3 binding of leucine\\xadrich repeat kinase 2 (LRRK2), promoting self\\xadassociation and cellular redistribution. Journal of biological chemistry, 289 (31). pp. 21386\\xad21400. ISSN 1083\\xad 351X doi: https://doi.org/10.1074/jbc.M113.528463 Available at http://centaur.reading.ac.uk/77591/', 'externalIds': {'CorpusId': 265213877}, 'label': 0}\n",
      "{'paperId': '09254d9a5994bc8364751ab83bc81df06763f986', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/09254d9a5994bc8364751ab83bc81df06763f986', 'title': 'Haloarchaea and the Formation of Gas Vesicles', 'abstract': 'Halophilic Archaea (Haloarchaea) thrive in salterns containing sodium chloride concentrations up to saturation. Many Haloarchaea possess genes encoding gas vesicles, but only a few species, such as Halobacterium salinarum and Haloferax mediterranei, produce these gas-filled, proteinaceous nanocompartments. Gas vesicles increase the buoyancy of cells and enable them to migrate vertically in the water body to regions with optimal conditions. Their synthesis depends on environmental factors, such as light, oxygen supply, temperature and salt concentration. Fourteen gas vesicle protein (gvp) genes are involved in their formation, and regulation of gvp gene expression occurs at the level of transcription, including the two regulatory proteins, GvpD and GvpE, but also at the level of translation. The gas vesicle wall is solely formed of proteins with the two major components, GvpA and GvpC, and seven additional accessory proteins are also involved. Except for GvpI and GvpH, all of these are required to form the gas permeable wall. The applications of gas vesicles include their use as an antigen presenter for viral or pathogen proteins, but also as a stable ultrasonic reporter for biomedical purposes.', 'externalIds': {'MAG': 2009997050.0, 'PubMedCentral': 4390858.0, 'DOI': '10.3390/life5010385', 'CorpusId': 6640836, 'PubMed': 25648404.0}, 'label': 0}\n",
      "{'paperId': '0bdbe3462006edba37c2a883e326025f84c98610', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/0bdbe3462006edba37c2a883e326025f84c98610', 'title': 'First Report of Cucumber mosaic virus Associated with Capsicum chinense var. Scotch Bonnet in Florida.', 'abstract': \"Scotch bonnet (Capsicum chinense) is a tropical hot pepper variety that is grown in South America, the Caribbean Islands, and in Florida, and is an important cash crop. In Florida, scotch bonnet is grown on ~100 acres annually. Virus-like leaf symptoms including mosaic and yellow mottling were observed on scotch bonnet plants in a field at Quincy, FL, with a disease incidence of ~5%. Two symptomatic and one non-symptomatic plant sample were collected from this field for identification of the causal agent associated with the symptoms. Viral inclusion assays (2) of the epidermal tissues of the symptomatic scotch bonnet samples using Azure A stain indicated the presence of spherical aggregates of crystalline inclusion bodies. Testing of the symptomatic samples using lateral flow immunoassays (Immunostrips, Agdia, Elkhart, IN) specific to Cucumber mosaic virus (CMV), Potato virus Y (PVY), Pepper mild mottle virus (PMMoV), Tobacco mosaic virus (TMV), Zucchini yellow mosaic virus (ZYMV), and Papaya ringspot virus (PRSV), showed a positive reaction only to CMV. The sap from an infected leaf sample ground in 0.01 M Sorensons phosphate buffer (pH 7.0) was used to mechanically inoculate one healthy scotch bonnet plant (tested negative for CMV with Immunostrip) at the 2- to 3-leaf stage. The inoculated plant developed mild mosaic and mottling symptoms 12 to 14 days post inoculation. The presence of CMV in the mechanically inoculated plant was further verified using CMV Immunostrips. Total RNA was extracted (RNeasy Plant Mini Kit, Qiagen, Valencia, CA) from the previously collected two symptomatic and one non-symptomatic scotch bonnet samples. The samples were subjected to reverse-transcription (RT)-PCR assays using SuperScript III One-Step RT-PCR System (Invitrogen, Life Technologies, Grand Island, NY), and using multiplex RT-PCR primer sets (1). The primers were designed to differentiate the CMV subgroup I and II, targeting the partial coat protein gene and the 3'UTR. The RT-PCR assays using the multiplex primers produced an amplicon of 590 bp, with the CMV subgroup I primers. The RT-PCR product was only amplified from the symptomatic leaf samples. The obtained amplicons were gel eluted, and directly sequenced bi-directionally (GenBank Accession Nos. KF805389 and KF805390). BLAST analysis of these sequences showed 97 to 98% nucleotide identities with the CMV isolates in the NCBI database. The isolates collected in Florida exhibited highest identity (98%) with the CMV isolate from tomato (DQ302718). These results revealed the association of CMV subgroup I with symptomatic scotch bonnet leaf samples. Although CMV has been reported from scotch bonnet, this is the first report of its occurrence in Florida. References: (1) S. Chen et al. Acta Biochim Biophys Sin. 43:465, 2011. (2) R. G. Christie and J. R. Edwardson. Plant Dis. 70:273, 1986.\", 'externalIds': {'MAG': 2016621794.0, 'DOI': '10.1094/PDIS-12-13-1276-PDN', 'CorpusId': 73414741, 'PubMed': 30708920.0}, 'label': 0}\n",
      "{'paperId': '318a3f40e6384729e371d046a4738cea72d7075d', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/318a3f40e6384729e371d046a4738cea72d7075d', 'title': 'Humpty Dumpty: Controlling Word Meanings via Corpus Poisoning', 'abstract': 'Word embeddings, i.e., low-dimensional vector representations such as GloVe and SGNS, encode word \"meaning\" in the sense that distances between words\\x92 vectors correspond to their semantic proximity. This enables transfer learning of semantics for a variety of natural language processing tasks.Word embeddings are typically trained on large public corpora such as Wikipedia or Twitter. We demonstrate that an attacker who can modify the corpus on which the embedding is trained can control the \"meaning\" of new and existing words by changing their locations in the embedding space. We develop an explicit expression over corpus features that serves as a proxy for distance between words and establish a causative relationship between its values and embedding distances. We then show how to use this relationship for two adversarial objectives: (1) make a word a top-ranked neighbor of another word, and (2) move a word from one semantic cluster to another.An attack on the embedding can affect diverse downstream tasks, demonstrating for the first time the power of data poisoning in transfer learning scenarios. We use this attack to manipulate query expansion in information retrieval systems such as resume search, make certain names more or less visible to named entity recognition models, and cause new words to be translated to a particular target word regardless of the language. Finally, we show how the attacker can generate linguistically likely corpus modifications, thus fooling defenses that attempt to filter implausible sentences from the corpus using a language model.', 'externalIds': {'MAG': 3046527848.0, 'DBLP': 'journals/corr/abs-2001-04935', 'DOI': '10.1109/SP40000.2020.00115', 'CorpusId': 210180638, 'ArXiv': 2001.04935}, 'label': 0}\n",
      "{'paperId': 'be5a6b1b2874dd5c06473530931ae7c5221e4ed1', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/be5a6b1b2874dd5c06473530931ae7c5221e4ed1', 'title': 'The Prospects for Psychosomatic Medicine: Selected Topics1', 'abstract': 'It is exactly 27 years ago since I first had the honour of presenting a paper to this Society\\x97one that has meant much to me professionally and socially. Dr. Rose\\'s generous invitation to speak to you was, therefore, most gratifying. He asked me to peer uncertainly into the future\\x97a perilous adventure. I shall not try to define Psychosomatic Medicine, nor the future for you. We could all agree that Psychosomatic Medicine is as von Krehl (1) and Balint (2) have called it, a \"patient-oriented\" not a \"diseaseoriented\" medicine. Some of you might even agree that conceptually it contains the seeds of a theory of health, illness, and disease alternative to the traditional biomedical theory of disease. To call this other theory \"biopsychosocial\" rather than psychosomatic, may well be an improvement: This compound adjective forces us to pay renewed attention to critical social factors (such as socio-', 'externalIds': {'MAG': 2327105912.0, 'DOI': '10.1097/00006842-198212000-00002', 'CorpusId': 31210697, 'PubMed': 6131466.0}, 'label': 0}\n",
      "{'paperId': '1fa424e6def7edce2525143f5f9b9ca29e9d07b9', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/1fa424e6def7edce2525143f5f9b9ca29e9d07b9', 'title': 'Going Forward : Increasing the Accessibility of Imaging MS 1 2', 'abstract': '2 Liam A. McDonnell*, Ron M.A. Heeren, Per E. Andrén, Markus Stoeckli, Garry C. Corthals, 3 4 5 1 Biomolecular Mass Spectrometry Unit, Department of Parasitology, Leiden University Medical Center, 6 Leiden, the Netherlands 7 2 FOM Institute AMOLF, Science Park 104, Amsterdam, the Netherlands 8 3 Department of Pharmaceutical Biosciences, Medical Mass Spectrometry, Uppsala University, Uppsala, 9 Sweden 10 4 Novartis Institutes of BioMedical Research, Analytical & Imaging Sciences, Basel, Switzerland 11 5 Turku Centre for Biotechnology, University of Turku & Åbo Akademi University, Turku, Finland 12 13 Running title: improving imaging MS accessibility 14 15', 'externalIds': {'CorpusId': 199598496}, 'label': 0}\n",
      "{'paperId': '19ef79992e71a374d59f8be3feb93125fd7815d9', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/19ef79992e71a374d59f8be3feb93125fd7815d9', 'title': 'Non-uniform patch sampling with deep convolutional neural networks for white matter hyperintensity segmentation', 'abstract': 'Convolutional neural networks (CNN) have been widely used for visual recognition tasks including semantic segmentation of images. While the existing methods consider uniformly sampled single-or multi-scale patches from the neighborhood of each voxel, this approach might be sub-optimal as it captures and processes unnecessary details far away from the center of the patch. We instead propose to train CNNs with non-uniformly sampled patches that allow a wider extent for the sampled patches. This results in more captured contextual information, which is in particular of interest for biomedical image analysis, where the anatomical location of imaging features are often crucial. We evaluate and compare this strategy for white matter hyperintensity segmentation on a test set of 46 MRI scans. We show that the proposed method not only outperforms identical CNNs with uniform patches of the same size (0.780 Dice coefficient compared to 0.736), but also gets very close to the performance of an independent human expert (0.796 Dice coefficient).', 'externalIds': {'MAG': 2422852360.0, 'DBLP': 'conf/isbi/GhafoorianKHULM16', 'DOI': '10.1109/ISBI.2016.7493532', 'CorpusId': 24840324}, 'label': 0}\n",
      "{'paperId': 'c2dea3bebf30d572ced9b460030d2b279600ba0a', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/c2dea3bebf30d572ced9b460030d2b279600ba0a', 'title': 'Ambient affiliation, misinformation and moral panic: Negotiating social bonds in a YouTube internet hoax', 'abstract': 'Deceptive communication and misinformation are crucial issues that are currently having a significant impact on social life. Parallel to the important work of identifying misinformation on digital platforms is understanding why such material proliferates. One approach to answering this question is to attempt to understand the values that are being targeted by misinformation as a means of interpreting the underlying social bonds that are at stake. This study examines the kinds of social bonds that are communed around and contested in a corpus of YouTube video comments about the viral internet hoax \\x91The Momo Challenge\\x92. A social semiotic approach to \\x91ambient affiliation\\x92 (Zappavigna, 2011) is used to investigate how these bonds are negotiated in this digital discourse. This approach involves establishing the types of personae (for instance Moralisers, Myth Spreaders and Connoisseurs) who were negotiating meaning in the comments on the basis of the values that they recurrently shared, deferred or disputed. The analysis suggests that, in addition to concern over whether Momo was real and dangerous, there was a deeper moral panic about parenting in the digital age and the legitimacy of institutions such as schools and media as brokers of knowledge.', 'externalIds': {'MAG': 3128606397.0, 'DOI': '10.1177/1750481321989838', 'CorpusId': 233907285}, 'label': 0}\n",
      "{'paperId': 'a46fe99206eb58bbf9d52a4c2dc3c4cb515e3227', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/a46fe99206eb58bbf9d52a4c2dc3c4cb515e3227', 'title': 'Proceedings of the 1st ACM international workshop on Multimedia indexing and information retrieval for healthcare', 'abstract': 'It is our great pleasure to welcome you to the 2013 ACM MM Workshop on Multimedia Indexing and Information Retrieval for Healthcare -- MIIRH\\'13. This is the first workshop on Multimedia Information Indexing and Retrieval for Healthcare and is intended to establish a platform for the continued discussion of key research issues in multimedia for healthcare, remote monitoring and treatment. Multimodal monitoring for health can take place at home, but should be discreet, unobtrusive and personalized. Theoretical, i.e. research-oriented and practical, application-specific issues related to the extraction of lifestyle, behavior and health information from multimodal data will be examined. The setup of smart homes has become of great interest lately, as the latter need to ensure accurate, reliable, discreet and cost-efficient measurements, involving, among others, privacy protection and appropriate sensor placement. Marketing of multimodal remote monitoring options also needs to be examined carefully, as independent living at home, smart homes and remote care are forecast to gain importance in years to come. Multimedia Indexing and Retrieval research is now being oriented towards this application domain of primarily importance for the society. Workshop papers and presentations will focus on the analysis of multimodal data to obtain information pertinent to healthcare problems and also examine remote monitoring solutions. Personalization, unobtrusiveness, accuracy of analysis results, data storage, retrieval, transmission, marketability and privacy concerns are among the many topics that will be discussed. \\n \\nThe workshop will provide a forum for researchers from all over the world to share information on their latest investigations on multimedia information retrieval and indexing with healthcare applications. MIIRH is held as a one day workshop with presentations from 9:00 am to 5:00 pm with breaks and a 1-hour lunch period. \\n \\nThe call for papers attracted many submissions from Asia, Europe, Australia and the Americas. The program committee accepted 10 papers that cover a variety of topics, including: recognition of daily living activities, analysis of therapy exercises, fall detection, context aware recommendation, experience sharing, and medical image retrieval. In addition to paper presentations, posters and demos, MIIRH will feature an invited keynote talk by Prof. Linda Shapiro on \"Image Analysis for Biomedical and Healthcare Applications\" as well as an invited talk by Prof. Jean-Francois Dartigues on \"Dementia and Dependency: a Major Challenge for the 21st century\". We hope that these proceedings will serve as a valuable reference for healthcarerelated multimedia indexing and retrieval researchers and developers.', 'externalIds': {'MAG': 2612289276.0, 'CorpusId': 67273795}, 'label': 0}\n",
      "{'paperId': 'fe893821e4e15a99bf5716f7ce615f4b73137a73', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/fe893821e4e15a99bf5716f7ce615f4b73137a73', 'title': 'Drug Carriers', 'abstract': 'In recent years, there has been an exponential interest in the development of novel drug delivery systems using drug carriers. Drug carriers offer significant advantages over the conventional drug delivery systems in terms of high stability, high specificity, high drug loading capacity, controlled release of drug and ability to deliver both hydrophilic and hydrophobic drugs. As a result of their unique behaviors, drug carriers have a wide range of biomedical and industrial applications. Nanospheres are associated with a lot of benefits such as ease of administration to target sites, reduction in toxicity level and ease of passage via the capillary vessels. Hydrogel nanoparticles are useful in the treatment of inflammatory diseases, as bioresponsive hydrogels in drug delivery system and as a carrier in controlled drug delivery system.\\xa0 Carbon nanotubes have a large surface area which has the ability to adsorb or conjugate with a wide variety of therapeutic and diagnostic agents. They are useful in the areas of gene delivery, tissue regeneration and biosensor diagnosis. Liposomes are known to target a drug to a specific site. They entrap drugs which are released for subsequent absorption. They are used to achieve active targeting, increase efficacy and therapeutic index of drugs. Niosomes improve the solubility and oral bioavailability of poorly soluble drugs. They protect drugs from biological environment, increase the stability of entrapped drugs and they can easily reach the site of action. Aquasomes are nanoparticulate carriers that can be characterized for structural analysis. They preserve conformational integrity and biochemical stability of drugs. Ethosomes are noninvasive delivery carriers that enable drugs to reach the deep skin layers and the systemic circulation.\\xa0 They contain phospholipids which could be in form of phosphatidyl choline (PC), hydrogenated PC, phosphatidic acid (PA), Phosphatidyl serine (PS) and phosphatidyl inositol (PI). Ethosomes are known to increase skin permeation of drugs, improve biological activity and pharmacodynamics profile of drugs. This review aims to emphasize the importance of drug carriers in drug delivery system, and applications of drug carriers in various areas of research, technology and treatment.\\n\\xa0', 'externalIds': {'DOI': '10.54117/jcbr.v2i1.3', 'CorpusId': 247259792}, 'label': 0}\n",
      "{'paperId': '33db6eaf4f93d1de31e32a2b3d2ed1d9c4cf6f2c', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/33db6eaf4f93d1de31e32a2b3d2ed1d9c4cf6f2c', 'title': 'Collective Intelligence for Semantic and Knowledge Grid', 'abstract': 'Recently, grid computing has been regarded as the most promising paradigm to interconnect heterogeneous computing environments. Main goal of this grid computing paradigm is to share local but limited resources with others to solve very complex problems [Foster 2003]. Especially, semantics and knowledge are playing an important role of building an efficient grid platform to share information and knowledge with each other [de Roure et al. 2005]. A variety of domains, e.g., business [Zhen and Jiang 2008, Jung 2008], chemistry [Taylor et al. 2006], information retrieval [Jung 2007], and biomedical areas [Tsiknakis et al. 2008], have been attempting to employ this semantic grid platform. However, there are several hurdles that they have to overcome in common, e.g., semantic heterogeneity (e.g., inconsistency and conflict) between information sources on a grid. In order to efficiently deal with the hurdles and implement the semantic grid platform, there have been representative approaches, e.g., web services (S-OGSA [Corcho et al. 2006]), metadata, ontologies and reasoning. More particularly, collective intelligence is the latest buzzword to take into account how to find any opportunities to link individual intelligence as well as how to apply the collective intelligence to various problems. In this issue, we are focusing on the semantic and knowledge grid platforms (as well as distributed platforms) for building and exploiting collective intelligence. Main topics of interests are noted, as follows;', 'externalIds': {'MAG': 94616045.0, 'DBLP': 'journals/jucs/JungN08', 'CorpusId': 10330768}, 'label': 0}\n",
      "{'paperId': 'ad8b156f8d54e32e53d1a0bc02beb7f67fa8f062', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/ad8b156f8d54e32e53d1a0bc02beb7f67fa8f062', 'title': 'Recent Advances of Cell Membrane?Coated Nanomaterials for Biomedical Applications', 'abstract': 'Surface modification of nanomaterials is essential for their biomedical applications owing to their passive immune clearance and damage to reticuloendothelial systems. Recently, a cell membrane?coating technology has been proposed as an ideal approach to modify nanomaterials owing to its facile functionalized process and good biocompatibility for improving performances of synthetic nanomaterials. Here, recent advances of cell membrane?coated nanomaterials are reviewed based on the main biological functions of the cell membrane in living cells. An overview of the cell membrane is introduced to understand its functions and potential applications. Then, the applications of cell membrane?coated nanomaterials based on the functions of the cell membrane are summarized, including physical barrier with selective permeability and cellular communication via information transmission and reception processes. Finally, perspectives of biomedical applications and challenges about cell membrane?coated nanomaterials are discussed.', 'externalIds': {'MAG': 3047868968.0, 'DOI': '10.1002/adfm.202003559', 'CorpusId': 225386123}, 'label': 0}\n",
      "{'paperId': '547d0113d02dcf7d001f0e96c253d0b8d4c5dcaa', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/547d0113d02dcf7d001f0e96c253d0b8d4c5dcaa', 'title': 'The dynamic change of gene expression profiles of rats\\x92 benign prostate hyperplasia tissues after denervation of sympathetic nerve', 'abstract': 'Objective \\nTo investigate the dynamic change of gene expression profiles of rats\\x92 benign prostate hyperplasia (BPH) tissues after denervation of sympathetic nerve. \\n \\n \\nMethods \\nTwelve spontaneous hypertension rats (SHR), male, 29 weeks old, 3 for normal control (N), 9 were cut the adrenergic inferior epigastric innervation to prostate. Three N, 3 SHR 3 days after operation (D3), 3 D11 and 3 D21 were sacrificed and collected the ventral lobe of prostate for histopathological examination, RNA extraction, gene expression profiles microarray, real-time quantitative polymerase chain reaction (Real-time PCR) and bioinformatics analysis. \\n \\n \\nResults \\nThe smooth muscle in rats\\x92 BPH tissues presented a transient structure and function damage after losing the sympathetic innervations. Gene expression profiles microarray tests were finished successfully, their reliability were verified by the real-time PCR. Clustering analysis indicated that the number of up-regulated gene and down-regulated gene in gene set D3/N were 318, 117, D11/N were 192, 66 and D21/N were 44, 92, respectively. GO function and Pathway enrichment analysis indicated that these differentially expressed genes were involved in numerous molecular function, biological progress, cellular compartment and signal pathway, the numbers also decreased with the extension of time. The GO function and signal pathway were related with inflammation, immune response and cellular response to injure and stress at early stages, related with repairmen of tissue compartment and cellular function in late period. Most of the top ranked signal pathways at early stages had relationship with the activation of complement system, and genes involved were up-regulated. \\n \\n \\nConclusion \\nThe impact of denervation of sympathetic nerve for rats\\x92 BPH tissue (mainly smooth muscle) in molecular level also is transient, and the abnormal activation of complement system seems to play a important role in the serial molecular events. \\n \\n \\nKey words: \\nBenign prostate hyperplasia;\\xa0Denervation;\\xa0Sympathetic innervations;\\xa0Gene expression profile;\\xa0Bioinformatics analysis;\\xa0Rat', 'externalIds': {'MAG': 3032284908.0, 'DOI': '10.3760/CMA.J.ISSN.1001-9030.2019.05.036', 'CorpusId': 224064836}, 'label': 0}\n",
      "{'paperId': 'daa00a115de681d934db8048b8bef61485243046', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/daa00a115de681d934db8048b8bef61485243046', 'title': \"From Popperian science to normal science. Commentary on Sestini (2009) 'Epistemology and ethics of evidence-based medicine'.\", 'abstract': 'In \\x91Epistemology and ethics of evidence-based medicine: Putting goal-setting in the right place\\x92, Piersante Sestini argues that evidence-based medicine (EBM) is highly consistent with Karl Popper\\x92s philosophy of science, which famously demarcated science by the falsifiability criterion and highlighted for generations of scientists the inherent fallibility of scientific claims. In this commentary, I will demonstrate, contra Sestini, that Popper and EBM share only superficial similarity. Furthermore, Sestini\\x92s focus on the centrality that formulating the clinical question plays in evidence-based practice instead highlights EBM\\x92s compatibility with the Kuhnian picture of \\x91normal science\\x92. Despite Sestini\\x92s claim to find high compatibility between EBM and Popper\\x92s objective theory of conjectural knowledge [1], he illustrates only a thin allegiance between the two. Sestini finds Popperian influence in the EBM criterion that clinicians begin by \\x91formulating an answerable question\\x92. While an unanswerable question would certainly fall outside of the purview of Popperian science, it was the untestable hypothesis that interested Popper in his demarcation of science from pseudoscience. A hypothesis is considered scientific if it is testable, that is, falsifiable by way of a possible observational event that is incompatible with theoretical prediction [2]. All other theories, even those making empirical claims, are pseudo-science. For example, broad ideological theories, like Marx\\x92s theory of history and Freud\\x92s theory of psychoanalysis, make empirical claims about the world and have remarkable explanatory power (according to Marxists and Freudians), yet cannot be disconfirmed by singular observational events. The grandness of their claims, and constant supply of confirming evidence \\x96 \\x91a Marxist could not open a newspaper without finding on every page confirming evidence for his interpretation of history; not only in the news, but also in its presentation \\x96 which revealed the class bias of the paper \\x96 and especially of course in what the paper did not say\\x92 ([2], p. 46) \\x96 seemed to permit such discretion ([2], pp. 43\\x9677). Unlike the logical positivists\\x92 claim that nonscience is non-sense, Popper allowed such metaphysical speculation to be meaningful and informative. They were not, however, scientific claims [3]. Sestini also links the \\x91evidence-based\\x92 criterion \\x96 the evidence determines the answer to clinical problems \\x96 to Popper\\x92s demarcation of science: External clinical evidence both invalidates previously accepted diagnostic tests and treatments and replaces them with new ones that are more powerful, more accurate, more efficacious, and safer, which is as close as it could be to Popper\\x92s criterion of demarcation based on falsifiability [4]. Yet an accurate reading of Popper reveals that theories can only be falsified and not confirmed by any inductive evidence. The \\x91replacement\\x92 of old invalidated theories with new ones is merely conjectural. In a dramatic break from the common picture of science as an inductive process, Popper proposed that science progresses through a series of conjectures and refutations [2]. Scientists hold onto their conjectures until damning evidence falsifies them in a methodology of \\x91trial and the examination of error\\x92 ([1], p. 18). Once falsified, the conjecture is abandoned, a new one is proposed, and the effort at falsification is repeated. The growth of scientific knowledge, for Popper, results from an enlarging body of falsified knowledge claims. While Popper\\x92s account of science avoids the vexing \\x91problem of induction\\x92 for empiricism [5,6], critics have frequently argued that a theory of scientific reasoning devoid of theory confirmation is unworkable for actual scientific practice [7]. What is a Popperian biomedical researcher or doctor supposed to do when faced with competing solutions to a clinical problem \\x96 that is, two unfalsified claims? Popper is quite clear that we have no logical grounds for selecting one over the other. It is surprising that Popper is such a hero to scientists given how irrational he made theory choice. Yet Sestini\\x92s comment is also linked to the democratic tenor of the evidence-based programme. EBM was lauded in the early literature as an iconoclastic practice [8]. Much like Popper\\x92s critical science, evidence-based practitioners do not resist disconfirming evidence nor hold onto their theories dogmatically. Popper took this critical attitude even further by encouraging scientists to pursue actively disconfirming observational evidence in order to increase the robustness of their theories. This picture of the proper scientific attitude is hugely attractive. The Popperian scientist\\x92s character traits include creativity, critical thinking and openmindedness [2]. EBM, however, does not demand the critical scientist that Popper envisioned. EBM offers a detailed systematic approach to clinical problem solving that demands rule-following and compliance (albeit those rules may be reasonable!) rather than open-ended inquiry. A re-examination of Sestini\\x92s area of interest, the formulation of the clinical question in evidence-based practice, demonstrates this to be the case.', 'externalIds': {'MAG': 1509997342.0, 'DOI': '10.1111/j.1365-2753.2010.01389.x', 'CorpusId': 29929698, 'PubMed': 20367853.0}, 'label': 0}\n",
      "{'paperId': '3852a7981815f05f0a23e0710bbc7d6c52086ca3', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/3852a7981815f05f0a23e0710bbc7d6c52086ca3', 'title': 'and Jonathan Shear First-person Methodologies : What , Why , How ?', 'abstract': 'By first-person events we mean the lived experience associated with cognitive and mental events. Sometimes terms such as \\x91phenomenal consciousness\\x92 and even \\x91qualia\\x92 are also used, but it is natural to speak of \\x91conscious experience\\x92 or simply \\x91experience\\x92. These terms imply here that the process being studied (vision, pain, memory, imagination, etc.) appears as relevant and manifest for a \\x91self\\x92 or \\x91subject\\x92 that can provide an account; they have a \\x91subjective\\x92 side. In contrast, third-person descriptions concern the descriptive experiences associated with the study of other natural phenomena. Although there are always human agents in science who provide and produce descriptions, the contents of such descriptions (i.e. of biochemical reactions, black holes or synaptic voltages) are not clearly or immediately linked to the human agents who come up with them. Their defining characteristics refer to properties of world events without a direct manifestation in the experiential-mental sphere; they can only be linked to this sphere indirectly (via the actual laboratory life, the modes of scientific communication and so on). Such \\x91objective\\x92 descriptions do have a subjective-social dimension, but this dimension is hidden within the social practices of science. The ostensive, direct reference is to the \\x91objective\\x92, the \\x91outside\\x92, the content of current science that we have today concerning various natural phenomena, such as physics and biology. Now, recent history and philosophy of science often suggests that this apparent objectivity cannot be characterized as dealing with things-out-there, as independent of mental contents-in-here. Science is permeated by the procedural and social regulations that go under the name of scientific method, that permits the constitution of a corpus of shared knowledge about natural objects. The linchpin of this constitution is public verification and validation according to complex human exchanges. What we take to be objective is what can be turned from individual accounts into a body of regulated knowledge. This body of knowledge is inescapably in part subjective, since it depends on individual observation and experience, and partly objective, since it is constrained and regulated by the empirical, natural phenomena. This brief reminder that the subjective is already implicit in the objective highlights how the received distinction between objective and subjective as an absolute', 'externalIds': {'CorpusId': 13253908}, 'label': 0}\n",
      "{'paperId': 'e3a7283a9308d4e01e5c7a73486edbc05c6971c8', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/e3a7283a9308d4e01e5c7a73486edbc05c6971c8', 'title': 'As necessidades em saúde da população rural em Colômbia e Laranjeiras/SP em análise', 'abstract': 'to identify the perception that rural populations living in the municipalities of Colombia and Laranjeiras have about their health and about the needs for the best health conditions. Exploratory study, conducted through an interview with a script of open questions and analysis of the sociodemographic information of the e-SUS of the communities. Of the 42 interviewees, there was a consensus regarding the concept of health, which is believed to be a health-disease process, based on the biomedical model. Respondents resent resources that can improve their living conditions and believe that there could be greater investment in transport or infrastructure, in addition to better financing of health care. Regarding collaboration to improve the local scenario, more than half said they did not have the capacity to change the situation in their communities. Due to the adopted health model, a service structure is overloaded by excessive consultations, diagnostic tests and the supply of medications. It is necessary to improve the conditions of care and seek the implementation of programs and / or actions with the objective of stimulating the empowerment of the settlers and the search for self-responsibility for health care.', 'externalIds': {'MAG': 3130385470.0, 'DOI': '10.25059/2527-2594/RETRATOSDEASSENTAMENTOS/2020.V23I2.419', 'CorpusId': 234649774}, 'label': 0}\n",
      "{'paperId': '93777acb84add24b240b04b6be01780cb1fb93c9', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/93777acb84add24b240b04b6be01780cb1fb93c9', 'title': 'Device for indexing peripheral neuropathy', 'abstract': 'A prototype device for improved assessment of clinical diabetic neuropathy was designed, developed, and pilot tested by students of the Design of Medical Devices II course, which is part of the biomedical engineering program of the Higher Colleges of Technology in the United Arab Emirates. Specifically, students identified a specific clinical problem faced by healthcare staff in the screening of diabetes mellitus complications and researched possible solutions in consideration of patient care, ease of use, and assessment effectiveness. In response, students designed and pilot tested PAD, Peripheral nerve Assessment Device, which is a prototype that meets the design criteria of the healthcare staff through digital indexing of sensory nerve perception.', 'externalIds': {'MAG': 2151259545.0, 'DOI': '10.1109/MECBME.2011.5752107', 'CorpusId': 36923127}, 'label': 0}\n",
      "{'paperId': '392bfd11e5b83119f0b1b4468ad20142abd2fcb2', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/392bfd11e5b83119f0b1b4468ad20142abd2fcb2', 'title': 'Quantitative Episode Trees', 'abstract': 'In this paper we focus on {\\\\em serial episodes}, that are sequences of event types extracted from single or multiple input sequences, and that reflect a qualitative relation {\\\\em is-followed-by} between the event types. \\n \\nEpisodes have natural applications into several domains, including for instance the analysis of business time series, medical data, geophysical data and also alarm log analysis for network monitoring (especially in telecommunications). \\n \\nHowever, in many applications episodes clearly show some limitations, due to the fact that the information provided by the {\\\\em is-followed-by} relation is not always enough to properly characterize the phenomena at hand. This, in particular, pulls our research toward the refinement of episodes to incorporate quantitative temporal information, able to describe the time intervals observed for the {\\\\em is-followed-by} relation. \\n \\nWe proposed a refinement of episodes called {\\\\em quantitative episodes}, that provides quantitative temporal information in a readable, tree-based graphically representable form. These quantitative episodes describe the main groups of homogeneous behaviors within the occurrences of each episode, according to the elapsed times between the consecutive event types of the episode. Moreover, they are not provided in an isolated way, but in trees giving a global view of how the occurrences of the corresponding episode differentiate in homogeneous groups along the elements of the pattern. From a computational point of view, the main interest of the quantitative episodes is that they can be mined in a sound and complete way without increasing the cost of extractions significantly when compared to extractions of episodes alone. This is achieved through an extraction algorithm that tightly integrates episode extraction with a computationally reasonable analysis of temporal quantitative information.', 'externalIds': {'MAG': 2909824946.0, 'CorpusId': 8949256}, 'label': 0}\n",
      "{'paperId': '1d99f0ae1b1d916c6be970e1cfed3eb1c9b33db8', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/1d99f0ae1b1d916c6be970e1cfed3eb1c9b33db8', 'title': 'The endocannabinoid system: critical for the neurotrophic action of psychotropic drugs', 'abstract': 'There is growing evidence that neurotrophins besides their well-established actions in regulating the survival, differentiation, and maintenance of the functions of specific populations of neurons, act as the potential mediators of antidepressant responses. Previous studies on the regulation of nerve growth factor (NGF) levels by psychotropic medications are limited in scope and the underlying mechanism(s) remain elusive. In this review, the latest findings on the effects of pharmacologically heterogeneous groups of psychotropic drugs on NGF contents in the brain regions involved in the modulation of emotions are summarized. Moreover, the therapeutic potentials of the endocannabinoid system which is linked to depression and/or antidepressant effects and appears to interact with neurotrophin signalling, are reviewed. New findings demonstrate that endocannabinoid system is involved in the mechanisms of action of certain psychotropic medications including neurokinin receptor antagonists and that these are mediated via the upregulation of brain regional levels of NGF. This provides a better understanding of the pathophysiological mechanisms underlying neuropsychiatric disorders, leading to novel drug designs. Biomedical Reviews 2010; 21: 31-46.', 'externalIds': {'MAG': 1992393823.0, 'DOI': '10.14748/BMR.V21.45', 'CorpusId': 15999868}, 'label': 0}\n",
      "{'paperId': '4477df57c1acdcbcf6dd333b0eff0345994bbd96', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/4477df57c1acdcbcf6dd333b0eff0345994bbd96', 'title': 'Advanced Transfer Learning Approach for Improving Sentiment Analysis on Different Dialects of Spanish', 'abstract': 'In the last years, innovative techniques like Transfer Learning have impacted strongly in Natural Language Processing, increasing massively the state-of-the art in several challenging tasks. In particular, the Universal Language Model Fine-Tuning (ULMFiT) and the Bidirectional Encoder Representations from Transformers (BERT) algorithms have proven to have an impressive performance on several English text classification tasks. In this paper, we aim at developing an algorithm for Spanish Sentiment Analysis of short texts that is comparable to the state-of-the-art. In order to do so, we have adapted the ULMFiT and BERT algorithms to this setting. Experimental results on benchmark datasets (InterTASS 2017 and InterTASS 2018) show how this simple transfer learning approach performs well when compared to fancy deep learning techniques.', 'externalIds': {'DOI': '10.52591/lxai201912084', 'CorpusId': 250269127}, 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load CSV file with specified encoding\n",
    "df = pd.read_csv(\"papers.csv\", encoding=\"latin1\")\n",
    "\n",
    "# Function to build nested 'externalIds' dict\n",
    "def build_external_ids(row):\n",
    "    external_keys = [\"MAG\", \"DBLP\", \"PubMedCentral\", \"DOI\", \"CorpusId\", \"PubMed\", \"ACL\", \"ArXiv\"]\n",
    "    return {\n",
    "        key: row[f\"externalIds.{key}\"] for key in external_keys if not pd.isna(row[f\"externalIds.{key}\"])\n",
    "    }\n",
    "\n",
    "# Function to map isBionlp values to labels (1 for 'Y', 0 for 'N' and 'N/A')\n",
    "def map_is_bionlp(value):\n",
    "    if value == \"Y\":\n",
    "        return 1\n",
    "    elif value == \"N\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 \n",
    "\n",
    "# Convert each row to a JSON object\n",
    "jsonl_lines = []\n",
    "for _, row in df.iterrows():\n",
    "    json_obj = {\n",
    "        \"paperId\": row[\"paperId\"],\n",
    "        \"semanticScholarUrl\": row[\"semanticScholarUrl\"],\n",
    "        \"title\": row[\"title\"],\n",
    "        \"abstract\": row[\"abstract\"],\n",
    "        \"externalIds\": build_external_ids(row),\n",
    "        \"label\": map_is_bionlp(row[\"isBionlp\"]) if \"isBionlp\" in row else 0\n",
    "    }\n",
    "    jsonl_lines.append(json_obj)\n",
    "\n",
    "# Save to .jsonl\n",
    "with open(\"papers.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in jsonl_lines:\n",
    "        print(item)\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4721ed23",
   "metadata": {},
   "source": [
    "## Get test data (remove first 50 paper / last 30 from test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cd06cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paperId': '88ed818b44ac91d0e410c2444b785ae33db490f5', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/88ed818b44ac91d0e410c2444b785ae33db490f5', 'title': 'Diseases 2.0: a weekly updated database of disease–gene associations from text mining and data integration', 'abstract': 'The scientific knowledge about which genes are involved in which diseases grows rapidly, which makes it difficult to keep up with new publications and genetics datasets. The DISEASES database aims to provide a comprehensive overview by systematically integrating and assigning confidence scores to evidence for disease–gene associations from curated databases, genome-wide association studies (GWAS), and automatic text mining of the biomedical literature. Here, we present a major update to this resource, which greatly increases the number of associations from all these sources. This is especially true for the text-mined associations, which have increased by at least 9-fold at all confidence cutoffs. We show that this dramatic increase is primarily due to adding full-text articles to the text corpus, secondarily due to improvements to both the disease and gene dictionaries used for named entity recognition, and only to a very small extent due to the growth in number of PubMed abstracts. DISEASES now also makes use of a new GWAS database, TIGA, which considerably increased the number of GWAS-derived disease–gene associations. DISEASES itself is also integrated into several other databases and resources, including GeneCards/MalaCards, Pharos/TCRD, and the Cytoscape stringApp. All data in DISEASES is updated on a weekly basis and is available via a web interface at https://diseases.jensenlab.org, from where it can also be downloaded under open licenses.', 'externalIds': {'DBLP': 'journals/biodb/GrissaJOJ22', 'PubMedCentral': 9216524.0, 'DOI': '10.1093/database/baac019', 'CorpusId': 245048201.0, 'PubMed': 35348648.0}, 'label': 1}\n",
      "{'paperId': '5b57067ee5088b5faa111137c3cb33cd28a8fe46', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/5b57067ee5088b5faa111137c3cb33cd28a8fe46', 'title': 'BioNerFlair: biomedical named entity recognition using flair embedding and sequence tagger', 'abstract': 'Motivation: The proliferation of Biomedical research articles has made the task of information retrieval more important than ever. Scientists and Researchers are having difficulty in finding articles that contain information relevant to them. Proper extraction of biomedical entities like Disease, Drug/chem, Species, Gene/protein, can considerably improve the filtering of articles resulting in better extraction of relevant information. Performance on BioNer benchmarks has progressively improved because of progression in transformers-based models like BERT, XLNet, OpenAI, GPT2, etc. These models give excellent results; however, they are computationally expensive and we can achieve better scores for domain-specific tasks using other contextual string-based models and LSTM-CRF based sequence tagger. Results: We introduce BioNerFlair, a method to train models for biomedical named entity recognition using Flair plus GloVe embeddings and Bidirectional LSTM-CRF based sequence tagger. With almost the same generic architecture widely used for named entity recognition, BioNerFlair outperforms previous state-of-the-art models. I performed experiments on 8 benchmarks datasets for biomedical named entity recognition. Compared to current state-of-the-art models, BioNerFlair achieves the best F1-score of 90.17 beyond 84.72 on the BioCreative II gene mention (BC2GM) corpus, best F1-score of 94.03 beyond 92.36 on the BioCreative IV chemical and drug (BC4CHEMD) corpus, best F1-score of 88.73 beyond 78.58 on the JNLPBA corpus, best F1-score of 91.1 beyond 89.71 on the NCBI disease corpus, best F1-score of 85.48 beyond 78.98 on the Species-800 corpus, while near best results was observed on BC5CDR-chem, BC3CDR-disease, and LINNAEUS corpus.', 'externalIds': {'MAG': 3094868181.0, 'DBLP': 'journals/corr/abs-2011-01504', 'CorpusId': 226237525.0, 'ArXiv': 2011.01504}, 'label': 1}\n",
      "{'paperId': '594232d8cecfd0f2cbbb2698649594c0fff39c2f', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/594232d8cecfd0f2cbbb2698649594c0fff39c2f', 'title': 'Energy-based architecture for classification of publication figures', 'abstract': 'We present an implementation of the experimental and theoretical results obtained in the analysis of text and image content of biomedical publications. Particularly, we propose a novel optical recognition system using an adaptive algorithm for the classification and analysis of highly heterogeneous images in research papers. When compared with conventional algorithms, our technology substantially increases the probability of detection and classification of images buried in text or obscured by other images. We report successful testing of the new architecture using PubMed publications.', 'externalIds': {'MAG': 1992754166.0, 'DOI': '10.1109/BSEC.2013.6618492', 'CorpusId': 30101997.0}, 'label': 0}\n",
      "{'paperId': '4116ead5bc5472ea4fdf97b443fdaf6a1b31c2df', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/4116ead5bc5472ea4fdf97b443fdaf6a1b31c2df', 'title': 'Transformers for Clinical Coding in Spanish', 'abstract': 'Automatic clinical coding is an essential task in the process of extracting relevant information from unstructured documents contained in electronic health records (EHRs). However, most research in the development of computer-based methods for clinical coding focuses on texts written in English due to the limited availability of medical linguistic resources in languages other than English. With nearly 500 million native speakers, there is a worldwide interest in processing healthcare texts in Spanish. In this study, we systematically analyzed transformer-based models for automatic clinical coding in Spanish. Using a transfer-learning-based approach, the three existing transformer architectures that support the Spanish language, namely, multilingual BERT (mBERT), BETO and XLM-RoBERTa (XLM-R), were first pretrained on a corpus of real-world oncology clinical cases with the goal of adapting transformers to the particularities of Spanish medical texts. The resulting models were fine-tuned on three distinct clinical coding tasks, following a multilabel sentence classification strategy. For each analyzed transformer, the domain-specific version outperformed the original general domain model across those tasks. Moreover, the combination of the developed strategy with an ensemble approach leveraging the predictive capacities of the three distinct transformers yielded the best obtained results, with MAP scores of 0.662, 0.544 and 0.884 on CodiEsp-D, CodiEsp-P and Cantemist-Coding shared tasks, which remarkably improved the previous state-of-the-art performance by 11.6%, 10.3% and 4.4%, respectively. We publicly release the mBERT, BETO and XLMR transformers adapted to the Spanish clinical domain at https://github.com/guilopgar/ClinicalCodingTransformerES, providing the clinical natural language processing community with advanced deep learning methods for performing medical coding and other tasks in the Spanish clinical domain.', 'externalIds': {'DBLP': 'journals/access/Lopez-GarciaJRA21', 'DOI': '10.1109/ACCESS.2021.3080085', 'CorpusId': 235077408.0}, 'label': 1}\n",
      "{'paperId': '430d8b0b176ce2d780a20053ccd9cd2b72da9b7d', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/430d8b0b176ce2d780a20053ccd9cd2b72da9b7d', 'title': 'Cross-lingual Candidate Search for Biomedical Concept Normalization', 'abstract': 'Biomedical concept normalization links concept mentions in texts to a semantically equivalent concept in a biomedical knowledge base. This task is challenging as concepts can have different expressions in natural languages, e.g. paraphrases, which are not necessarily all present in the knowledge base. Concept normalization of non-English biomedical text is even more challenging as non-English resources tend to be much smaller and contain less synonyms. To overcome the limitations of non-English terminologies we propose a cross-lingual candidate search for concept normalization using a character-based neural translation model trained on a multilingual biomedical terminology. Our model is trained with Spanish, French, Dutch and German versions of UMLS. The evaluation of our model is carried out on the French Quaero corpus, showing that it outperforms most teams of CLEF eHealth 2015 and 2016. Additionally, we compare performance to commercial translators on Spanish, French, Dutch and German versions of Mantra. Our model performs similarly well, but is free of charge and can be run locally. This is particularly important for clinical NLP applications as medical documents underlay strict privacy restrictions.', 'externalIds': {'MAG': 2801213160.0, 'DBLP': 'journals/corr/abs-1805-01646', 'CorpusId': 24141378.0, 'ArXiv': 1805.01646}, 'label': 1}\n",
      "{'paperId': 'ebecc56f7e1a9b954c7d472306eca0326250998f', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/ebecc56f7e1a9b954c7d472306eca0326250998f', 'title': 'An Active Transfer Learning Framework for Protein-Protein Interaction Extraction', 'abstract': 'SUMMARY Protein-Protein Interaction Extraction (PPIE) from biomedical literatures is an important task in biomedical text mining and has achieved great success on public datasets. However, in real-world applications, the existing PPI extraction methods are limited to label e ﬀ ort. Therefore, transfer learning method is applied to reduce the cost of manual labeling. Current transfer learning methods su ﬀ er from negative transfer and lower performance. To tackle this problem, an improved TrAdaBoost algo-rithm is proposed, that is, relative distribution is introduced to initialize the weights of TrAdaBoost to overcome the negative transfer caused by domain di ﬀ erences. To make further improvement on the performance of transfer learning, an approach combining active learning with the improved TrAd-aBoost is presented. The experimental results on publicly available PPI corpora show that our method outperforms TrAdaBoost and SVM when the labeled data is insu ﬃ cient,and on document classiﬁcation corpora, it also illustrates that the proposed approaches can achieve better performance than TrAdaBoost and TPTSVM in ﬁnal, which veriﬁes the e ﬀ ectiveness of our methods.', 'externalIds': {'MAG': 2786191679.0, 'DBLP': 'journals/ieicet/LiHZHR18', 'DOI': '10.1587/TRANSINF.2017EDP7232', 'CorpusId': 37476671.0}, 'label': 1}\n",
      "{'paperId': '2966e82ec5f89f23ec7636acc00c9ee74d491968', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/2966e82ec5f89f23ec7636acc00c9ee74d491968', 'title': 'Chemical–gene relation extraction using recursive neural network', 'abstract': 'Abstract In this article, we describe our system for the CHEMPROT task of the BioCreative VI challenge. Although considerable research on the named entity recognition of genes and drugs has been conducted, there is limited research on extracting relationships between them. Extracting relations between chemical compounds and genes from the literature is an important element in pharmacological and clinical research. The CHEMPROT task of BioCreative VI aims to promote the development of text mining systems that can be used to automatically extract relationships between chemical compounds and genes. We tested three recursive neural network approaches to improve the performance of relation extraction. In the BioCreative VI challenge, we developed a tree-Long Short-Term Memory networks (tree-LSTM) model with several additional features including a position feature and a subtree containment feature, and we also applied an ensemble method. After the challenge, we applied additional pre-processing steps to the tree-LSTM model, and we tested the performance of another recursive neural network model called Stack-augmented Parser Interpreter Neural Network (SPINN). Our tree-LSTM model achieved an F-score of 58.53% in the BioCreative VI challenge. Our tree-LSTM model with additional pre-processing and the SPINN model obtained F-scores of 63.7 and 64.1%, respectively. Database URL: https://github.com/arwhirang/recursive_chemprot', 'externalIds': {'MAG': 2809349863.0, 'DBLP': 'journals/biodb/LimK18', 'PubMedCentral': 6014134.0, 'DOI': '10.1093/database/bay060', 'CorpusId': 13676496.0, 'PubMed': 29961818.0}, 'label': 1}\n",
      "{'paperId': '0f97f0624594fb5ca840a0f1c9a52231922f470a', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/0f97f0624594fb5ca840a0f1c9a52231922f470a', 'title': 'ELLPMDA: Ensemble learning and link prediction for miRNA-disease association prediction', 'abstract': 'ABSTRACT Recently, accumulating evidences have indicated miRNAs play critical roles in the progression and development of various human complex diseases, which pointed out that identifying miRNA-disease association could enable us to understand diseases at miRNA level. Thus, revealing more and more potential miRNA-disease associations is a vital topic in biomedical domain. However, it will be extremely expensive and time-consuming if we examine all the possible miRNA-disease pairs. Therefore, more accurate and efficient methods are being highly requested to detect potential miRNA-disease associations. In this study, we developed a computational model of Ensemble Learning and Link Prediction for miRNA-Disease Association prediction (ELLPMDA) to achieve this goal. By integrating miRNA functional similarity, disease semantic similarity, miRNA-disease association and Gaussian profile kernel similarity for miRNAs and diseases, we constructed a similarity network and utilized ensemble learning to combine rank results given by three classic similarity-based algorithms. To evaluate the performance of ELLPMDA, we exploited global and local Leave-One-Out Cross Validation (LOOCV), 5-fold Cross Validation (CV) and three kinds of case studies. As a result, the AUCs of ELLPMDA is 0.9181, 0.8181 and 0.9193+/−0.0002 in global LOOCV, local LOOCV and 5-fold CV, respectively, which significantly exceed almost all the previous methods. Moreover, in three distinct kinds of case studies for Kidney Neoplasms, Lymphoma, Prostate Neoplasms, Colon Neoplasms and Esophageal Neoplasms, 88%, 92%, 86%, 98% and 98% out of the top 50 predicted miRNAs has been confirmed, respectively. Besides, ELLPMDA is based on global similarity measure and applicable to new diseases without any known related miRNAs.', 'externalIds': {'MAG': 2795540478.0, 'DOI': '10.1080/15476286.2018.1460016', 'CorpusId': 4599451.0, 'PubMed': 29619882.0}, 'label': 0}\n",
      "{'paperId': 'ca742e5c1a680b1969f5fbb4dfd0a730c785eded', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/ca742e5c1a680b1969f5fbb4dfd0a730c785eded', 'title': 'Discovering peripheral arterial disease cases from radiology notes using natural language processing.', 'abstract': \"As part of the Electronic Medical Records and Genomics Network, we applied, extended and evaluated an open source clinical Natural Language Processing system, Mayo's Clinical Text Analysis and Knowledge Extraction System, for the discovery of peripheral arterial disease cases from radiology reports. The manually created gold standard consisted of 223 positive, 19 negative, 63 probable and 150 unknown cases. Overall accuracy agreement between the system and the gold standard was 0.93 as compared to a named entity recognition baseline of 0.46. Sensitivity for the positive, probable and unknown cases was 0.93-0.96, and for the negative cases was 0.72. Specificity and negative predictive value for all categories were in the 90's. The positive predictive value for the positive and unknown categories was in the high 90's, for the negative category was 0.84, and for the probable category was 0.63. We outline the main sources of errors and suggest improvements.\", 'externalIds': {'MAG': 70606898.0, 'CorpusId': 40731344.0, 'PubMed': 21347073.0}, 'label': 1}\n",
      "{'paperId': '37112eae96347fd0fb5970e31130534f9232048e', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/37112eae96347fd0fb5970e31130534f9232048e', 'title': 'Introducing anisotropic Minkowski functionals and quantitative anisotropy measures for local structure analysis in biomedical imaging', 'abstract': 'The ability of Minkowski Functionals to characterize local structure in different biological tissue types has been demonstrated in a variety of medical image processing tasks. We introduce anisotropic Minkowski Functionals (AMFs) as a novel variant that captures the inherent anisotropy of the underlying gray-level structures. To quantify the anisotropy characterized by our approach, we further introduce a method to compute a quantitative measure motivated by a technique utilized in MR diffusion tensor imaging, namely fractional anisotropy. We showcase the applicability of our method in the research context of characterizing the local structure properties of trabecular bone micro-architecture in the proximal femur as visualized on multi-detector CT. To this end, AMFs were computed locally for each pixel of ROIs extracted from the head, neck and trochanter regions. Fractional anisotropy was then used to quantify the local anisotropy of the trabecular structures found in these ROIs and to compare its distribution in different anatomical regions. Our results suggest a significantly greater concentration of anisotropic trabecular structures in the head and neck regions when compared to the trochanter region (p < 10-4). We also evaluated the ability of such AMFs to predict bone strength in the femoral head of proximal femur specimens obtained from 50 donors. Our results suggest that such AMFs, when used in conjunction with multi-regression models, can outperform more conventional features such as BMD in predicting failure load. We conclude that such anisotropic Minkowski Functionals can capture valuable information regarding directional attributes of local structure, which may be useful in a wide scope of biomedical imaging applications.', 'externalIds': {'MAG': 2065274778.0, 'DBLP': 'journals/corr/abs-2004-01185', 'DOI': '10.1117/12.2007192', 'CorpusId': 206396264.0, 'PubMed': 29170580.0}, 'label': 0}\n",
      "{'paperId': 'b39435346d91f6e3b71f7f995a5f6df12a98b184', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/b39435346d91f6e3b71f7f995a5f6df12a98b184', 'title': 'ALGORITHM FOR UMLS METATHESAURUS CONCEPTS SPECIFICITY ESTIMATION USING EXAMPLE OF ANALYSIS OF THE SEMANTIC MODEL DESCRIBING AXIAL SPONDYLOARTHRITIS DIFFERENTIAL DIAGNOSTICS', 'abstract': '. Background. Early axial spondyloarthritis (axSpA) diagnostics is a difficult task requiring clinical decision support (CDS) making. Currently, there is a big unstructured data applicable in CDS systems development. Semantic data analysis is a complex issue to solve, and unified tools for named entity recognition are required. The biggest data source for biomedical text annotation is the Unified Medical Language System (UMLS) Metathesaurus. It includes more than 11 million atomic terms for writing of 4.6 million concepts. The main issue in UMLS using for medical text analysis is a presence of numerous unspecified (generic) terms without any clinical value. Their application leads to significant decrease of searching results. That is why tools for automatic specificity degree estimation are needed to be developed. Aim. To develop an algorithm for specificity degree estimation for UMLS metathesaurus concepts (using example of axial spondyloarthritis). Methods. English clinical abstracts have been used as data source for automatic UMLS named entity recognition. They have been extracted using free search engine PubMed followed by integration into single electronic corpus. Then each of 24276 texts in corpus has been labeled (affiliated with one of diagnosis in differential list for axSpA) and used for UMLS concepts mapping. A total of 8260 UMLS concepts have been recognized. Each term received an expert binary label of relative specificity. Results. Rules for concepts specificity degree estimation have been developed based on comparison of 4 parameters: mean length of hierarchical chain, total count of direct relationships, TF-IDF score and count of hierarchical relationships with child concepts UMLS. These rules have been integrated into the total algorithm for UMLS concepts specificity degree estimation. Its accuracy was 99,1% for test data sample for paired comparisons. But its accuracy for solid comparison of all extracted concepts was 74,2%, which less than desirable for substantiation of this algorithm use for automatically terms big sets cutbacks. That is why some limitations for developed algorithm have been outlined.', 'externalIds': {'DOI': '10.25881/18110193_2023_3_30', 'CorpusId': 269101448.0}, 'label': 0}\n",
      "{'paperId': '1400adc26880405468fba432d00360edb8ce7aeb', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/1400adc26880405468fba432d00360edb8ce7aeb', 'title': 'Enhanced Labelling in Active Learning for Coreference Resolution', 'abstract': 'In this paper we describe our attempt to increase the amount of information that can be retrieved through active learning sessions compared to previous approaches. We optimise the annotator’s labelling process using active learning in the context of coreference resolution. Using simulated active learning experiments, we suggest three adjustments to ensure the labelling time is spent as efficiently as possible. All three adjustments provide more information to the machine learner than the baseline, though a large impact on the F1 score over time is not observed. Compared to previous models, we report a marginal F1 improvement on the final coreference models trained using for two out of the three approaches tested when applied to the English OntoNotes 2012 Coreference Resolution data. Our best-performing model achieves 58.01 F1, an increase of 0.93 F1 over the baseline model.', 'externalIds': {'CorpusId': 227230324.0, 'ACL': '2020.crac-1.12'}, 'label': 0}\n",
      "{'paperId': '0a7a35dee8e6e856be8ecb9c3893a78d4fd87b9f', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/0a7a35dee8e6e856be8ecb9c3893a78d4fd87b9f', 'title': 'Terminological ontology learning based on LDA', 'abstract': 'Ontology has extensive application in many fields, such as retrieval, information extraction and artificial intelligence et al. In this paper we describe a new approach about automatic learning terminological ontologies. this method make use fo the LDA model as concepts and builds relationship such concepts to learn ontologies. The method presents two measures, CP measure and L1 norm measure respectively, of computing semantic similarity between topics to organize these topics into hierarchy structure and forms the new ontology. Moreover, we design a method to determine the size of new ontology that is automatically created from text corpora, which can quantify the quality of the learned ontology in a natural manner. We evaluate our approach through GENIA corpus which is a text collections of biomedical literature. And the experiment results demonstrate the validity and efficiency of proposed method.', 'externalIds': {'MAG': 2783717580.0, 'DBLP': 'conf/icsai/Lin17a', 'DOI': '10.1109/ICSAI.2017.8248539', 'CorpusId': 24574012.0}, 'label': 0}\n",
      "{'paperId': '634e8a148fbe96cd611c09bdddc85de4bdd8a52d', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/634e8a148fbe96cd611c09bdddc85de4bdd8a52d', 'title': 'Continual Contrastive Finetuning Improves Low-Resource Relation Extraction', 'abstract': 'Relation extraction (RE), which has relied on structurally annotated corpora for model training, has been particularly challenging in low-resource scenarios and domains. Recent literature has tackled low-resource RE by self-supervised learning, where the solution involves pretraining the entity pair embedding by RE-based objective and finetuning on labeled data by classification-based objective. However, a critical challenge to this approach is the gap in objectives, which prevents the RE model from fully utilizing the knowledge in pretrained representations. In this paper, we aim at bridging the gap and propose to pretrain and finetune the RE model using consistent objectives of contrastive learning. Since in this kind of representation learning paradigm, one relation may easily form multiple clusters in the representation space, we further propose a multi-center contrastive loss that allows one relation to form multiple clusters to better align with pretraining. Experiments on two document-level RE datasets, BioRED and Re-DocRED, demonstrate the effectiveness of our method. Particularly, when using 1% end-task training data, our method outperforms PLM-based RE classifier by 10.5% and 6.1% on the two datasets, respectively.', 'externalIds': {'DBLP': 'journals/corr/abs-2212-10823', 'DOI': '10.48550/arXiv.2212.10823', 'CorpusId': 254926992.0, 'ACL': '2023.acl-long.739', 'ArXiv': 2212.10823}, 'label': 0}\n",
      "{'paperId': '46cfca8d9167f747638bca8e93047c3aa7f485f6', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/46cfca8d9167f747638bca8e93047c3aa7f485f6', 'title': 'Natural Language Processing Techniques for Text Classification of Biomedical Documents: A Systematic Review', 'abstract': 'The classification of biomedical literature is engaged in a number of critical issues that physicians are expected to answer. In many cases, these issues are extremely difficult. This can be conducted for jobs such as diagnosis and treatment, as well as efficient representations of ideas such as medications, procedure codes, and patient visits, as well as in the quick search of a document or disease classification. Pathologies are being sought from clinical notes, among other sources. The goal of this systematic review is to analyze the literature on various problems of classification of medical texts of patients based on criteria such as: the quality of the evaluation metrics used, the different methods of machine learning applied, the different data sets, to highlight the best methods in this type of problem, and to identify the different challenges associated. The study covers the period from 1 January 2016 to 10 July 2022. We used multiple databases and archives of research articles, including Web Of Science, Scopus, MDPI, arXiv, IEEE, and ACM, to find 894 articles dealing with the subject of text classification, which we were able to filter using inclusion and exclusion criteria. Following a thorough review, we selected 33 articles dealing with biological text categorization issues. Following our investigation, we discovered two major issues linked to the methodology and data used for biomedical text classification. First, there is the data-centric challenge, followed by the data quality challenge.', 'externalIds': {'DBLP': 'journals/information/KesikuCG22', 'DOI': '10.3390/info13100499', 'CorpusId': 253012448.0}, 'label': 1}\n",
      "{'paperId': '76b99439d524ae1813c30edc4bcad487a30a1f8c', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/76b99439d524ae1813c30edc4bcad487a30a1f8c', 'title': 'UniversalNER: Targeted Distillation from Large Language Models for Open Named Entity Recognition', 'abstract': \"Large language models (LLMs) have demonstrated remarkable generalizability, such as understanding arbitrary entities and relations. Instruction tuning has proven effective for distilling LLMs into more cost-efficient models such as Alpaca and Vicuna. Yet such student models still trail the original LLMs by large margins in downstream applications. In this paper, we explore targeted distillation with mission-focused instruction tuning to train student models that can excel in a broad application class such as open information extraction. Using named entity recognition (NER) for case study, we show how ChatGPT can be distilled into much smaller UniversalNER models for open NER. For evaluation, we assemble the largest NER benchmark to date, comprising 43 datasets across 9 diverse domains such as biomedicine, programming, social media, law, finance. Without using any direct supervision, UniversalNER attains remarkable NER accuracy across tens of thousands of entity types, outperforming general instruction-tuned models such as Alpaca and Vicuna by over 30 absolute F1 points in average. With a tiny fraction of parameters, UniversalNER not only acquires ChatGPT's capability in recognizing arbitrary entity types, but also outperforms its NER accuracy by 7-9 absolute F1 points in average. Remarkably, UniversalNER even outperforms by a large margin state-of-the-art multi-task instruction-tuned systems such as InstructUIE, which uses supervised NER examples. We also conduct thorough ablation studies to assess the impact of various components in our distillation approach. We release the distillation recipe, data, and UniversalNER models to facilitate future research on targeted distillation.\", 'externalIds': {'DBLP': 'journals/corr/abs-2308-03279', 'DOI': '10.48550/arXiv.2308.03279', 'CorpusId': 260682557.0, 'ArXiv': 2308.03279}, 'label': 0}\n",
      "{'paperId': 'b574ec199b2b1a7a18d856a37ae8862db644465f', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/b574ec199b2b1a7a18d856a37ae8862db644465f', 'title': 'Disease Mention Recognition with Specific Features', 'abstract': 'Despite an increasing amount of research on biomedical named entity recognition, there has been not enough work done on disease mention recognition. Difficulty of obtaining adequate corpora is one of the key reasons which hindered this particular research. Previous studies argue that correct identification of disease mentions is the key issue for further improvement of the disease-centric knowledge extraction tasks. In this paper, we present a machine learning based approach that uses a feature set tailored for disease mention recognition and outperforms the state-of-the-art results. The paper also discusses why a feature set for the well studied gene/protein mention recognition task is not necessarily equally effective for other biomedical semantic types such as diseases.', 'externalIds': {'MAG': 107258648.0, 'DBLP': 'conf/bionlp/ChowdhuryL10', 'CorpusId': 3852572.0, 'ACL': 'W10-1911'}, 'label': 1}\n",
      "{'paperId': '087d19037086020275bfb780df8cf1893ee62e97', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/087d19037086020275bfb780df8cf1893ee62e97', 'title': 'Drug–drug interaction extraction via hierarchical RNNs on sequence and shortest dependency paths', 'abstract': 'Motivation Adverse events resulting from drug‐drug interactions (DDI) pose a serious health issue. The ability to automatically extract DDIs described in the biomedical literature could further efforts for ongoing pharmacovigilance. Most of neural networks‐based methods typically focus on sentence sequence to identify these DDIs, however the shortest dependency path (SDP) between the two entities contains valuable syntactic and semantic information. Effectively exploiting such information may improve DDI extraction. Results In this article, we present a hierarchical recurrent neural networks (RNNs)‐based method to integrate the SDP and sentence sequence for DDI extraction task. Firstly, the sentence sequence is divided into three subsequences. Then, the bottom RNNs model is employed to learn the feature representation of the subsequences and SDP, and the top RNNs model is employed to learn the feature representation of both sentence sequence and SDP. Furthermore, we introduce the embedding attention mechanism to identify and enhance keywords for the DDI extraction task. We evaluate our approach using the DDI extraction 2013 corpus. Our method is competitive or superior in performance as compared with other state‐of‐the‐art methods. Experimental results show that the sentence sequence and SDP are complementary to each other. Integrating the sentence sequence with SDP can effectively improve the DDI extraction performance. Availability and implementation The experimental data is available at https://github.com/zhangyijia1979/hierarchical‐RNNs‐model‐for‐DDI‐extraction. Contact zhyj@dlut.edu.cn or michel.dumontier@maastrichtuniversity.nl. Supplementary information Supplementary data are available at Bioinformatics online.', 'externalIds': {'MAG': 2765742249.0, 'DBLP': 'journals/bioinformatics/ZhangZLWYD18', 'PubMedCentral': 6030919.0, 'DOI': '10.1093/bioinformatics/btx659', 'CorpusId': 2957401.0, 'PubMed': 29077847.0}, 'label': 1}\n",
      "{'paperId': '227d0ec1231b951c06c8dc2992e4dcdd5cd62248', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/227d0ec1231b951c06c8dc2992e4dcdd5cd62248', 'title': 'Interactive Span Recommendation for Biomedical Text', 'abstract': 'Motivated by the scarcity of high-quality labeled biomedical text, as well as the success of data programming, we introduce KRISS-Search. By leveraging the Unified Medical Language Systems (UMLS) ontology, KRISS-Search addresses an interactive few-shot span recommendation task that we propose. We first introduce unsupervised KRISS-Search and show that our method outperforms existing methods in identifying spans that are semantically similar to a given span of interest, with >50% AUPRC improvement relative to PubMedBERT. We then introduce supervised KRISS-Search, which leverages human interaction to improve the notion of similarity used by unsupervised KRISS-Search. Through simulated human feedback, we demonstrate an enhanced F1 score of 0.68 in classifying spans as semantically similar or different in the low-label setting, outperforming PubMedBERT by 2 F1 points. Finally, supervised KRISS-Search demonstrates competitive or superior performance compared to PubMedBERT in few-shot biomedical named entity recognition (NER) across five benchmark datasets, with an average improvement of 5.6 F1 points. We envision KRISS-Search increasing the efficiency of programmatic data labeling and also providing broader utility as an interactive biomedical search engine.', 'externalIds': {'DBLP': 'conf/acl-clinicalnlp/BlankemeierZTKG23', 'DOI': '10.18653/v1/2023.clinicalnlp-1.40', 'CorpusId': 259833841.0, 'ACL': '2023.clinicalnlp-1.40'}, 'label': 1}\n",
      "{'paperId': '1b806d23d6e1daee1a7fa8df12b009e5c64bee59', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/1b806d23d6e1daee1a7fa8df12b009e5c64bee59', 'title': 'Are we there yet? Exploring clinical domain knowledge of BERT models', 'abstract': 'We explore whether state-of-the-art BERT models encode sufficient domain knowledge to correctly perform domain-specific inference. Although BERT implementations such as BioBERT are better at domain-based reasoning than those trained on general-domain corpora, there is still a wide margin compared to human performance on these tasks. To bridge this gap, we explore whether supplementing textual domain knowledge in the medical NLI task: a) by further language model pretraining on the medical domain corpora, b) by means of lexical match algorithms such as the BM25 algorithm, c) by supplementing lexical retrieval with dependency relations, or d) by using a trained retriever module, can push this performance closer to that of humans. We do not find any significant difference between knowledge supplemented classification as opposed to the baseline BERT models, however. This is contrary to the results for evidence retrieval on other tasks such as open domain question answering (QA). By examining the retrieval output, we show that the methods fail due to unreliable knowledge retrieval for complex domain-specific reasoning. We conclude that the task of unsupervised text retrieval to bridge the gap in existing information to facilitate inference is more complex than what the state-of-the-art methods can solve, and warrants extensive research in the future.', 'externalIds': {'DBLP': 'conf/bionlp/SushilSD21', 'DOI': '10.18653/v1/2021.bionlp-1.5', 'CorpusId': 235097555.0, 'ACL': '2021.bionlp-1.5'}, 'label': 1}\n",
      "{'paperId': '9ee289dbda34e13e0e35df9b343738b107fd7ce6', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/9ee289dbda34e13e0e35df9b343738b107fd7ce6', 'title': 'Domain Adaptation with Active Learning for Coreference Resolution', 'abstract': 'In the literature, most prior work on coreference resolution centered on the newswire domain. Although a coreference resolution system trained on the newswire domain performs well on newswire texts, there is a huge performance drop when it is applied to the biomedical domain. In this paper, we present an approach integrating domain adaptation with active learning to adapt coreference resolution from the newswire domain to the biomedical domain. We explore the effect of domain adaptation, active learning, and target domain instance weighting for coreference resolution. Experimental results show that domain adaptation with active learning and target domain instance weighting achieves performance on MEDLINE abstracts similar to a system trained on coreference annotation of only target domain training instances, but with a greatly reduced number of target domain training instances that we need to annotate.', 'externalIds': {'MAG': 2252165061.0, 'DBLP': 'conf/acl-louhi/ZhaoN14', 'DOI': '10.3115/v1/W14-1104', 'CorpusId': 7725722.0, 'ACL': 'W14-1104'}, 'label': 1}\n",
      "{'paperId': '218e7323c030041e025d6d35ca5cd8cce2088eda', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/218e7323c030041e025d6d35ca5cd8cce2088eda', 'title': 'LMU Munich’s Neural Machine Translation Systems at WMT 2018', 'abstract': 'We present the LMU Munich machine translation systems for the English–German language pair. We have built neural machine translation systems for both translation directions (English→German and German→English) and for two different domains (the biomedical domain and the news domain). The systems were used for our participation in the WMT18 biomedical translation task and in the shared task on machine translation of news. The main focus of our recent system development efforts has been on achieving improvements in the biomedical domain over last year’s strong biomedical translation engine for English→German (Huck et al., 2017a). Considerable progress has been made in the latter task, which we report on in this paper.', 'externalIds': {'MAG': 2902363747.0, 'DBLP': 'conf/wmt/HuckSHF18', 'DOI': '10.18653/v1/W18-6446', 'CorpusId': 53233185.0, 'ACL': 'W18-6446'}, 'label': 1}\n",
      "{'paperId': 'd46b75da1120d949076975ee340232b92faa918b', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/d46b75da1120d949076975ee340232b92faa918b', 'title': 'Predicting miRNA-disease associations based on graph attention networks and dual Laplacian regularized least squares', 'abstract': 'Increasing biomedical evidence has proved that the dysregulation of miRNAs is associated with human complex diseases. Identification of disease-related miRNAs is of great importance for disease prevention, diagnosis and remedy. To reduce the time and cost of biomedical experiments, there is a strong incentive to develop efficient computational methods to infer potential miRNA-disease associations. Although many computational approaches have been proposed to address this issue, the prediction accuracy needs to be further improved. In this study, we present a computational framework MKGAT to predict possible associations between miRNAs and diseases through graph attention networks (GATs) using dual Laplacian regularized least squares. We use GATs to learn embeddings of miRNAs and diseases on each layer from initial input features of known miRNA-disease associations, intra-miRNA similarities and intra-disease similarities. We then calculate kernel matrices of miRNAs and diseases based on Gaussian interaction profile (GIP) with the learned embeddings. We further fuse the kernel matrices of each layer and initial similarities with attention mechanism. Dual Laplacian regularized least squares are finally applied for new miRNA-disease association predictions with the fused miRNA and disease kernels. Compared with six state-of-the-art methods by 5-fold cross-validations, our method MKGAT receives the highest AUROC value of 0.9627 and AUPR value of 0.7372. We use MKGAT to predict related miRNAs for three cancers and discover that all the top 50 predicted results in the three diseases are confirmed by existing databases. The excellent performance indicates that MKGAT would be a useful computational tool for revealing disease-related miRNAs.', 'externalIds': {'DBLP': 'journals/bib/WangC22', 'DOI': '10.1093/bib/bbac292', 'CorpusId': 250622757.0, 'PubMed': 35849099.0}, 'label': 0}\n",
      "{'paperId': '8ba999d716a17fc2448c6bdb5d8eec98e0b98e7e', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/8ba999d716a17fc2448c6bdb5d8eec98e0b98e7e', 'title': 'Named Entity Recognition Based on Character-level Language Models and Attention Mechanism', 'abstract': 'As a basic task in the field of natural language processing, named entity recognition plays an important role in text data processing tasks. Extracting features from the original text can be considered as the first step in the identification of named entities, but on this basic issue, traditional research still stays at the coarser granularity of words. Unlike traditional research, this paper focuses on finer granularity-character-level named entity recognition research. In order to fully extract the character-level feature representation from the character-level language model, this paper uses CNN and BiLSTM to perform feature extraction together, and introduces the attention mechanism to achieve more effective combination of character features and word features, then combines with BiLSTM-CRF to construct a complete end-to-end deep learning model (At- BiLSTM-CNNs-CRF). The experimental results show that its recognition ability exceeds most deep learning models.', 'externalIds': {'MAG': 3087685590.0, 'DOI': '10.6919/ICJE.202001_6(1).0028', 'CorpusId': 226671176.0}, 'label': 0}\n",
      "{'paperId': '6f159da950e0776309c4c14430f042284ed6c718', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/6f159da950e0776309c4c14430f042284ed6c718', 'title': 'DANGNT-SGU at SemEval-2022 Task 11: Using Pre-trained Language Model for Complex Named Entity Recognition', 'abstract': 'In this paper, we describe a system that we built to participate in the SemEval 2022 Task 11: MultiCoNER Multilingual Complex Named Entity Recognition, specifically the track Mono-lingual in English. To construct this system, we used Pre-trained Language Models (PLMs). Especially, the Pre-trained Model base on BERT is applied for the task of recognizing named entities by fine-tuning method. We performed the evaluation on two test datasets of the shared task: the Practice Phase and the Evaluation Phase of the competition.', 'externalIds': {'DBLP': 'conf/semeval/NguyenH22', 'DOI': '10.18653/v1/2022.semeval-1.203', 'CorpusId': 250390969.0, 'ACL': '2022.semeval-1.203'}, 'label': 0}\n",
      "{'paperId': '254798f2f55448d06d5726e72f2e92a6db54b759', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/254798f2f55448d06d5726e72f2e92a6db54b759', 'title': 'Unified deep neural network for segmentation and labeling of multipanel biomedical figures', 'abstract': 'Recent efforts in biomedical visual question answering (VQA) research rely on combined information gathered from the image content and surrounding text supporting the figure. Biomedical journals are a rich source of information for such multimodal content indexing. For multipanel figures in these journals, it is critical to develop automatic figure panel splitting and label recognition algorithms to associate individual panels with text metadata in the figure caption and the body of the article. Challenges in this task include large variations in figure panel layout, label location, size, contrast to background, and so on. In this work, we propose a deep convolutional neural network, which splits the panels and recognizes the panel labels in a single step. Visual features are extracted from several layers at various depths of the backbone neural network and organized to form a feature pyramid. These features are fed into classification and regression networks to generate candidates of panels and their labels. These candidates are merged to create the final panel segmentation result through a beam search algorithm. We evaluated the proposed algorithm on the ImageCLEF data set and achieved better performance than the results reported in the literature. In order to thoroughly investigate the proposed algorithm, we also collected and annotated our own data set of 10,642 figures. The experiments, trained on 9,642 figures and evaluated on the remaining 1,000 figures, show that combining panel splitting and panel label recognition mutually benefit each other.', 'externalIds': {'MAG': 3001680139.0, 'DBLP': 'journals/jasis/ZouTA20', 'DOI': '10.1002/asi.24334', 'CorpusId': 213409354.0}, 'label': 0}\n",
      "{'paperId': '8c68dd92e4ea60dd5cda57ed43299b2b013afa41', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/8c68dd92e4ea60dd5cda57ed43299b2b013afa41', 'title': 'Automated Disease Normalization with Low Rank Approximations', 'abstract': 'While machine learning methods for named entity recognition (mention-level detection) have become common, machine learning methods have rarely been applied to normalization (concept-level identification). Recent research introduced a machine learning method for normalization based on pairwise learning to rank. This method, DNorm, uses a linear model to score the similarity between mentions and concept names, and has several desirable properties, including learning term variation directly from training data. In this manuscript we employ a dimensionality reduction technique based on low-rank matrix approximation, similar to latent semantic indexing. We compare the performance of the low rank method to previous work, using disease name normalization in the NCBI Disease Corpus as the test case, and demonstrate increased performance as the matrix rank increases. We further demonstrate a significant reduction in the number of parameters to be learned and discuss the implications of this result in the context of algorithm scalability.', 'externalIds': {'MAG': 2251872110.0, 'DBLP': 'conf/bionlp/LeamanL14', 'DOI': '10.3115/v1/W14-3404', 'CorpusId': 9164895.0, 'ACL': 'W14-3404'}, 'label': 1}\n",
      "{'paperId': '1d871d47a8269e5f2a9896fe461ea9d62a60491f', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/1d871d47a8269e5f2a9896fe461ea9d62a60491f', 'title': 'The Comparison Of the Biomedical Named Entity Recognition Models Based On Machine Learning', 'abstract': 'A great number of biomedical texts have offered enough information for people. Yet the lack of good tools prevents people from getting information and knowledge from them. NER plays a very important role in information retrieval, information extraction, knowledge discovery and so on. Based on the bio-entity recognition task at JNLPBA, this paper focuses on the introduction to the NER models based on machine learning usually used in biomedical texts. It presents a general comparison and discussion in them, and also provides some relative information.', 'externalIds': {'MAG': 2360236096.0, 'CorpusId': 63553784.0}, 'label': 1}\n",
      "{'paperId': '8438f1614bd991cbf0edf9d6bda0364a9c14d466', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/8438f1614bd991cbf0edf9d6bda0364a9c14d466', 'title': 'Unsupervised Method for Extracting Machine Understandable Medical Knowledge from a Large Free Text Collection', 'abstract': 'Definitions of medical concepts (e.g diseases, drugs) are essential background knowledge for researchers, clinicians and health care consumers. However, the rapid growth of biomedical research requires that such knowledge continually needs updating. To address this problem, we have developed an unsupervised pattern learning approach that extracts disease and drug definitions from automatically structured randomized clinical trial (RCT) abstracts. In addition, each extracted definition is semantically classified without relying on external medical knowledge. When used to identify definitions from 100 manually annotated RCT abstracts, our medical definition knowledge base has precision of 0.97, recall of 0.93, F1 of 0.94 and semantic classification accuracy of 0.96.', 'externalIds': {'MAG': 1885997810.0, 'DBLP': 'conf/amia/XuDG09', 'CorpusId': 30950454.0, 'PubMed': 20351945.0}, 'label': 1}\n",
      "{'paperId': '87e3c7e94afda108a049c157d93c72fbe920c35b', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/87e3c7e94afda108a049c157d93c72fbe920c35b', 'title': 'Multi-Objective Optimization for the Joint Disambiguation of Nouns and Named Entities', 'abstract': 'In this paper, we present a novel approach to joint word sense disambiguation (WSD) and entity linking (EL) that combines a set of complementary objectives in an extensible multi-objective formalism. During disambiguation the system performs continuous optimization to find optimal probability distributions over candidate senses. The performance of our system on nominal WSD as well as EL improves state-ofthe-art results on several corpora. These improvements demonstrate the importance of combining complementary objectives in a joint model for robust disambiguation.', 'externalIds': {'MAG': 2250718062.0, 'DBLP': 'conf/acl/WeissenbornHXU15', 'DOI': '10.3115/v1/P15-1058', 'CorpusId': 15813261.0, 'ACL': 'P15-1058'}, 'label': 0}\n",
      "{'paperId': 'e1d38510e9027ee98ba5630361036e406bb0e915', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/e1d38510e9027ee98ba5630361036e406bb0e915', 'title': 'An automated method to extract information in the biomedical literature about interactions between drugs', 'abstract': 'Text mining techniques are useful in extracting hidden information about the biomedical interactions such as Protein-Protein, Drug-Drug and Protein-Drug. Recently, there is an increased interest in automated methods due to the vast growth in the volume of published text regarding biomedical interactions. This work mainly focuses on extraction of Drug-Drug interactions (DDIs) in biomedical research articles from well-known databases such as DrugBank and MedLine. The proposed approach is developed based on feature engineering through natural language processing (NLP) techniques such as bag-of-words approach, tokenization, part-of-speech (POS) tagging, lemmatization and so on. This uncomplicated and easy to implement set of features are combined into a feature vector which is used to train a machine learning model. The effectiveness of the proposed approach was measured by conducting several experiments on the “DDI Extraction 2013” corpus. The system showed encouraging F-measure value of 76.9%.', 'externalIds': {'MAG': 2580531752.0, 'DOI': '10.1109/ICTER.2016.7829913', 'CorpusId': 33085226.0}, 'label': 1}\n",
      "{'paperId': '4275a582cde36c063252b1f0e930b3c0efe9aa90', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/4275a582cde36c063252b1f0e930b3c0efe9aa90', 'title': 'Extracting Entity Synonymous Relations via Context-Aware Permutation Invariance', 'abstract': \"Discovering entity synonymous relations is an important work for many entity-based applications. Existing entity synonymous relation extraction approaches are mainly based on lexical patterns or distributional corpus-level statistics, ignoring the context semantics between entities. For example, the contexts around ''apple'' determine whether ''apple'' is a kind of fruit or Apple Inc. In this paper, an entity synonymous relation extraction approach is proposed using context-aware permutation invariance. Specifically, a triplet network is used to obtain the permutation invariance between the entities to learn whether two given entities possess synonymous relation. To track more synonymous features, the relational context semantics and entity representations are integrated into the triplet network, which can improve the performance of extracting entity synonymous relations. The proposed approach is implemented on three real-world datasets. Experimental results demonstrate that the approach performs better than the other compared approaches on entity synonymous relation extraction task.\", 'externalIds': {'MAG': 3205829967.0, 'DBLP': 'journals/ijitwe/YanHK22', 'DOI': '10.4018/ijitwe.288039', 'CorpusId': 244073216.0}, 'label': 0}\n",
      "{'paperId': '399cbcf0187197c8c371fcca1bd78cd3e529621c', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/399cbcf0187197c8c371fcca1bd78cd3e529621c', 'title': 'Named Entity Recognition in Electronic Health Records: A Methodological Review', 'abstract': 'Objectives A substantial portion of the data contained in Electronic Health Records (EHR) is unstructured, often appearing as free text. This format restricts its potential utility in clinical decision-making. Named entity recognition (NER) methods address the challenge of extracting pertinent information from unstructured text. The aim of this study was to outline the current NER methods and trace their evolution from 2011 to 2022. Methods We conducted a methodological literature review of NER methods, with a focus on distinguishing the classification models, the types of tagging systems, and the languages employed in various corpora. Results Several methods have been documented for automatically extracting relevant information from EHRs using natural language processing techniques such as NER and relation extraction (RE). These methods can automatically extract concepts, events, attributes, and other data, as well as the relationships between them. Most NER studies conducted thus far have utilized corpora in English or Chinese. Additionally, the bidirectional encoder representation from transformers using the BIO tagging system architecture is the most frequently reported classification scheme. We discovered a limited number of papers on the implementation of NER or RE tasks in EHRs within a specific clinical domain. Conclusions EHRs play a pivotal role in gathering clinical information and could serve as the primary source for automated clinical decision support systems. However, the creation of new corpora from EHRs in specific clinical domains is essential to facilitate the swift development of NER and RE models applied to EHRs for use in clinical practice.', 'externalIds': {'PubMedCentral': 10651400.0, 'DOI': '10.4258/hir.2023.29.4.286', 'CorpusId': 265105841.0, 'PubMed': 37964451.0}, 'label': 1}\n",
      "{'paperId': 'eb1cc140b14d0a8f5f789ba26e5e497a9776dd7e', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/eb1cc140b14d0a8f5f789ba26e5e497a9776dd7e', 'title': 'Annotating chemicals , diseases and their interactions in biomedical literature', 'abstract': 'Community-run formal evaluations and manually annotated text corpora are critically important for advancing biomedical text mining research. Recently in BioCreative V, a new challenge was organized for the tasks of disease named entity recognition (DNER) and chemical-induced disease (CID) relation extraction. Given the nature of both tasks, a test collection is required to contain both disease/chemical annotations and relation annotations in the same set of articles. Despite previous efforts in biomedical corpus construction, none were found to be sufficient for the task. Thus, we developed our own corpus during the challenge by inviting a team of expert annotators from both MeSH and the Comparative Toxicogenomics Database (CTD), who performed manual annotation of entities (diseases/chemicals) and relations, respectively. To ensure high annotation quality and productivity, detailed annotation guidelines and automatic annotation tools were provided. The resulting corpus consists of 1,500 PubMed articles with 4,409 annotated chemicals, 5,818 diseases, and 3,116 chemical-disease interactions. Each annotation includes both the mention text spans and normalized concept identifiers (MeSH was used as the controlled vocabulary). To ensure accuracy, the entities were captured independently by two annotators; the average inter-annotator agreement (IAA) scores are 88.75% and 96.31% for the disease and chemicals, respectively, in the test set according to the Jaccard similarity coefficient. Our corpus was successfully used for the BioCreative V challenge tasks and should serve as a valuable resource for the text-mining research community.', 'externalIds': {'CorpusId': 30300780.0}, 'label': 1}\n",
      "{'paperId': '771276afd7d079ec72d1ecce33ffd6f0fb5aa2ae', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/771276afd7d079ec72d1ecce33ffd6f0fb5aa2ae', 'title': 'A Comparative Analysis of Active Learning for Biomedical Text Mining', 'abstract': 'An enormous amount of clinical free-text information, such as pathology reports, progress reports, clinical notes and discharge summaries have been collected at hospitals and medical care clinics. These data provide an opportunity of developing many useful machine learning applications if the data could be transferred into a learn-able structure with appropriate labels for supervised learning. The annotation of this data has to be performed by qualified clinical experts, hence, limiting the use of this data due to the high cost of annotation. An underutilised technique of machine learning that can label new data called active learning (AL) is a promising candidate to address the high cost of the label the data. AL has been successfully applied to labelling speech recognition and text classification, however, there is a lack of literature investigating its use for clinical purposes. We performed a comparative investigation of various AL techniques using ML and deep learning (DL)-based strategies on three unique biomedical datasets. We investigated random sampling (RS), least confidence (LC), informative diversity and density (IDD), margin and maximum representativeness-diversity (MRD) AL query strategies. Our experiments show that AL has the potential to significantly reducing the cost of manual labelling. Furthermore, pre-labelling performed using AL expediates the labelling process by reducing the time required for labelling.', 'externalIds': {'MAG': 3138979178.0, 'DOI': '10.3390/ASI4010023', 'CorpusId': 233660408.0}, 'label': 1}\n",
      "{'paperId': 'db90127b3fdb45466f0930440bf01aaebbfa1f5c', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/db90127b3fdb45466f0930440bf01aaebbfa1f5c', 'title': 'Defining and Learning Refined Temporal Relations in the Clinical Narrative', 'abstract': 'We present refinements over existing temporal relation annotations in the Electronic Medical Record clinical narrative. We refined the THYME corpus annotations to more faithfully represent nuanced temporality and nuanced temporal-coreferential relations. The main contributions are in re-defining CONTAINS and OVERLAP relations into CONTAINS, CONTAINS-SUBEVENT, OVERLAP and NOTED-ON. We demonstrate that these refinements lead to substantial gains in learnability for state-of-the-art transformer models as compared to previously reported results on the original THYME corpus. We thus establish a baseline for the automatic extraction of these refined temporal relations. Although our study is done on clinical narrative, we believe it addresses far-reaching challenges that are corpus- and domain- agnostic.', 'externalIds': {'MAG': 3103341697.0, 'DBLP': 'conf/acl-louhi/Wright-BettnerL20', 'DOI': '10.18653/v1/2020.louhi-1.12', 'CorpusId': 226283778.0, 'ACL': '2020.louhi-1.12'}, 'label': 1}\n",
      "{'paperId': 'eb13873a4e4348b23ba436188e02aa509b5a6a54', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/eb13873a4e4348b23ba436188e02aa509b5a6a54', 'title': 'Self-supervised extractive text summarization for biomedical literatures', 'abstract': 'In this study, we propose a self-supervised approach to extractive text summarization for biomedical literature. The approach uses abstracts to find the most informative content in the article, then generate a summary for training a classification model. The Sentences in the abstract and literature were first embedded using BERT. A similarity-based model was then applied to label the informative sentences for training the classifier. We used logistic regression as our classification model and used the features of sentence embedding for the classification. The results showed the feasibility of employing the abstract to perform self-supervised training of a classification model to generate extractive summarization. This approach can enable automatic generation of one or two-page executive summaries of biomedical literature to keep clinicians and biomedical researchers up to date with the latest development', 'externalIds': {'DBLP': 'conf/ichi/XieZLLG21', 'DOI': '10.1109/ICHI52183.2021.00091', 'CorpusId': 238994346.0}, 'label': 1}\n",
      "{'paperId': 'c189ee5794fc966a637154478d985d92da040306', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/c189ee5794fc966a637154478d985d92da040306', 'title': 'A benchmark for automatic medical consultation system: frameworks, tasks and datasets', 'abstract': 'Abstract Motivation In recent years, interest has arisen in using machine learning to improve the efficiency of automatic medical consultation and enhance patient experience. In this article, we propose two frameworks to support automatic medical consultation, namely doctor–patient dialogue understanding and task-oriented interaction. We create a new large medical dialogue dataset with multi-level fine-grained annotations and establish five independent tasks, including named entity recognition, dialogue act classification, symptom label inference, medical report generation and diagnosis-oriented dialogue policy. Results We report a set of benchmark results for each task, which shows the usability of the dataset and sets a baseline for future studies. Availability and implementation Both code and data are available from https://github.com/lemuria-wchen/imcs21. Supplementary information Supplementary data are available at Bioinformatics online.', 'externalIds': {'DBLP': 'journals/corr/abs-2204-08997', 'PubMedCentral': 9848052.0, 'DOI': '10.1093/bioinformatics/btac817', 'CorpusId': 248239674.0, 'PubMed': 36539203.0, 'ArXiv': 2204.08997}, 'label': 1}\n",
      "{'paperId': '6416b5a45d52cf1b4cdb1b6683e7d9768914db20', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/6416b5a45d52cf1b4cdb1b6683e7d9768914db20', 'title': 'Glutathione S-Transferase M 1 , M 3 , P 1 , and T 1 Genetic Polymorphisms and Susceptibility to Breast Cancer 1', 'abstract': 'This study was undertaken to examine if glutathioneStransferase (GST)M1, M3, P1, andT1 genotypes affected breast cancer risk in Finnish women. The study population consisted of 483 incident breast cancer cases and 482 healthy population controls. Genotyping analyses were performed by PCR-based methods, and odds ratios (ORs) and 95% confidence intervals (CIs) were calculated by unconditional logistic regression adjusting for known or suspected risk factors for breast cancer. When the genes were studied separately, the only significant finding was betweenGSTM1 null genotype and postmenopausal breast cancer risk (OR, 1.49; 95% CI, 1.03–2.15). Conversely, when the potential combined effects of the at-risk genotypes were examined, significant associations were observed only among premenopausal women. Although only a moderate risk of breast cancer was seen for premenopausal women concurrently carrying the GSTM3*B allele containing genotypes and theGSTP1Ile/ Ile genotype (OR, 2.07; 95% CI, 1.02–4.18), the risk rose steeply if they simultaneously lacked theGSTT1gene (OR, 9.93, 95% CI, 1.10–90.0). A borderline significant increase in the risk of breast cancer was also seen for premenopausal women with the combination ofGSTM1 null, GSTP1Ile/Ile, and GSTT1null genotypes (OR, 3.96; 95% CI, 0.99–15.8). Our findings support the view that GST genotypes contribute to the individual breast cancer risk, especially in certain combinations. Introduction Breast cancer is both the prevailing malignancy and the most common cause of cancer death among women in Western countries (1, 2). The major risk factors for breast cancer are mainly related to reproductive events that influence lifetime levels of hormones (3, 4). The carcinogenicity of estrogen has been linked not only to its mitotic activity but also to the role of catechol estrogens as carcinogenic metabolites (5). Quinones, the further oxidized metabolites, are the ultimate reactive electrophiles capable of DNA binding if not inactivated by glutathione conjugation (6). There is also substantial evidence on the role of oxidative stress in relation to breast cancer risk (7–9). Reactive oxygen species may be generated through a number of mechanisms, including the redox cycling of quinones and semiquinones in the metabolism of estradiol (10). A large proportion of breast cancer cases cannot, however, be explained by the above mentioned risk factors. Identification of susceptibility factors that predispose individuals to breast cancer if they are exposed to particular environmental agents might give further insight into the etiology of this malignancy. It has been suggested that up to 80% of human cancers arise as a consequence of environmental exposure (11). The first line of defense is provided by the ability to metabolize and detoxify exogenous toxins (12). Therefore, inherited capacity for these metabolic activation and/or detoxification reactions may regulate individual susceptibility to environmentally induced diseases like cancer. GSTs are a superfamily of enzymes that are potentially important in regulating susceptibility to cancer because of their ability to metabolize reactive electrophilic intermediates to usually less reactive and more water soluble glutathione conjugates (13). To date, four polymorphic families of cytosolic soluble GSTs ( a, m, p, andu) of potential effect in this context have been identified in humans (13, 14). The absence of GSTM1 and GSTT1 enzyme activities in about 50% and 10–25% of Caucasians, respectively, is caused by homozygous deletion (null genotypes) of the corresponding genes (15). In GSTM3gene, theGSTM3*Awild type andGSTM3*B variant allele differ from each other by a deletion of three bp in intron 6 resulting in the generation of a recognition sequence for the YY1 transcription factor in the latter. The functional consequences of this are still unclear, but both negative and positive regulatory effects have been suggested (16, 17). Relatively little is known about the role of GSTM3 in the metabolism of harmful agents, except having overlapping substrate specificity with GSTM1 (13). For GSTP1 gene, two variant alleles, GSTP1*B and GSTP1*C, have been detected in addition to the wild-type Received 9/1/00; revised 1/3/01; accepted 1/10/01. The costs of publication of this article were defrayed in part by the payment of page charges. This article must therefore be hereby marked advertisementin accordance with 18 U.S.C. Section 1734 solely to indicate this fact. 1 Supported by the Academy of Finland, the Finnish Konkordia Foundation, and EVO funds from Kuopio University Hospital. 2 To whom requests for reprints should be addressed, at Molecular Epidemiology Group, Department of Industrial Hygiene and Toxicology, Finnish Institute of Occupational Health, Topeliuksenkatu 41 a A, FIN-00250 Helsinki, Finland. Phone: 358-9-4747-2204; Fax: 358-9-4747-2110; E-mail: Ari.Hirvonen@occuphealth.fi. 3 The abbreviations used are: GST, Glutathione S-transferase; OR, odds ratio; CI, confidence interval; WHR, waist-to-hip ratio; BMI, body-mass index. 229 Vol. 10, 229–236, March 2001 Cancer Epidemiology, Biomarkers & Prevention on November 6, 2017. © 2001 American Association for Cancer Research. cebp.aacrjournals.org Downloaded from alleleGSTP1*A(18). In both variant alleles, a point mutation at nucleotide 313 results in a single amino acid change from isoleucine (Ile) to valine (Val) at codon 105. This residue lies in close proximity to the hydrophobic binding site for electrophilic substrates (19), and the Val 105 variant allele has been demonstrated to exhibit altered specific activity and affinity for electrophilic substrates (20). The GSTM1genotype has been related to the individual breast cancer risk in several recent studies (21), some of which suggested an association between GSTM1null genotype and breast cancer risk in postmenopausal women (22, 23), whereas others found no association (24–29). In contrast toGSTM1, there is little data on the potential role of GSTP1andGSTT1genotypes in breast cancer risk, and no studies have yet been reported on GSTM3and breast cancer. Two recent studies (29, 30) revealed no significant association between theGSTP1genotypes and breast cancer proneness, although one study (23) suggested a trend for increasing risk with higher numbers of GSTP1Val alleles. Similarly, three recent studies found no association between the GSTT1null genotype and the breast cancer risk (23, 26, 29), but one study (31) suggested a remarkably lower risk for premenopausal women lacking theGSTT1gene. There are several potential reasons for the inconsistencies in the outcomes of the above studies; they may arise from an inadequate number of study subjects, unknown menopausal status, or the lack of information or population differences on the other risk factors known to confer breast cancer risk. Moreover, because GSTs are known to have overlapping substrate specificities, deficiencies of GST isoenzymes may be compensated by other isoforms. Simultaneous determination of all of the relevant genotypes for a given exposure may, therefore, be a prerequisite for reliable interpretation of the results. We investigated the potential role of all of the four polymorphic GSTgenes in susceptibility to breast cancer in a Finnish Caucasian study population consisting of 483 incident breast cancer patients and 482 population controls. Materials and Methods Study Population. This study is an extension of Kuopio Breast Cancer Study, a prospective study that follows the protocol of the International Collaborative Study of Breast and Colorectal Cancer coordinated by the European Institute of Oncology in Milan. Women with a suspect breast lump and living in the study catchment area between 1990 and 1995 were invited to Kuopio University Hospital for additional examinations and final diagnosis. They were asked to participate in the study at the first hospital examination and were interviewed by a trained study nurse before any diagnostic procedures. The recruitment protocol missed 51 women later diagnosed with breast cancer, all of who were private patients who did not enter the hospital by the standard procedure. Furthermore, 11 cases were missed during the nurses’ one-month strike in 1995. According to comparison with the Finnish Cancer Registry, only 26 breast cancer cases were treated elsewhere. Five hundred and sixteen of the women who agreed to participate in the study and 12 of the women who had refused to participate in the study were finally diagnosed with breast cancer. Thus, the participation rate of the cases was 98%. Healthy controls were drawn from the Finnish National Population Register covering the catchment area of the cases. They were initially contacted by a letter explaining the study protocol and later called up by a research nurse. In all, 514 controls were interviewed in parallel with the cases. The participation rate for population controls was 72%. Detailed data on socioeconomic background, reproduction history, medical history, family history of breast cancer, current alcohol intake, smoking, and body-size indicators (height, weight, waist, and hip circumferences) were recorded (32). All of the blood samples were collected before diagnosis and stored at220°C before DNA extraction. For this study, DNA sample was available for 486 cases and 492 controls. Four population controls were excluded from the study because they had earlier breast cancer diagnosis, and two were excluded because of their non-Finnish origin. In addition, three cases and four controls were excluded because genotype data could not be obtained for them. Thus the final study population consisted of 483 histologically confirmed breast cancer cases and 482 population controls; all of them were Finnish Caucasians. Genotyping Analyses.Genomic DNA (100 ng), extracted from lymphocytes by standard techniques, was used as template in the genotyping analyses performed blinded to the c', 'externalIds': {'CorpusId': 2523438.0}, 'label': 0}\n",
      "{'paperId': '23dc7a1fb8837f9c3fb04f616d017f7687f4a467', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/23dc7a1fb8837f9c3fb04f616d017f7687f4a467', 'title': 'SRT’s Neural Machine Translation System for WMT22 Biomedical Translation Task', 'abstract': 'This paper describes the Samsung Research’s Translation system (SRT) submitted to the WMT22 biomedical translation task in two language directions: English to Spanish and Spanish to English. To improve the overall quality, we adopt the deep transformer architecture and employ the back-translation strategy for monolingual corpus. One of the issues in the domain translation is to translate domain-specific terminologies well. To address this issue, we apply the soft-constrained terminology translation based on biomedical terminology dictionaries. In this paper, we provide the performance of our system with WMT20 and WMT21 biomedical testsets. Compared to the best model in WMT20 and WMT21, our system shows equal or better performance. According to the official evaluation results in terms of BLEU scores, our systems get the highest scores in both directions.', 'externalIds': {'DBLP': 'conf/wmt/ChoiSRK22', 'CorpusId': 256460974.0, 'ACL': '2022.wmt-1.83'}, 'label': 1}\n",
      "{'paperId': '66bda495f4bba7afc0dafca63fd098558d410feb', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/66bda495f4bba7afc0dafca63fd098558d410feb', 'title': 'Predicting Informativeness of Semantic Triples', 'abstract': 'Many automatic semantic relation extraction tools extract subject-predicate-object triples from unstructured text. However, a large quantity of these triples merely represent background knowledge. We explore using full texts of biomedical publications to create a training corpus of informative and important semantic triples based on the notion that the main contributions of an article are summarized in its abstract. This corpus is used to train a deep learning classifier to identify important triples, and we suggest that an importance ranking for semantic triples could also be generated.', 'externalIds': {'DBLP': 'conf/ranlp/Preiss21', 'DOI': '10.26615/978-954-452-072-4_126', 'CorpusId': 244071275.0, 'ACL': '2021.ranlp-1.126'}, 'label': 0}\n",
      "{'paperId': 'f79fe4b4d39f1aa74bb5e16e7e014c436da183f1', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/f79fe4b4d39f1aa74bb5e16e7e014c436da183f1', 'title': 'Domain Adaptation for Medical Semantic Textual Similarity', 'abstract': 'Semantic textual similarity is a common task to determine whether two sentences in a pair own the same meaning. In the medical domain, the annotated data is limited and sparse, which brings great difficulty to obtain accurate semantic information from it. In this paper, we propose a two-stream model to adapt knowledge learned from other domains to the medical domain. To optimize and reduce the computation, we further compress the proposed model by knowledge distillation. Experimental results show that our proposed method achieves better performance than the baseline methods.', 'externalIds': {'DBLP': 'conf/icnidc/SunL21', 'DOI': '10.1109/IC-NIDC54101.2021.9660484', 'CorpusId': 245708330.0}, 'label': 1}\n",
      "{'paperId': '53dec7a5ffd7bdc9e78448e4494413762f30d802', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/53dec7a5ffd7bdc9e78448e4494413762f30d802', 'title': 'Building Patterns for Biomedical Event Extraction', 'abstract': 'Generally, Event Extraction is to identify any instance of a particular class of events in a natural language text, to extract the relevant arguments of the event, and to represent the extracted information into a structured form.1Let us define Event on the binary relation between two entities for special event verbs which are predefined by biologists. Here, Entity means biomedical entities such as proteins, genes, cells, tissues, etc. According to the definition of event, our event extraction system considers only such sentences which contain at least one event verb and two entities. The training consists of two procedures (Figure 1). First, the preprocessor involves chunking, named entity tagging, dependency relation tagging and sentence normalization with special items for building patterns. Special items are entities, event verbs, non-event verbs, prepositions, relatives, conjunctions and symbols. Second, all possible candidate events are extracted from the training corpus and the corresponding patterns are also generated. At this time, we utilize the following assumptions: one event can be described by one or more patterns in the whole documents and one pattern also can be generated by one or more events. Therefore, the event and the pattern information has reciprocal relation. We use the event score (Equation 1) to measure the reliability of extracted events and the pattern score (Equation 2) to measure the reliability of extracted patterns. The scores are iteratively updated in a co-updating method. Updating the event score causes reranking of candidate events and the iteration is continued until the ranking of events is no longer changed. The result of the training is a set of generated patterns and their scores. The events in training corpus are also extracted as the by-product of the training.', 'externalIds': {'CorpusId': 16527801.0}, 'label': 1}\n",
      "{'paperId': '640bbec28cd16c2c986215a354d2fbabfa058501', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/640bbec28cd16c2c986215a354d2fbabfa058501', 'title': 'Zero-shot sampling of adversarial entities in biomedical question answering', 'abstract': 'The increasing depth of parametric domain knowledge in large language models (LLMs) is fueling their rapid deployment in real-world applications. In high-stakes and knowledge-intensive tasks, understanding model vulnerabilities is essential for quantifying the trustworthiness of model predictions and regulating their use. The recent discovery of named entities as adversarial examples in natural language processing tasks raises questions about their potential guises in other settings. Here, we propose a powerscaled distance-weighted sampling scheme in embedding space to discover diverse adversarial entities as distractors. We demonstrate its advantage over random sampling in adversarial question answering on biomedical topics. Our approach enables the exploration of different regions on the attack surface, which reveals two regimes of adversarial entities that markedly differ in their characteristics. Moreover, we show that the attacks successfully manipulate token-wise Shapley value explanations, which become deceptive in the adversarial setting. Our investigations illustrate the brittleness of domain knowledge in LLMs and reveal a shortcoming of standard evaluations for high-capacity models.', 'externalIds': {'DBLP': 'journals/corr/abs-2402-10527', 'DOI': '10.48550/arXiv.2402.10527', 'CorpusId': 267740295.0, 'ArXiv': 2402.10527}, 'label': 1}\n",
      "{'paperId': '9309e03c5ea14eb1306fc832f3000ee89411b939', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/9309e03c5ea14eb1306fc832f3000ee89411b939', 'title': 'Joint Extraction of Uyghur Medicine Knowledge with Edge Computing', 'abstract': 'Medical knowledge extraction methods based on edge computing deploy deep learning models on edge devices to achieve localized entity and relation extraction. This approach avoids transferring substantial sensitive data to cloud data centers, effectively safeguarding the privacy of healthcare services. However, existing relation extraction methods mainly employ a sequential pipeline approach, which classifies relations between determined entities after entity recognition. This mode faces challenges such as error propagation between tasks, insufficient consideration of dependencies between the two subtasks, and the neglect of interrelations between different relations within a sentence. To address these challenges, a joint extraction model with parameter sharing in edge computing is proposed, named CoEx-Bert. This model leverages shared parameterization between two models to jointly extract entities and relations. Specifically, CoEx-Bert employs two models, each separately sharing hidden layer parameters, and combines these two loss functions for joint backpropagation to optimize the model parameters. Additionally, it effectively resolves the issue of entity overlapping when extracting knowledge from unstructured Uyghur medical texts by considering contextual relations. Finally, this model is deployed on edge devices for real-time extraction and inference of Uyghur medical knowledge. Experimental results demonstrate that CoEx-Bert outperforms existing state-of-the-art methods, achieving accuracy, recall, and F1 scores of 90.65\\\\%, 92.45\\\\%, and 91.54\\\\%, respectively, in the Uyghur traditional medical literature dataset. These improvements represent a 6.45\\\\% increase in accuracy, a 9.45\\\\% increase in recall, and a 7.95\\\\% increase in F1 score compared to the baseline.', 'externalIds': {'DBLP': 'journals/corr/abs-2401-07009', 'DOI': '10.48550/arXiv.2401.07009', 'CorpusId': 266998914.0, 'ArXiv': 2401.07009}, 'label': 1}\n",
      "{'paperId': 'dbfc044a9ee9a36ba307fe6ea850ba5233bcc619', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/dbfc044a9ee9a36ba307fe6ea850ba5233bcc619', 'title': 'A small regulatory core that discriminates the gene expression profiles of cancer points to a ‘Medusa’ structure of the genomic network', 'abstract': 'Over the past decades, researchers seeking to understand molecular mechanisms underlying various diseases, notably cancer, have taken advantage of DNA microarrays to interrogate tissue specimen of patients for the expression status of thousands of genes at once. Jointly, such gene expression status of each gene in the genome, measured as the level of their transcripts, constitutes the gene expression profile. Since each of the tens of thousands of genes can be switched on or off, a gene expression profile contains complex information, akin to a huge bar code with tens of thousands of digits for every sample. While microarray data were initially used by gene hunters to identify novel genes, such as those which are only active in samples of particular cancer tissues, researchers have later learned to employ sophisticated computational tools to classify these bar codes into subgroups and to find subgroup-specific signatures. In cancer research such statistical analysis of gene expression patterns can serve to identify new cancer subtypes and help classify patients more accurately. However, there is only so much that such brute force computational pattern recognition can offer. Biologists also would like to understand: Where the particular gene expression pattern comes from? How does the cell know how to ‘write’ the long bar code, defining the expression level of gene after gene, across tens of thousands of genes, in such a reliable manner to encode cell types and cancer cell phenotypes? Although not often asked by computational biologists using statistical analysis to extract information, this is a central and basic biological question. A team of researchers at Harvard Medical School’s Children’s Hospital led by Sui Huang (who is now at the University of Calgary) have analyzed gene expression profiles with precisely this question in mind. In the work published on page 628 of this issue of Experimental Biology and Medicine, Dr Huang and his students, Guo, Feng and Trivedi, offer a first step towards understanding the source of the stable pattern of gene expression profiles by testing whether gene expression profiles are indeed established by a gene regulatory network that has the structure of a ‘medusa,’ with a command and control ‘head’ and an enslaved periphery, as proposed by theoreticians. ‘We tend to take gene expression profiles for granted – much like the forensic examiner looks at finger prints without ever asking how they are produced in development,’ Dr Huang says. The expression of a gene is regulated by particular types of proteins, the transcription factors (TFs), of which there are 2000 or so in the human genome. Thus, obviously, the entire gene expression profile, the tens of thousands digit bar code, is determined by the collective activity of these TFs. Since they also control the expression of each other, this subset of TF genes forms a ‘core network’ of mutual regulation. In addition, they must also control the ‘non-TF’ work horse proteins of the cell, such as cytoskeletal proteins or metabolic enzymes which are also regulated by TFs (as are all genes) but do not regulate the expression of other genes. In this elementary picture, the pattern of the gene expression bar code would be determined essentially by the core network which represents the medusa head and controls the peripheral, regulated but not-regulating genes, the medusa arms (tentacles). If the entire gene expression profile, the bar code that characterizes the phenotype of cell types, is controlled by the core of a just few thousands genes rather than the entire genome of tens of thousands of genes, then as Dr Huang explains ‘this would have practical consequences beyond theoretical biology, for it would facilitate gene expression pattern based disease characterisation and diagnosis by allowing efficient computation focused on the regulatory core.’ Huang’s team has now used a set of gene expression profiles of lung cancer tissues from a group of patients to show that the expression patterns are consistent with a medusa network. They found using various statistical tests that instead of the entire set of almost 10,000 genes available on the DNA microarrays less than a thousand TF genes were sufficient to classify the patient lung cancer samples according to the diagnosed cancer types. The subset of a few hundred TFs performed as well or better than the set of nearly 10,000 genes that represent much of the genome. The effect persisted after correction for gene number and expression levels. Conversely, metabolic genes that would correspond to the subordinate arms of the medusa, and hence should have minimal influence on the gene expression profile, performed most poorly in the same comparison. Interestingly, Huang and his group also found that microRNAs, a class of regulatory transcripts that do not encode for proteins but contain nucleotide sequence complementary to protein coding transcripts that allow them to specifically target the latter and prevent translation into proteins, were even more powerful than TFs. Since microRNAs are part of the regulatory core, this was not entirely surprising. But why did they perform so much better than TFs? As Huang explains, continuing to draw the analogy of', 'externalIds': {'DOI': '10.1258/ebm.2011.011f05', 'CorpusId': 38508329.0, 'PubMed': 21714146.0}, 'label': 0}\n",
      "{'paperId': 'a24ef0cc13f3641ed15708471244b630a179d044', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/a24ef0cc13f3641ed15708471244b630a179d044', 'title': 'Addressing Limited Data for Textual Entailment Across Domains', 'abstract': 'We seek to address the lack of labeled data (and high cost of annotation) for textual entailment in some domains. To that end, we first create (for experimental purposes) an entailment dataset for the clinical domain, and a highly competitive supervised entailment system, ENT, that is effective (out of the box) on two domains. We then explore self-training and active learning strategies to address the lack of labeled data. With self-training, we successfully exploit unlabeled data to improve over ENT by 15% F-score on the newswire domain, and 13% F-score on clinical data. On the other hand, our active learning experiments demonstrate that we can match (and even beat) ENT using only 6.6% of the training data in the clinical domain, and only 5.8% of the training data in the newswire domain.', 'externalIds': {'MAG': 2419247925.0, 'DBLP': 'conf/acl/ShivadeRP16', 'DOI': '10.18653/v1/P16-1118', 'CorpusId': 16775562.0, 'ACL': 'P16-1118', 'ArXiv': 1606.02638}, 'label': 0}\n",
      "{'paperId': '93626c85865dd3fffed73b1cf8299ec739aad9dd', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/93626c85865dd3fffed73b1cf8299ec739aad9dd', 'title': 'Semantic Relatedness and Similarity Reference Standards for Medical Terms', 'abstract': '1. MayoSRS.csv: A set of 101 medical concept pairs manually rater by medical coders for semantic relatedness.', 'externalIds': {'MAG': 2887442125.0, 'DOI': '10.13020/D6CX04', 'CorpusId': 56965311.0}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' ', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': '2. MiniMayoSRS.csv: A subset of 29 medical concept pairs manually rater by medical coders for semantic relatedness with high inter-rater agreement.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' ', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': '3. UMNSRS_similarity.csv: A set of 566 UMLS concept pairs manually rated for semantic similarity using a continuous response scale.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' ', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': '4. UMNSRS_relatedenss.csv: A set of 588 UMLS concept pairs manually rated for semantic relatedness using a continuous response scale.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' ', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': '5. UMNSRS_similarity_mod449_word2vec.csv: Modification of the UMNSRS-Similarity dataset to exclude control samples and those pairs that did not match text in clinical, biomedical and general English corpora. Exact modifications are detailed in the referenced paper. The resulting dataset contains 449 pairs.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' ', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': '6. UMNSRS_relatedness_mod458_word2vec.csv: Modification of the UMNSRS-Similarity dataset to exclude control samples and those pairs that did not match text in clinical, biomedical and general English corpora. Exact modifications are detailed in the referenced paper. The resulting dataset contains 458 pairs.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': '938c961875763eef6ca08639dbd5cc5005931e93', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/938c961875763eef6ca08639dbd5cc5005931e93', 'title': 'The polymerase chain reaction: Miracle or mirage? A critical review of its uses and limitations in diagnosis and research', 'abstract': 'Since publication of the polymerase chain reaction (PCR) technique in 1985 (Saiki et al. Science 1985; 230: 1350–1354), there has been an explosion of reports on its use in medicine and science. We critically review its use both as a diagnostic technique and as a research tool, and show the pathologist how to evaluate PCR data and how to avoid the pitfalls of overinterpretation. We discuss the value of PCR in the characterization of genetic defects, prenatal diagnosis, carrier testing, H LA typing, detecting micro‐organisms, identifying activated oncogenes, and in the characterization of leukaemias and lymphomas, and summarize the main applications in biomedical research.', 'externalIds': {'MAG': 2154595239.0, 'DOI': '10.1002/path.1711620203', 'CorpusId': 44701848.0, 'PubMed': 2250198.0}, 'label': 0}\n",
      "{'paperId': 'aa0312b080da7e3e821c59d5ebc81058b4a7ba30', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/aa0312b080da7e3e821c59d5ebc81058b4a7ba30', 'title': 'Terminology-based knowledge mining for new knowledge discovery', 'abstract': 'In this article we present an integrated knowledge-mining system for the domain of biomedicine, in which automatic term recognition, term clustering, information retrieval, and visualization are combined. The primary objective of this system is to facilitate knowledge acquisition from documents and aid knowledge discovery through terminology-based similarity calculation and visualization of automatically structured knowledge. This system also supports the integration of different types of databases and simultaneous retrieval of different types of knowledge. In order to accelerate knowledge discovery, we also propose a visualization method for generating similarity-based knowledge maps. The method is based on real-time terminology-based knowledge clustering and categorization and allows users to observe real-time generated knowledge maps, graphically. Lastly, we discuss experiments using the GENIA corpus to assess the practicality and applicability of the system.', 'externalIds': {'MAG': 2045315960.0, 'DBLP': 'journals/talip/MimaAM06', 'DOI': '10.1145/1131348.1131354', 'CorpusId': 17433436.0}, 'label': 1}\n",
      "{'paperId': 'b2958aaf41a251e3aca11ca8e633dc71e15ebe81', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/b2958aaf41a251e3aca11ca8e633dc71e15ebe81', 'title': 'The 22 nd Annual Conference of the Japanese Society for Artificial Intelligence , 2008-1-Classifying biomedical text abstracts using binary and multi-class Support Vector Machine', 'abstract': 'Text classification systems on biomedical literature aim to select relevant articles that match query keywords from large corpora. For this purpose, systems for finding relevant documents must be able to identify terms related to the search in the abstracts and also must distinguish between relevant and irrelevant results. Lately, many researchers attempt to find more applicable ways for classifying biomedical text articles in order to help users find relevant articles on the web. Due to this reason, our focus is on the problem of identifying relevant and irrelevant documents based on binary and multi-class classification in biomedical texts, especially for text biomedical abstracts. For our experiments, we have randomly downloaded and collected 400 paper abstracts of four diseases, including cancer, hepatitis, HIV/AIDS and thyroid from Medline database. Then, we have tested and compared the performance of binary classification and multi-class classification using LIBSVM. The results obtained in our experiments demonstrate that the accuracy of binary classification on the average 80.89% (with scaling) and 86.92% (without scaling), meanwhile multi-class classification on the average 75.73% (with scaling) and 85.25% (without scaling) for our biomedical text data with four categories of diseases. We observe that the choice of percentage for training and testing dataset has little influence on the classification accuracy.', 'externalIds': {'CorpusId': 145030843.0}, 'label': 1}\n",
      "{'paperId': 'ebbbdb79772704c351711adc3df60ae2113de706', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/ebbbdb79772704c351711adc3df60ae2113de706', 'title': 'Enhancing Extraction of Drug-Drug Interaction from Literature Using Neutral Candidates, Negation, and Clause Dependency', 'abstract': 'Motivation Supervised biomedical relation extraction plays an important role in biomedical natural language processing, endeavoring to obtain the relations between biomedical entities. Drug-drug interactions, which are investigated in the present paper, are notably among the critical biomedical relations. Thus far many methods have been developed with the aim of extracting DDI relations. However, unfortunately there has been a scarcity of comprehensive studies on the effects of negation, complex sentences, clause dependency, and neutral candidates in the course of DDI extraction from biomedical articles. Results Our study proposes clause dependency features and a number of features for identifying neutral candidates as well as negation cues and scopes. Furthermore, our experiments indicate that the proposed features significantly improve the performance of the relation extraction task combined with other kernel methods. We characterize the contribution of each category of features and finally conclude that neutral candidate features have the most prominent role among all of the three categories.', 'externalIds': {'MAG': 2528213836.0, 'PubMedCentral': 5047471.0, 'DOI': '10.1371/journal.pone.0163480', 'CorpusId': 15062879.0, 'PubMed': 27695078.0}, 'label': 1}\n",
      "{'paperId': '3b93e6f04e8817174a3de2042982aaed3ee01bc3', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/3b93e6f04e8817174a3de2042982aaed3ee01bc3', 'title': 'Cloning and sequencing of cDNAs coding for the human intra-acrosomal antigen SP-10.', 'abstract': 'cDNAs coding for the intra-acrosomal protein SP-10 were cloned and characterized as a first step in understanding the expression of this antigen during spermatogenesis. Three overlapping SP-10-specific cDNAs were isolated from a human testes cDNA expression library. These cDNAs hybridized to a 1.35-kb mRNA that was present in human testes but was not found in liver or placenta. Complete sequencing of these cDNAs, designated SP-10-5, SP-10-8, and SP-10-10, produced an 1117-bp sequence containing a 265-amino acid-coding region for the SP-10 protein. Hydrophobicity plots generated from the deduced amino acid sequence showed a very hydrophobic amino terminus characteristic of a signal peptide. Sequence data showed that three different amino acid repeats occurred a total of 16 times in the central third of the SP-10 protein. Interestingly, cDNA SP-10-10 has an internal 57-base pair (19 amino acids) in-frame deletion that is not present in SP-10-5, suggesting that alternative splicing generates more than one SP-10 mRNA. The SP-10 protein appears to be a unique acrosomal protein, based on previous immunohistological data and the observation that SP-10 cDNA sequences did not show any significant homology to other sequences found in the Genbank, National Biomedical Research Foundation, or Swiss sequence banks. A recombinant SP-10 fusion protein was produced in an Escherichia coli expression vector and used to generate a polyclonal antiserum. This antiserum stained the acrosomal cap in situ and reacted with a similar set of peptides on Western blots as did a monoclonal antibody to SP-10.', 'externalIds': {'MAG': 2182859426.0, 'DOI': '10.1095/BIOLREPROD42.4.693', 'CorpusId': 5178411.0, 'PubMed': 1693291.0}, 'label': 0}\n",
      "{'paperId': '3441b2a5c02f434e04ff437799eadb7fcbd242f7', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/3441b2a5c02f434e04ff437799eadb7fcbd242f7', 'title': 'Modeling biomedical assertions in the semantic web', 'abstract': 'We present an enhanced version of an ontological framework called MachineProse that is meant to represent the evolving knowledge resulting from biomedical research. This framework bridges the semantic gap between the use of keywords or controlled vocabularies to index articles and the expressive free-text content of research papers. The benefits of the framework are the ability to carry out precise searches to retrieve relevant literature, and novel abilities to provide answers to questions. We illustrate MachineProse with a case study of its application to Evidence Based Medicine.', 'externalIds': {'MAG': 2093027613.0, 'DBLP': 'conf/sac/DinakarpandianTL07', 'DOI': '10.1145/1244002.1244295', 'CorpusId': 3239336.0}, 'label': 1}\n",
      "{'paperId': 'f6055cf63e4d24c75f8ff4c3c7e2fbd7a2695119', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/f6055cf63e4d24c75f8ff4c3c7e2fbd7a2695119', 'title': 'SAIS: Supervising and Augmenting Intermediate Steps for Document-Level Relation Extraction', 'abstract': 'Stepping from sentence-level to document-level, the research on relation extraction (RE) confronts increasing text length and more complicated entity interactions. Consequently, it is more challenging to encode the key information sources—relevant contexts and entity types. However, existing methods only implicitly learn to model these critical information sources while being trained for RE. As a result, they suffer the problems of ineffective supervision and uninterpretable model predictions. In contrast, we propose to explicitly teach the model to capture relevant contexts and entity types by supervising and augmenting intermediate steps (SAIS) for RE. Based on a broad spectrum of carefully designed tasks, our proposed SAIS method not only extracts relations of better quality due to more effective supervision, but also retrieves the corresponding supporting evidence more accurately so as to enhance interpretability. By assessing model uncertainty, SAIS further boosts the performance via evidence-based data augmentation and ensemble inference while reducing the computational cost. Eventually, SAIS delivers state-of-the-art RE results on three benchmarks (DocRED, CDR, and GDA) and outperforms the runner-up by 5.04% relatively in F1 score in evidence retrieval on DocRED.', 'externalIds': {'DBLP': 'journals/corr/abs-2109-12093', 'DOI': '10.18653/v1/2022.naacl-main.171', 'CorpusId': 237635295.0, 'ACL': '2022.naacl-main.171', 'ArXiv': 2109.12093}, 'label': 0}\n",
      "{'paperId': '5eee280d8cba0956ec410a7cdccc49d1611a6168', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/5eee280d8cba0956ec410a7cdccc49d1611a6168', 'title': 'Marginal Likelihood Training of BiLSTM-CRF for Biomedical Named Entity Recognition from Disjoint Label Sets', 'abstract': 'Extracting typed entity mentions from text is a fundamental component to language understanding and reasoning. While there exist substantial labeled text datasets for multiple subsets of biomedical entity types—such as genes and proteins, or chemicals and diseases—it is rare to find large labeled datasets containing labels for all desired entity types together. This paper presents a method for training a single CRF extractor from multiple datasets with disjoint or partially overlapping sets of entity types. Our approach employs marginal likelihood training to insist on labels that are present in the data, while filling in “missing labels”. This allows us to leverage all the available data within a single model. In experimental results on the Biocreative V CDR (chemicals/diseases), Biocreative VI ChemProt (chemicals/proteins) and MedMentions (19 entity types) datasets, we show that joint training on multiple datasets improves NER F1 over training in isolation, and our methods achieve state-of-the-art results.', 'externalIds': {'MAG': 2889869899.0, 'DBLP': 'conf/emnlp/GreenbergBVM18', 'DOI': '10.18653/v1/D18-1306', 'CorpusId': 53082686.0, 'ACL': 'D18-1306'}, 'label': 1}\n",
      "{'paperId': '173d8a79318fa472e76c4512b5a0e25c0ad7e9b0', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/173d8a79318fa472e76c4512b5a0e25c0ad7e9b0', 'title': 'Joint Extraction of Entities and Overlapping Relations Using Position-Attentive Sequence Labeling', 'abstract': 'Joint entity and relation extraction is to detect entity and relation using a single model. In this paper, we present a novel unified joint extraction model which directly tags entity and relation labels according to a query word position p, i.e., detecting entity at p, and identifying entities at other positions that have relationship with the former. To this end, we first design a tagging scheme to generate n tag sequences for an n-word sentence. Then a position-attention mechanism is introduced to produce different sentence representations for every query position to model these n tag sequences. In this way, our method can simultaneously extract all entities and their type, as well as all overlapping relations. Experiment results show that our framework performances significantly better on extracting overlapping relations as well as detecting long-range relation, and thus we achieve state-of-the-art performance on two public datasets.', 'externalIds': {'MAG': 2905462022.0, 'DBLP': 'conf/aaai/DaiXLDSW19', 'DOI': '10.1609/AAAI.V33I01.33016300', 'CorpusId': 69848964.0}, 'label': 0}\n",
      "{'paperId': '3598e8b4664477cb82b9887c78e4d178a2437f5c', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/3598e8b4664477cb82b9887c78e4d178a2437f5c', 'title': 'The Genia Event Extraction Shared Task, 2013 Edition - Overview', 'abstract': 'The Genia Event Extraction task is organized for the third time, in BioNLP Shared Task 2013. Toward knowledge based construction, the task is modified in a number of points. As the final results, it received 12 submissions, among which 2 were withdrawn from the final report. This paper presents the task setting, data sets, and the final results with discussion for possible future directions.', 'externalIds': {'MAG': 2250469303.0, 'DBLP': 'conf/bionlp/KimWY13', 'CorpusId': 20209175.0, 'ACL': 'W13-2002'}, 'label': 1}\n",
      "{'paperId': '277594a9a545decbdd35f1be60c811cc6c1e0e7c', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/277594a9a545decbdd35f1be60c811cc6c1e0e7c', 'title': 'A robust approach to extract biomedical events from literature', 'abstract': 'MOTIVATION', 'externalIds': {'MAG': 2097300420.0, 'DBLP': 'journals/bioinformatics/BuiS12', 'DOI': '10.1093/bioinformatics/bts487', 'CorpusId': 2678540.0, 'PubMed': 22859502.0}, 'label': 1}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'The abundance of biomedical literature has attracted significant interest in novel methods to automatically extract biomedical relations from the literature. Until recently, most research was focused on extracting binary relations such as protein-protein interactions and drug-disease relations. However, these binary relations cannot fully represent the original biomedical data. Therefore, there is a need for methods that can extract fine-grained and complex relations known as biomedical events.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'RESULTS', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'In this article we propose a novel method to extract biomedical events from text. Our method consists of two phases. In the first phase, training data are mapped into structured representations. Based on that, templates are used to extract rules automatically. In the second phase, extraction methods are developed to process the obtained rules. When evaluated against the Genia event extraction abstract and full-text test datasets (Task 1), we obtain results with F-scores of 52.34 and 53.34, respectively, which are comparable to the state-of-the-art systems. Furthermore, our system achieves superior performance in terms of computational efficiency.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'AVAILABILITY', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Our source code is available for academic use at http://dl.dropbox.com/u/10256952/BioEvent.zip.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': '364ce0b25adda96d5110d52820f264186af2b686', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/364ce0b25adda96d5110d52820f264186af2b686', 'title': 'Cost-aware active learning for named entity recognition in clinical text', 'abstract': 'OBJECTIVE', 'externalIds': {'MAG': 2959026463.0, 'DBLP': 'journals/jamia/WeiCSDMLCWFCX19', 'DOI': '10.1093/jamia/ocz102', 'CorpusId': 61911748.0, 'PubMed': 31294792.0}, 'label': 1}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Active Learning (AL) attempts to reduce annotation cost (ie, time) by selecting the most informative examples for annotation. Most approaches tacitly (and unrealistically) assume that the cost for annotating each sample is identical. This study introduces a cost-aware AL method, which simultaneously models both the annotation cost and the informativeness of the samples and evaluates both via simulation and user studies.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'MATERIALS AND METHODS', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'We designed a novel, cost-aware AL algorithm (Cost-CAUSE) for annotating clinical named entities; we first utilized lexical and syntactic features to estimate annotation cost, then we incorporated this cost measure into an existing AL algorithm. Using the 2010 i2b2/VA data set, we then conducted a simulation study comparing Cost-CAUSE with noncost-aware AL methods, and a user study comparing Cost-CAUSE with passive learning.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'RESULTS', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Our cost model fit empirical annotation data well, and Cost-CAUSE increased the simulation area under the learning curve (ALC) scores by up to 5.6% and 4.9%, compared with random sampling and alternate AL methods. Moreover, in a user annotation task, Cost-CAUSE outperformed passive learning on the ALC score and reduced annotation time by 20.5%-30.2%.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'DISCUSSION', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Although AL has proven effective in simulations, our user study shows that a real-world environment is far more complex. Other factors have a noticeable effect on the AL method, such as the annotation accuracy of users, the tiredness of users, and even the physical and mental condition of users.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'CONCLUSION', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Cost-CAUSE saves significant annotation cost compared to random sampling.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': '46b75e94359653e26d290d7771b82e54f157b9c4', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/46b75e94359653e26d290d7771b82e54f157b9c4', 'title': 'Biomedical and Clinical Language Models for Spanish: On the Benefits of Domain-Specific Pretraining in a Mid-Resource Scenario', 'abstract': \"This work presents biomedical and clinical language models for Spanish by experimenting with different pretraining choices, such as masking at word and subword level, varying the vocabulary size and testing with domain data, looking for better language representations. Interestingly, in the absence of enough clinical data to train a model from scratch, we applied mixed-domain pretraining and cross-domain transfer approaches to generate a performant bio-clinical model suitable for real-world clinical data. We evaluated our models on Named Entity Recognition (NER) tasks for biomedical documents and challenging hospital discharge reports. When compared against the competitive mBERT and BETO models, we outperform them in all NER tasks by a significant margin. Finally, we studied the impact of the model's vocabulary on the NER performances by offering an interesting vocabulary-centric analysis. The results confirm that domain-specific pretraining is fundamental to achieving higher performances in downstream NER tasks, even within a mid-resource scenario. To the best of our knowledge, we provide the first biomedical and clinical transformer-based pretrained language models for Spanish, intending to boost native Spanish NLP applications in biomedicine. Our best models are freely available in the HuggingFace hub: https://huggingface.co/BSC-TeMU.\", 'externalIds': {'DBLP': 'journals/corr/abs-2109-03570', 'CorpusId': 237439236.0, 'ArXiv': 2109.0357}, 'label': 1}\n",
      "{'paperId': 'ab3b5e8c2a70c43be5587505891ce27d43a8ef48', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/ab3b5e8c2a70c43be5587505891ce27d43a8ef48', 'title': 'Overexpression of miR-1306-5p, miR-3195, and miR-3914 Inhibits Ameloblast Differentiation through Suppression of Genes Associated with Human Amelogenesis Imperfecta', 'abstract': 'Amelogenesis imperfecta is a congenital form of enamel hypoplasia. Although a number of genetic mutations have been reported in humans, the regulatory network of these genes remains mostly unclear. To identify signatures of biological pathways in amelogenesis imperfecta, we conducted bioinformatic analyses on genes associated with the condition in humans. Through an extensive search of the main biomedical databases, we found 56 genes in which mutations and/or association/linkage were reported in individuals with amelogenesis imperfecta. These candidate genes were further grouped by function, pathway, protein–protein interaction, and tissue-specific expression patterns using various bioinformatic tools. The bioinformatic analyses highlighted a group of genes essential for extracellular matrix formation. Furthermore, advanced bioinformatic analyses for microRNAs (miRNAs), which are short non-coding RNAs that suppress target genes at the post-transcriptional level, predicted 37 candidates that may be involved in amelogenesis imperfecta. To validate the miRNA–gene regulation association, we analyzed the target gene expression of the top seven candidate miRNAs: miR-3195, miR-382-5p, miR-1306-5p, miR-4683, miR-6716-3p, miR-3914, and miR-3935. Among them, miR-1306-5p, miR-3195, and miR-3914 were confirmed to regulate ameloblast differentiation through the regulation of genes associated with amelogenesis imperfecta in AM-1 cells, a human ameloblastoma cell line. Taken together, our study suggests a potential role for miRNAs in amelogenesis imperfecta.', 'externalIds': {'PubMedCentral': 7926528.0, 'DOI': '10.3390/ijms22042202', 'CorpusId': 232111889.0, 'PubMed': 33672174.0}, 'label': 0}\n",
      "{'paperId': '87c7fa20518b27562f3345a780f8544bee7b0701', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/87c7fa20518b27562f3345a780f8544bee7b0701', 'title': 'Genome-Wide Investigation and Functional Analysis of Sus scrofa RNA Editing Sites across Eleven Tissues', 'abstract': 'Recently, the prevalence and importance of RNA editing have been illuminated in mammals. However, studies on RNA editing of pigs, a widely used biomedical model animal, are rare. Here we collected RNA sequencing data across 11 tissues and identified more than 490,000 RNA editing sites. We annotated their biological features, detected flank sequence characteristics of A-to-I editing sites and the impact of A-to-I editing on miRNA–mRNA interactions, and identified RNA editing quantitative trait loci (edQTL). Sus scrofa RNA editing sites showed high enrichment in repetitive regions with a median editing level as 15.38%. Expectedly, 96.3% of the editing sites located in non-coding regions including intron, 3′ UTRs, intergenic, and gene proximal regions. There were 2233 editing sites located in the coding regions and 980 of them caused missense mutation. Our results indicated that to an A-to-I editing site, the adjacent four nucleotides, two before it and two after it, have a high impact on the editing occurrences. A commonly observed editing motif is CCAGG. We found that 4552 A-to-I RNA editing sites could disturb the original binding efficiencies of miRNAs and 4176 A-to-I RNA editing sites created new potential miRNA target sites. In addition, we performed edQTL analysis and found that 1134 edQTLs that significantly affected the editing levels of 137 RNA editing sites. Finally, we constructed PRESDB, the first pig RNA editing sites database. The site provides necessary functions associated with Sus scrofa RNA editing study.', 'externalIds': {'MAG': 2942860411.0, 'PubMedCentral': 6678271.0, 'DOI': '10.3390/genes10050327', 'CorpusId': 145022300.0, 'PubMed': 31052161.0}, 'label': 0}\n",
      "{'paperId': '4c76b1a8448263fa52194367b368b331709efffd', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/4c76b1a8448263fa52194367b368b331709efffd', 'title': 'Supramolecular dendritic polymers: from synthesis to applications.', 'abstract': 'CONSPECTUS: Supramolecular dendritic polymers (SDPs), which perfectly combine the advantages of dendritic polymers with those of supramolecular polymers, are a novel class of non-covalently bonded, highly branched macromolecules with three-dimensional globular topology. Because of their dynamic/reversible nature, unique topological structure, and exceptional physical/chemical properties (e.g., low viscosity, high solubility, and a large number of functional terminal groups), SDPs have attracted increasing attention in recent years in both academic and industrial fields. In particular, the reversibility of non-covalent interactions endows SDPs with the ability to undergo dynamic switching of structure, morphology, and function in response to various external stimuli, such as pH, temperature, light, stress, and redox agents, which further provides a flexible and robust platform for designing and developing smart supramolecular polymeric materials and functional supramolecular devices. The existing SDPs can be systematically classified into the following six major types according to their topological features: supramolecular dendrimers, supramolecular dendronized polymers, supramolecular hyperbranched polymers, supramolecular linear-dendritic block copolymers, supramolecular dendritic-dendritic block copolymers, and supramolecular dendritic multiarm copolymers. These different types of SDPs possess distinct morphologies, unique architectures, and specific functions. Benefiting from their versatile topological structures as well as stimuli-responsive properties, SDPs have displayed not only unique characteristics or advantages in supramolecular self-assembly behaviors (e.g., controllable morphologies, specific performance, and facile functionalization) but also great potential to be promising candidates in various fields. In this Account, we summarize the recent progress in the synthesis, functionalization, and self-assembly of SDPs as well as their potential applications in a wide range of fields. A variety of synthetic methods using non-covalent interactions have been established to prepare different types of SDPs based on varied mono- or multifunctionalized building blocks (e.g., monomer, dendron, dendrimer, and hyperbranched polymer) with homo- or heterocomplementary units. In addition, SDPs can be further endowed with excellent functionalities by employing different modification approaches involving terminal, focal-point, and backbone modification. Similar to conventional dendritic polymers, SDPs can self-assemble into diverse supramolecular structures such as micelles, vesicles, fibers, nanorings, tubes, and many hierarchical structures. Finally, we highlight some typical examples of recent applications of SDP-based systems in biomedical fields (e.g., controlled drug/gene/protein delivery, bioimaging, and biomimetic chemistry), nanotechnology (e.g., nanoreactors, catalysis, and molecular imprinting), and functional materials. The current research on SDPs is still at the very early stage, and much more work needs to be done. We anticipate that future studies of SDPs will focus on developing multifunctional, hierarchical supramolecular materials toward their practical applications by utilization of cooperative non-covalent interactions.', 'externalIds': {'MAG': 2333263232.0, 'DOI': '10.1021/ar500057e', 'CorpusId': 206825171.0, 'PubMed': 24779892.0}, 'label': 0}\n",
      "{'paperId': '08786df661b0d8649ab2eb9ae642f6b2cfbaee14', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/08786df661b0d8649ab2eb9ae642f6b2cfbaee14', 'title': 'Local and global character representation enhanced model for Chinese medical named entity recognition', 'abstract': 'Chinese medical named entity recognition (CMNER) aims to extract entities from Chinese unstructured medical texts. Existing character-based NER models do not comprehensively consider character’s characteristics from different perspectives, which limits their performance in applying to CMNER. In this paper, we propose a local and global character representation enhanced model for CMNER. For the input sentence, the model fuses the spacial and sequential character representation using autoencoder to get the local character representation; extracts the global character representation according to the corresponding domain words; integrates the local and global representation through gating mechanism to obtain the enhanced character representation, which has better ability to perceive medical entities. Finally, the model sent the enhanced character representation to the Bi-LSTM and CRF layers for context encoding and tags decoding respectively. The experimental results demonstrate that our model achieves a significant improvement over the best baseline, increasing the F1 values by 1.04% and 0.62% on the IMCS21 and CMeEE datasets, respectively. In addition, we verify the effectiveness of each component of our model by ablation experiments.', 'externalIds': {'DBLP': 'journals/jifs/XiangLGZ23', 'DOI': '10.3233/jifs-231554', 'CorpusId': 259791482.0}, 'label': 1}\n",
      "{'paperId': '5eae85ded277cb06eed20adc3b7a2366c6c0d2f3', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/5eae85ded277cb06eed20adc3b7a2366c6c0d2f3', 'title': 'Deep fusion of multiple term-similarity measures for biomedical passage retrieval', 'abstract': 'Passage retrieval is an important stage of question answering systems. Closed domain passage retrieval, e.g. biomedical passage retrieval presents additional challenges such as specialized terminology, more complex and elaborated queries, scarcity in the amount of available data, among others. However, closed domains also offer some advantages such as the availability of specialized structured information sources, e.g. ontologies and thesauri, that could be used to improve retrieval performance. This paper presents a novel approach for biomedical passage retrieval which is able to combine different information sources using a similarity matrix fusion strategy based on convolutional neural network architecture. The method was evaluated over the standard BioASQ dataset, a dataset specialized on biomedical question answering. The results show that the method is an effective strategy for biomedical passage retrieval able to outperform other state-of-the-art methods in this domain.', 'externalIds': {'MAG': 3036083029.0, 'DBLP': 'journals/jifs/Rosso-MateusMRG20', 'DOI': '10.3233/jifs-179887', 'CorpusId': 221594164.0}, 'label': 1}\n",
      "{'paperId': '16def7d1fe3e23030a0cfd53abbdcfc3c6693d25', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/16def7d1fe3e23030a0cfd53abbdcfc3c6693d25', 'title': 'Permanently aligned multi-line lasers: a simplified solution for optical integration in biomedical instrumentation and fluorescence microscopes', 'abstract': 'The integration of multi-color laser excitation into biomedical instrumentation is associated with several challenges which must be overcome to meet the desired performance requirements of the instrument. Multi-color lasers are needed in fluorescence-analysis based applications such as flow cytometry, DNA sequencing, and various types of fluorescence microscopes such as scanning confocal microscopes, TIRF, Light-sheet, SIM, STORM and STED techniques. In many cases, these techniques require capability for excitation of multiple fluorophores and therefore access to several laser lines within the instrument. The advantages of lasers over other light-sources, such as LEDs, for these techniques are high-brightness and wavelength precision. Unfortunately, the inclusion of lasers also introduces complexity in the design. Laser combiners including individual lasers have been integrated with the intention of simplifying the design, as an alternative to traditional multiline gas lasers. This solution, however, is still susceptible to misalignment over time, and can increase the size and cost of the instrument. A compact, permanently aligned, multi-line laser simplifies the integration of multiple laser wavelengths by eliminating the need for in-field alignment and service, reducing manufacturing cost, and allowing for more compact designs. In addition to overcoming the initial design challenges of integrating lasers into bio-instrumentation, a multi-line laser is also an easy-to-upgrade field replacement for previous generations of technology, such as Argon Ion gas lasers. Here we demonstrate how a compact and robust permanently aligned multi-line solid-state laser can be achieved using novel techniques for optical assembly and miniaturization. We also show how the integration of such a multi-line laser can deliver the required optical performance while simplifying the design and enabling commercialization of a new bioimaging technology, and exemplify the integration of this solution as a drop-in replacement for an Argon Ion lasers in existing microscope set-ups.', 'externalIds': {'MAG': 3007723691.0, 'DOI': '10.1117/12.2546757', 'CorpusId': 212879162.0}, 'label': 0}\n",
      "{'paperId': '5a292941d5d483ee5fc529081b6c0efc0d6b0652', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/5a292941d5d483ee5fc529081b6c0efc0d6b0652', 'title': 'NeuroNER: an easy-to-use program for named-entity recognition based on neural networks', 'abstract': 'Named-entity recognition (NER) aims at identifying entities of interest in a text. Artificial neural networks (ANNs) have recently been shown to outperform existing NER systems. However, ANNs remain challenging to use for non-expert users. In this paper, we present NeuroNER, an easy-to-use named-entity recognition tool based on ANNs. Users can annotate entities using a graphical web-based user interface (BRAT): the annotations are then used to train an ANN, which in turn predict entities’ locations and categories in new texts. NeuroNER makes this annotation-training-prediction flow smooth and accessible to anyone.', 'externalIds': {'MAG': 2952733848.0, 'DBLP': 'conf/emnlp/DernoncourtLS17', 'DOI': '10.18653/v1/D17-2017', 'CorpusId': 2816661.0, 'ACL': 'D17-2017', 'ArXiv': 1705.05487}, 'label': 0}\n",
      "{'paperId': '928b9e8f51c42e9a38b9121a3d74d45c02beb262', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/928b9e8f51c42e9a38b9121a3d74d45c02beb262', 'title': 'TEG: a hybrid approach to information extraction', 'abstract': 'This paper describes a hybrid statistical and knowledge-based information extraction model, able to extract entities and relations at the sentence level. The model attempts to retain and improve the high accuracy levels of knowledge-based systems while drastically reducing the amount of manual labor by relying on statistics drawn from a training corpus. The implementation of the model, called TEG (Trainable Extraction Grammar), can be adapted to any IE domain by writing a suitable set of rules in a SCFG (Stochastic Context Free Grammar) based extraction language, and training them using an annotated corpus. The system does not contain any purely linguistic components, such as PoS tagger or parser. We demonstrate the performance of the system on several named entity extraction and relation extraction tasks. The experiments show that our hybrid approach outperforms both purely statistical and purely knowledge-based systems, while requiring orders of magnitude less manual rule writing and smaller amount of training data. The improvement in accuracy is slight for named entity extraction task and more pronounced for relation extraction.', 'externalIds': {'MAG': 2008547014.0, 'DBLP': 'conf/cikm/RosenfeldFFSA04', 'DOI': '10.1145/1031171.1031280', 'CorpusId': 30571085.0}, 'label': 0}\n",
      "{'paperId': 'af91136cb45b92e9a45815fa93423125673da109', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/af91136cb45b92e9a45815fa93423125673da109', 'title': 'Towards Fast and Unified Transfer Learning Architectures for Sequence Labeling', 'abstract': 'Sequence labeling systems have advanced continuously using neural architectures over the past several years. However, these tasks require large sets of annotated data to achieve such performance. In particular, we focus on the Named Entity Recognition (NER) task on clinical notes, which is one of the most fundamental and critical problems for medical text analysis. Our work centers on effectively adapting these neural architectures towards low-resource settings using parameter transfer methods. We complement a standard hierarchical NER model with a general transfer learning framework, the Tunable Transfer Network (TTN) consisting of parameter sharing between the source and target tasks, and showcase scores significantly above the baseline architecture. Our best TTN model achieves 2-5% improvement over pre-trained language model BERT as well as its multi task extension MT-DNN in low resource settings. However, our proposed sharing scheme requires an exponential search over tied parameter sets to generate an optimal configuration. To mitigate the problem of exhaustively searching for model optimization, we propose the Dynamic Transfer Networks (DTN), a gated architecture which learns the appropriate parameter sharing scheme between source and target datasets. DTN achieves the improvements of the optimized transfer learning framework with just a single training setting, effectively removing the need for an exponential search.', 'externalIds': {'MAG': 3008048265.0, 'DBLP': 'conf/icmla/BhatiaAC19', 'DOI': '10.1109/ICMLA.2019.00298', 'CorpusId': 211227398.0}, 'label': 0}\n",
      "{'paperId': '3eaa8aaebb8de1c54d5ebbf5861f4acc116faf71', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/3eaa8aaebb8de1c54d5ebbf5861f4acc116faf71', 'title': 'Danish Clinical Named Entity Recognition and Relation Extraction', 'abstract': 'Electronic health records contain important information regarding the patients’ medical history but much of this information is stored in unstructured narrative text. This paper presents the first Danish clinical named entity recognition and relation extraction dataset for extraction of six types of clinical events, six types of attributes, and three types of relations. The dataset contains 11,607 paragraphs from Danish electronic health records containing 54,631 clinical events, 41,954 attributes, and 14,604 relations. We detail the methodology of developing the annotation scheme, and train a transformer-based architecture on the developed dataset with macro F1 performance of 60.05%, 44.85%, and 70.64% for clinical events, attributes, and relations, respectively.', 'externalIds': {'DBLP': 'conf/nodalida/LaursenPHSV23', 'CorpusId': 258765300.0, 'ACL': '2023.nodalida-1.65'}, 'label': 1}\n",
      "{'paperId': 'fe62821b32cfa07a074b3f432de3cd353662a95c', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/fe62821b32cfa07a074b3f432de3cd353662a95c', 'title': 'Automating Identification of Multiple Chronic Conditions in Clinical Practice Guidelines', 'abstract': 'Many clinical practice guidelines (CPGs) are intended to provide evidence-based guidance to clinicians on a single disease, and are frequently considered inadequate when caring for patients with multiple chronic conditions (MCC), or two or more chronic conditions. It is unclear to what degree disease-specific CPGs provide guidance about MCC. In this study, we develop a method for extracting knowledge from single-disease chronic condition CPGs to determine how frequently they mention commonly co-occurring chronic diseases. We focus on 15 highly prevalent chronic conditions. We use publicly available resources, including a repository of guideline summaries from the National Guideline Clearinghouse to build a text corpus, a data dictionary of ICD-9 codes from the Medicare Chronic Conditions Data Warehouse (CCW) to construct an initial list of disease terms, and disease synonyms from the National Center for Biomedical Ontology to enhance the list of disease terms. First, for each disease guideline, we determined the frequency of comorbid condition mentions (a disease-comorbidity pair) by exactly matching disease synonyms in the text corpus. Then, we developed an annotated reference standard using a sample subset of guidelines. We used this reference standard to evaluate our approach. Then, we compared the co-prevalence of common pairs of chronic conditions from Medicare CCW data to the frequency of disease-comorbidity pairs in CPGs. Our results show that some disease-comorbidity pairs occur more frequently in CPGs than others. Sixty-one (29.0%) of 210 possible disease-comorbidity pairs occurred zero times; for example, no guideline on chronic kidney disease mentioned depression, while heart failure guidelines mentioned ischemic heart disease the most frequently. Our method adequately identifies comorbid chronic conditions in CPG recommendations with precision 0.82, recall 0.75, and F-measure 0.78. Our work identifies knowledge currently embedded in the free text of clinical practice guideline recommendations and provides an initial view of the extent to which CPGs mention common comorbid conditions. Knowledge extracted from CPG text in this way may be useful to inform gaps in guideline recommendations regarding MCC and therefore identify potential opportunities for guideline improvement.', 'externalIds': {'MAG': 2572387682.0, 'DBLP': 'conf/amia/LeungJZOMDG14', 'PubMedCentral': 4525235.0, 'CorpusId': 17564165.0, 'PubMed': 26306285.0}, 'label': 1}\n",
      "{'paperId': 'c07d534742b7c8c88a7483fd9c98bdcbf9cbcbc6', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/c07d534742b7c8c88a7483fd9c98bdcbf9cbcbc6', 'title': 'Relabel the Noise: Joint Extraction of Entities and Relations via Cooperative Multiagents', 'abstract': 'Distant supervision based methods for entity and relation extraction have received increasing popularity due to the fact that these methods require light human annotation efforts. In this paper, we consider the problem of shifted label distribution, which is caused by the inconsistency between the noisy-labeled training set subject to external knowledge graph and the human-annotated test set, and exacerbated by the pipelined entity-then-relation extraction manner with noise propagation. We propose a joint extraction approach to address this problem by re-labeling noisy instances with a group of cooperative multiagents. To handle noisy instances in a fine-grained manner, each agent in the cooperative group evaluates the instance by calculating a continuous confidence score from its own perspective; To leverage the correlations between these two extraction tasks, a confidence consensus module is designed to gather the wisdom of all agents and re-distribute the noisy training set with confidence-scored labels. Further, the confidences are used to adjust the training losses of extractors. Experimental results on two real-world datasets verify the benefits of re-labeling noisy instance, and show that the proposed model significantly outperforms the state-of-the-art entity and relation extraction methods.', 'externalIds': {'MAG': 3034598693.0, 'DBLP': 'conf/acl/ChenLLS20', 'DOI': '10.18653/v1/2020.acl-main.527', 'CorpusId': 216036249.0, 'ACL': '2020.acl-main.527', 'ArXiv': 2004.0993}, 'label': 0}\n",
      "{'paperId': '750d024a094de96f7bac9d835b9673cc2c08fde5', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/750d024a094de96f7bac9d835b9673cc2c08fde5', 'title': 'Statistical models for count time series with excess zeros', 'abstract': 'Time series data involving counts are frequently encountered in many biomedical and', 'externalIds': {'MAG': 77459311.0, 'DOI': '10.17077/ETD.BCRQ9MZ0', 'CorpusId': 14422793.0}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' public health applications. For example, in disease surveillance, the occurrence of rare', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' infections over time is often monitored by public health officials, and the time series', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' data collected can be used for the purpose of monitoring changes in disease activity.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' For rare diseases with low infection rates, the observed counts typically contain a high', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' frequency of zeros (zero-inflated), but the counts can also be very large during an', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' outbreak period. Failure to account for zero-inflation in the data may result in', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' misleading inference and the detection of spurious associations. In this thesis, we develop two classes of statistical models for zero-inflated time', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' series. The first part of the thesis introduces a class of observation-driven models in', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' a partial likelihood framework. The expectation-maximization (EM) algorithm is applied', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' to obtain the maximum partial likelihood estimator (MPLE). We establish the asymptotic', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' theory of the MPLE under certain regularity conditions. The performances of different', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' partial-likelihood based model selection criteria are compared under model', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' misspecification. In the second part of the thesis, we introduce a class of', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' parameter-driven models in a state-space framework. To estimate the model parameters, we', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' devise a Monte Carlo EM algorithm, where particle filtering and particle smoothing', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' methods are employed to approximate the high-dimensional integrals in the E-step of the', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': \" algorithm. Upon convergence, Louis' formula is used to find the observed information\", 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' matrix. The proposed models are illustrated with simulated data and an application based on', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' public health surveillance for syphilis, a sexually transmitted disease (STD) that', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' remains a major public health challenge in the United States. An R package, called ZIM', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' (Zero-Inflated Models), has been developed to fit both observation-driven models and', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' parameter-driven models.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': '32a46eb9e44a9b4d6940cbeef3039adb41d35ea8', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/32a46eb9e44a9b4d6940cbeef3039adb41d35ea8', 'title': 'Temporal Name Entity Recognition and Relation Extraction in Clinical Electronic Health Records with Span-based Entity and Relation Transformer', 'abstract': 'The task to generate a timeline representation of the International Classification of Disease (ICD) codes included in a given Electronic Health Record (EHR) is an open challenge. One step in that direction is the identification of temporal entities and relations in the text to arrange, chronologically, the important clinical events in the document. In this work, we cope with the recognition of temporal entities and the extraction of temporal relations between them in EHRs. Current approaches usually train separate models for entity recognition and relation extraction, easing the models at the expense of ignoring the underlying dependencies. This work explores SpERT, a joint entity recognition and relation extraction approach based on the Transformer architecture. We trained and evaluated the model with a small data-set with annotated temporal information. While previous works do not test their model on other data-sets, we also apply the model to a more extensive dataset without temporal information labelling in order to evaluate the performance of the model qualitatively. The qualitative evaluation allows the discovery and interpretation of the strengths and weaknesses of the model. Our experiments conclude that SpERT results are close to the state of the art. Moreover, we discovered that the model could generalize when applied to other clinical datasets.', 'externalIds': {'DBLP': 'conf/icbbb/LebenaCP24', 'DOI': '10.1145/3640900.3640901', 'CorpusId': 268134437.0}, 'label': 1}\n",
      "{'paperId': '00248a60f905f49c451e106ee6647823e9359e6c', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/00248a60f905f49c451e106ee6647823e9359e6c', 'title': 'Overview of Genia Event Task in BioNLP Shared Task 2011', 'abstract': 'The Genia event task, a bio-molecular event extraction task, is arranged as one of the main tasks of BioNLP Shared Task 2011. As its second time to be arranged for community-wide focused efforts, it aimed to measure the advance of the community since 2009, and to evaluate generalization of the technology to full text papers. After a 3-month system development period, 15 teams submitted their performance results on test cases. The results show the community has made a significant advancement in terms of both performance improvement and generalization.', 'externalIds': {'MAG': 154351976.0, 'DBLP': 'conf/bionlp/KimWTY11', 'CorpusId': 263873742.0, 'ACL': 'W11-1802'}, 'label': 1}\n",
      "{'paperId': 'cc9f33e6650ce3a62a4da70e30a2edae6bf5b3cf', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/cc9f33e6650ce3a62a4da70e30a2edae6bf5b3cf', 'title': 'Bmc Medical Informatics and Decision Making Relemed: Sentence-level Search Engine with Relevance Score for the Medline Database of Biomedical Articles', 'abstract': 'Background: Receiving extraneous articles in response to a query submitted to MEDLINE/ PubMed is common. When submitting a multi-word query (which is the majority of queries submitted), the presence of all query words within each article may be a necessary condition for retrieving relevant articles, but not sufficient. Ideally a relationship between the query words in the article is also required. We propose that if two words occur within an article, the probability that a relation between them is explained is higher when the words occur within adjacent sentences versus remote sentences. Therefore, sentence-level concurrence can be used as a surrogate for existence of the relationship between the words.', 'externalIds': {'CorpusId': 10860044.0}, 'label': 1}\n",
      "{'paperId': '5c8aa364ac7d832b3e0a49556876ed70370dc75b', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/5c8aa364ac7d832b3e0a49556876ed70370dc75b', 'title': 'Deep learning methods for biomedical named entity recognition: a survey and qualitative comparison', 'abstract': 'The biomedical literature is growing rapidly, and the extraction of meaningful information from the large amount of literature is increasingly important. Biomedical named entity (BioNE) identification is one of the critical and fundamental tasks in biomedical text mining. Accurate identification of entities in the literature facilitates the performance of other tasks. Given that an end-to-end neural network can automatically extract features, several deep learning-based methods have been proposed for BioNE recognition (BioNER), yielding state-of-the-art performance. In this review, we comprehensively summarize deep learning-based methods for BioNER and datasets used in training and testing. The deep learning methods are classified into four categories: single neural network-based, multitask learning-based, transfer learning-based and hybrid model-based methods. They can be applied to BioNER in multiple domains, and the results are determined by the dataset size and type. Lastly, we discuss the future development and opportunities of BioNER methods.', 'externalIds': {'DBLP': 'journals/bib/SongLLZ21', 'DOI': '10.1093/bib/bbab282', 'CorpusId': 236430295.0, 'PubMed': 34308472.0}, 'label': 1}\n",
      "{'paperId': 'c0e8b7b668d82afd5a7a90999d78c3a36d23d909', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/c0e8b7b668d82afd5a7a90999d78c3a36d23d909', 'title': 'An Entailment-Based Approach to the QA4MRE Challenge', 'abstract': 'This paper describes our entry to the 2012 QA4MRE Main Task (English dataset). The QA4MRE task poses a significant challenge as the expression of knowledge in the question and answer (in the document) typically substantially differs. Ultimately, one would need a system that can perform full machine reading – creating an internal model of the document’s meaning – to achieve high performance. Our approach is a preliminary step toward this, based on estimating the likelihood of textual entailment between sentences in the text, and the question Q and each candidate answer Ai. We first treat the question Q and each answer Ai independently, and find sets of sentences SQ, SA that each plausibly entail (the target of) Q or one of the Ai respectively. We then search for the closest (in the document) pair of sentences in these sets, and conclude that the answer Ai entailed by SAi in the closest pair is the answer. This approach assumes coherent discourse, i.e., that sentences close together are usually “talking about the same thing”, and thus conveying a single idea (namely an expression of the Q+Ai pair). In QA4MRE it is hard to \"prove\" entailment, as a candidate answer A may be expressed using a substantially different wording in the document, over multiple sentences, and only partially (as some aspects of A may be left implicit in the document, to be filled in by the reader). As a result, we instead estimate the likelihood of entailment (that a sentence S entails A) by look for evidence, namely entailment relationships between components of S and A such as words, bigrams, trigrams, and parse fragments. To identify these possible entailment relationships we use three knowledge resources, namely WordNet, ParaPara (a large paraphrase database from Johns Hopkins University), and the DIRT paraphrase database. Our best run scored 40% in the evaluation, and around 42% in additional (unsubmitted) runs afterwards. In ablation studies, we found that the majority of our score (approximately 38%) could be attributed to the basic algorithm, with the knowledge resources adding approximately 4% to this baseline score. Finally we critique our approach with respect to the broader goal of machine reading, and discuss what is needed to move closer to that goal.', 'externalIds': {'MAG': 2399355492.0, 'DBLP': 'conf/clef/ClarkHY12', 'CorpusId': 13480309.0}, 'label': 0}\n",
      "{'paperId': '31e66d0d4379743bbaef02feee4e19b7ec134312', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/31e66d0d4379743bbaef02feee4e19b7ec134312', 'title': 'Integrating Speculation Detection and Deep Learning to Extract Lung Cancer Diagnosis from Clinical Notes', 'abstract': 'Despite efforts to develop models for extracting medical concepts from clinical notes, there are still some challenges in particular to be able to relate concepts to dates. The high number of clinical notes written for each single patient, the use of negation, speculation, and different date formats cause ambiguity that has to be solved to reconstruct the patient’s natural history. In this paper, we concentrate on extracting from clinical narratives the cancer diagnosis and relating it to the diagnosis date. To address this challenge, a hybrid approach that combines deep learning-based and rule-based methods is proposed. The approach integrates three steps: (i) lung cancer named entity recognition, (ii) negation and speculation detection, and (iii) relating the cancer diagnosis to a valid date. In particular, we apply the proposed approach to extract the lung cancer diagnosis and its diagnosis date from clinical narratives written in Spanish. Results obtained show an F-score of 90% in the named entity recognition task, and a 89% F-score in the task of relating the cancer diagnosis to the diagnosis date. Our findings suggest that speculation detection is together with negation detection a key component to properly extract cancer diagnosis from clinical notes.', 'externalIds': {'MAG': 3125137681.0, 'DOI': '10.3390/APP11020865', 'CorpusId': 234140795.0}, 'label': 1}\n",
      "{'paperId': '581e386b5971429cb60d3594076dc365c7a54827', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/581e386b5971429cb60d3594076dc365c7a54827', 'title': 'Extracting Family History Information From Electronic Health Records: Natural Language Processing Analysis', 'abstract': 'Background The prognosis, diagnosis, and treatment of many genetic disorders and familial diseases significantly improve if the family history (FH) of a patient is known. Such information is often written in the free text of clinical notes. Objective The aim of this study is to develop automated methods that enable access to FH data through natural language processing. Methods We performed information extraction by using transformers to extract disease mentions from notes. We also experimented with rule-based methods for extracting family member (FM) information from text and coreference resolution techniques. We evaluated different transfer learning strategies to improve the annotation of diseases. We provided a thorough error analysis of the contributing factors that affect such information extraction systems. Results Our experiments showed that the combination of domain-adaptive pretraining and intermediate-task pretraining achieved an F1 score of 81.63% for the extraction of diseases and FMs from notes when it was tested on a public shared task data set from the National Natural Language Processing Clinical Challenges (N2C2), providing a statistically significant improvement over the baseline (P<.001). In comparison, in the 2019 N2C2/Open Health Natural Language Processing Shared Task, the median F1 score of all 17 participating teams was 76.59%. Conclusions Our approach, which leverages a state-of-the-art named entity recognition model for disease mention detection coupled with a hybrid method for FM mention detection, achieved an effectiveness that was close to that of the top 3 systems participating in the 2019 N2C2 FH extraction challenge, with only the top system convincingly outperforming our approach in terms of precision.', 'externalIds': {'PubMedCentral': 8092929.0, 'DOI': '10.2196/24020', 'CorpusId': 233996965.0, 'PubMed': 33664015.0}, 'label': 1}\n",
      "{'paperId': '7d8f64ee0a404e6f47b522ac9182d76330e09bc8', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/7d8f64ee0a404e6f47b522ac9182d76330e09bc8', 'title': 'An Explainable AI System for the Diagnosis of High Dimensional Biomedical Data', 'abstract': 'Typical state of the art flow cytometry data samples consists of measures of more than 100.000 cells in 10 or more features. AI systems are able to diagnose such data with almost the same accuracy as human experts. However, there is one central challenge in such systems: their decisions have far-reaching consequences for the health and life of people, and therefore, the decisions of AI systems need to be understandable and justifiable by humans. In this work, we present a novel explainable AI method, called ALPODS, which is able to classify (diagnose) cases based on clusters, i.e., subpopulations, in the high-dimensional data. ALPODS is able to explain its decisions in a form that is understandable for human experts. For the identified subpopulations, fuzzy reasoning rules expressed in the typical language of domain experts are generated. A visualization method based on these rules allows human experts to understand the reasoning used by the AI system. A comparison to a selection of state of the art explainable AI systems shows that ALPODS operates efficiently on known benchmark data and also on everyday routine case data.', 'externalIds': {'DBLP': 'journals/corr/abs-2107-01820', 'CorpusId': 235732185.0, 'ArXiv': 2107.0182}, 'label': 1}\n",
      "{'paperId': '23c52b4a361ff48401c0171b9a2d6b3ab66fc1d2', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/23c52b4a361ff48401c0171b9a2d6b3ab66fc1d2', 'title': 'Encoding Relation Requirements for Relation Extraction via Joint Inference', 'abstract': 'Most existing relation extraction models make predictions for each entity pair locally and individually, while ignoring implicit global clues available in the knowledge base, sometimes leading to conflicts among local predictions from different entity pairs. In this paper, we propose a joint inference framework that utilizes these global clues to resolve disagreements among local predictions. We exploit two kinds of clues to generate constraints which can capture the implicit type and cardinality requirements of a relation. Experimental results on three datasets, in both English and Chinese, show that our framework outperforms the state-of-theart relation extraction models when such clues are applicable to the datasets. And, we find that the clues learnt automatically from existing knowledge bases perform comparably to those refined by human.', 'externalIds': {'MAG': 2251421040.0, 'DBLP': 'conf/acl/ChenFHQZ14', 'DOI': '10.3115/v1/P14-1077', 'CorpusId': 87648.0, 'ACL': 'P14-1077'}, 'label': 0}\n",
      "{'paperId': 'a59bc29ee7ef92796078bada375242e176fecfce', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/a59bc29ee7ef92796078bada375242e176fecfce', 'title': 'BmQGen: Biomedical query generator for knowledge discovery', 'abstract': \"A large number of structured and unstructured data (e.g., EHRs, ontologies, reports) have been introduced by the biomedical community. Cross-domain data integration is identified as an important research problem for translational research. From an application perspective, identifying related concepts among medical ontologies is an important goal of life science research. It is essential to analyze how relations are specified to connect concepts in a single ontology or across multiple ontologies. With the explosion of cross domain datasets, it is extremely hard for researchers to discover knowledge from current infrastructures of ontologies. It is mainly a lack of the connectivity between the ontologies' cross domains and ontologies to unstructured data; even if they have specific biomedical knowledge in a more general and comprehensive level. Therefore, there is a need for a mechanism to do semantic partition and query generation for cross domain biomedical knowledge discovery. In this paper, we present such a model that clusters integrated data based on semantic closeness of predicates into different groups and produces meaningful queries to fully discover knowledge over a set of interlinked data sources. We have implemented a prototype of the BmQGen system and evaluated the proposed query model based on the predicate oriented clustering with colorectal surgical cohort from the Mayo Clinic.\", 'externalIds': {'MAG': 2209024493.0, 'DBLP': 'conf/bibm/ShenLSLL15', 'DOI': '10.1109/BIBM.2015.7359833', 'CorpusId': 39295919.0}, 'label': 1}\n",
      "{'paperId': '29ae1379007c6518401fefa13a656d446739b845', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/29ae1379007c6518401fefa13a656d446739b845', 'title': 'An Ensemble Semantic Textual Similarity Measure Based on Multiple Evidences for Biomedical Documents', 'abstract': 'With the increasing volume of the published biomedical literature, the fast and effective retrieval of the literature on the sequence, structure, and function of biological entities is an essential task for the rapid development of biology and medicine. To capture the semantic information in biomedical literature more effectively when biomedical documents are clustered, we propose a new multi-evidence-based semantic text similarity calculation method. Two semantic similarities and one content similarity are used, in which two semantic similarities include MeSH-based semantic similarity and word embedding-based semantic similarity. To fuse three different similarities more effectively, after, respectively, calculating two semantic and one content similarities between biomedical documents, feedforward neural network is applied to integrate the two semantic similarities. Finally, weighted linear combination method is used to integrate the semantic and content similarities. To evaluate the effectiveness, the proposed method is compared with the existing basic methods, and the proposed method outperforms the existing related methods. Based on the proven results of this study, this method can be used not only in actual biological or medical experiments such as protein sequence or function analysis but also in biological and medical research fields, which will help to provide, use, and understand thematically consistent documents.', 'externalIds': {'PubMedCentral': 9440839.0, 'DOI': '10.1155/2022/8238432', 'CorpusId': 251892106.0, 'PubMed': 36065380.0}, 'label': 1}\n",
      "{'paperId': 'f447b7a4291339c025de37ea949829b178b01d9a', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/f447b7a4291339c025de37ea949829b178b01d9a', 'title': \"Cohort Identification from Free-Text Clinical Notes Using SNOMED CT's Hierarchical Semantic Relations\", 'abstract': 'In this paper, a new cohort identification system that exploits the semantic hierarchy of SNOMED CT is proposed to overcome the limitations of supervised machine learning-based approaches. Eligibility criteria descriptions and free-text clinical notes from the 2018 National NLP Clinical Challenge (n2c2) were processed to map to relevant SNOMED CT concepts and to measure semantic similarity between the eligibility criteria and patients. The eligibility of a patient was determined if the patient had a similarity score higher than a threshold cut-off value. The performance of the proposed system was evaluated for three eligibility criteria. The performance of the current system exceeded the previously reported results of the 2018 n2c2, achieving the average F1 score of 0.933. This study demonstrated that SNOMED CT alone can be leveraged for cohort identification tasks without referring to external textual sources for training.', 'externalIds': {'DBLP': 'conf/amia/ChangM22', 'CorpusId': 256665900.0, 'PubMed': 37128385.0}, 'label': 1}\n",
      "{'paperId': '4ac4f24fa28d69838b2a74bf5ab411bc993e688c', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/4ac4f24fa28d69838b2a74bf5ab411bc993e688c', 'title': 'Improving Event Coreference Resolution Using Document-level and Topic-level Information', 'abstract': 'Event coreference resolution (ECR) aims to cluster event mentions that refer to the same real-world events. Deep learning methods have achieved SOTA results on the ECR task. However, due to the encoding length limitation, previous methods either adopt classical pairwise models based on sentence-level context or split each document into multiple chunks and encode them separately. They failed to capture the interactions and contextual cues among those long-distance event mentions. Besides, high-level information, such as event topics, is rarely considered to enhance representation learning for ECR. To address the above two issues, we first apply a Longformer-based encoder to obtain the document-level embeddings and an encoder with a trigger-mask mechanism to learn sentence-level embeddings based on local context. In addition, we propose an event topic generator to infer the latent topic-level representations. Finally, using the above event embeddings, we employ a multiple tensor matching method to capture their interactions at the document, sentence, and topic levels. Experimental results on the KBP 2017 dataset show that our model outperforms the SOTA baselines.', 'externalIds': {'DBLP': 'conf/emnlp/0006LZ22', 'DOI': '10.18653/v1/2022.emnlp-main.454', 'CorpusId': 256461410.0, 'ACL': '2022.emnlp-main.454'}, 'label': 0}\n",
      "{'paperId': '6de4dda7f3786bbd18d030f0253e5cee720b4381', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/6de4dda7f3786bbd18d030f0253e5cee720b4381', 'title': 'The role of automated word classification in the summarization of the contents of sets of documents', 'abstract': 'In future digital libraries, even \"perfect\" retrieval will typically return too much material for a user to cope with. One way to deal with this problem is to produce automated summaries tailored to the user\\'s requirements. One of the prime purposes of a summary of a collection of documents is to collapse together all of the important information elements that are common to the collection. This requires some method of discovering classes of similar items, e.g., word classes. This paper describes automated techniques for placing words in similarity classes. To do this, each target word is described by a composite vector that records the occurrence of words positioned near any occurrence of the target. Target words with similar contexts are grouped together by a clustering algorithm. We describe how such classifications can be used in information retrieval and for the summarization of biological literature. The dilemma of \"perfect\" retrieval In retrieving documents or portions of full-text documents, recall is the percentage of the desired documents that are retrieved and precision is the percentage of all retrieved documents that are of the desired type. No matter how good future systems become, even if they achieved 100% recall and precision, the amount of information that will be on line will be so large that the user will still be overwhelmed. It will rarely be the case that one returned paragraph or even one entire document will answer the user\\'s questions. The information the user wants is typically scattered throughout the documents simply because none of the documents were written (nor could they have been written) to satisfy the interests that one particular user would have at some later time. The user could look for a review of the topic, but again, there would probably not be a review focused on the user\\'s interests, much less one that was as up-to-date as the literature itself. Because the information desired is scattered across many documents, ranking the documents in order of relevance does not solve the problem. One solution: Summarizing document sets Retrieval systems could help to avoid the dilemma above if they could automatically produce a summary of the relevant documents tailored to the user\\'s interests, particular query, level of expertise and adjusted to some particular length (from a paragraph to many pages). There has been work on extracting information from single sentences, from paragraphs (Zadrozny & Jensen, 1991), work on summarizing the arguments in whole documents (Alvarado, 1990) and work on automatic abstracting (Paice, 1990). Extensions of these techniques can be applied to summarizing the contents of sets of documents. Manual analysis of reviews in the biological and computer science literature reveals the strategies authors use to summarize large collections of literature. One of the primary devices is to generate that describe items of a given class, citing the appropriate sources. The listings could be sets of genes or enzymes in biological articles or sorting algorithms or network protocols in computer science. Discovering the set of items in a given class in a document collection would need to be automated for this strategy to succeed. It is not appropriate to say that the system should refer to some standard listing of the items of a given class, because new terms are constantly being introduced in rapidly moving fields such as computer science or biology. Furthermore, terminology and use is often specific to a given subfield. As an example, we would like an automated summary system to produce tables such as the following for a biological topic, Term Context and source λ repres sor \"OL and OR each contain a series of nonidentical binding sites for the λ repressor...\" [Stryer, 1975] Pages 35-39 of Genetic Switch [Ptashne, 1992]. lac repres sor The repressor of the lactose operon [Stryer, 1975] In a navigation (hypertext) environment the user could select any of the items in the table for expansion. In order to select the terms that should be grouped together in tabular summaries as in the example above (λ and lac), word classification must be done. This is described in the next section. Describing and quantifying word contexts To discover word classes, we describe the context of a word (the target word) by the preceding two context words and the following two context words. Each context position is represented by a vector containing the joint frequencies of the 150 highest frequency words in the corpus, giving a 600-dimensional context vector. The entries in the context vectors are converted to mutual information measures, with smoothing. The similarities of the resultant context vectors for the 1,000 highest frequency words are computed from the normalized inner products of their context vectors (cosine rule). The resulting set of 500,000 similarities is used as the basis of a hierarchical clustering algorithm, a bottom-up approach producing binary trees with a similarity at each node, -1.0 ≤ ≤ 1.0. The method was inspired by (Finch & Chater, 1992) and is described in more detail in (Futrelle & Gauch, 1993). Near the leaves, the words were found to be grouped by both semantic and syntactic similarity. Further up the tree, the larger classes retained only syntactic similarity. 1 Prof. Gauch\\'s current address: Dept. of Computer Science, U. Kansas, Lawrence, KS. Some examples from the biological literature The corpus used for this analysis was the 220,000 words of text in 1,700 abstracts that completely cover the field of bacterial chemotaxis since its inception in 1965. Bacterial chemotaxis is a phenomena in which single bacteria move toward higher concentrations of chemical attractants such as sugars (and away from repellents). One of the classes of terms that is constantly being added to by biologists is genetic mutant designators. One class of these the system discovered consists of ten items: motB, tar, tsr, cheB, cheZ, cheY, cheA, flaA, flaE, double There are two apparent anomalies in this list, \"tar\" and \"double\", both common words in other contexts. The utility of the classification method is that it is sensitive to the particular use of these words in this specialized field. \"tar\" means \"taxis towards aspartate\" in this field and \"double\" is used to describe mutants which have two lesions in the same or different genes. Thus, if a table of mutants were constructed to summarize this set of papers it should include all ten items. The following class contains compounds that are attractants used in chemotaxis studies, aspartate, maltose, galactose, ribose, serine These could usefully be placed in a list summarizing the major compounds of interest. The word classes also include , which are fundamental to the understanding of living systems, chemotaxis, taxis, sensing, motility, rotation, behavior, movement, transport, uptake Again, a tabulation of these along with excerpts describing them or references to articles devoted to them would be useful as part of a summary. Note that the word classes shown above are both syntactically and semantically homogeneous. The examples above contain only nouns. The homogeneity is easily seen from some other classes generated by the system, adjectives: higher, lower, greater, less other, several, many molecular, structural nouns (physical units): degrees, min, s, mM, microM, nm', 'externalIds': {'MAG': 173427256.0, 'CorpusId': 16607679.0}, 'label': 0}\n",
      "{'paperId': '5507f4f666080cf1903788263763ba6c8e490983', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/5507f4f666080cf1903788263763ba6c8e490983', 'title': 'Research on named entity recognition of chinese electronic medical records based on multi-head attention mechanism and character-word information fusion', 'abstract': 'In the medical field, Named Entity Recognition (NER) plays a crucial role in the process of information extraction through electronic medical records and medical texts. To address the problems of long distance entity, entity confusion, and difficulty in boundary division in the Chinese electronic medical record NER task, we propose a Chinese electronic medical record NER method based on the multi-head attention mechanism and character-word fusion. This method uses a new character-word joint feature representation based on the pre-training model BERT and self-constructed domain dictionary, which can accurately divide the entity boundary and solve the impact of unregistered words. Subsequently, on the basis of the BiLSTM-CRF model, a multi-head attention mechanism is introduced to learn the dependency relationship between remote entities and entity information in different semantic spaces, which effectively improves the performance of the model. Experiments show that our models have better performance and achieves significant improvement compared to baselines. The specific performance is that the F1 value on the Chinese electronic medical record data set reaches 95.22%, which is 2.67%higher than the F1 value of the baseline model.', 'externalIds': {'DBLP': 'journals/jifs/ZhangWLZY22', 'DOI': '10.3233/jifs-212495', 'CorpusId': 247500995.0}, 'label': 1}\n",
      "{'paperId': '7c9f69848d28e0a7cbb00942ee83dab9773c23e4', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/7c9f69848d28e0a7cbb00942ee83dab9773c23e4', 'title': 'GPT-NER: Named Entity Recognition via Large Language Models', 'abstract': 'Despite the fact that large-scale Language Models (LLM) have achieved SOTA performances on a variety of NLP tasks, its performance on NER is still significantly below supervised baselines. This is due to the gap between the two tasks the NER and LLMs: the former is a sequence labeling task in nature while the latter is a text-generation model. In this paper, we propose GPT-NER to resolve this issue. GPT-NER bridges the gap by transforming the sequence labeling task to a generation task that can be easily adapted by LLMs e.g., the task of finding location entities in the input text\"Columbus is a city\"is transformed to generate the text sequence\"@@Columbus## is a city\", where special tokens @@## marks the entity to extract. To efficiently address the\"hallucination\"issue of LLMs, where LLMs have a strong inclination to over-confidently label NULL inputs as entities, we propose a self-verification strategy by prompting LLMs to ask itself whether the extracted entities belong to a labeled entity tag. We conduct experiments on five widely adopted NER datasets, and GPT-NER achieves comparable performances to fully supervised baselines, which is the first time as far as we are concerned. More importantly, we find that GPT-NER exhibits a greater ability in the low-resource and few-shot setups, when the amount of training data is extremely scarce, GPT-NER performs significantly better than supervised models. This demonstrates the capabilities of GPT-NER in real-world NER applications where the number of labeled examples is limited.', 'externalIds': {'DBLP': 'journals/corr/abs-2304-10428', 'DOI': '10.48550/arXiv.2304.10428', 'CorpusId': 258236561.0, 'ArXiv': 2304.10428}, 'label': 0}\n",
      "{'paperId': 'bbeed471a946eac19aeced258067f1534e1f1783', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/bbeed471a946eac19aeced258067f1534e1f1783', 'title': 'Cross-lingual Alignment Methods for Multilingual BERT: A Comparative Study', 'abstract': 'Multilingual BERT (mBERT) has shown reasonable capability for zero-shot cross-lingual transfer when fine-tuned on downstream tasks. Since mBERT is not pre-trained with explicit cross-lingual supervision, transfer performance can further be improved by aligning mBERT with cross-lingual signal. Prior work propose several approaches to align contextualised embeddings. In this paper we analyse how different forms of cross-lingual supervision and various alignment methods influence the transfer capability of mBERT in zero-shot setting. Specifically, we compare parallel corpora vs dictionary-based supervision and rotational vs fine-tuning based alignment methods. We evaluate the performance of different alignment methodologies across eight languages on two tasks: Name Entity Recognition and Semantic Slot Filling. In addition, we propose a novel normalisation method which consistently improves the performance of rotation-based alignment including a notable 3% F1 improvement for distant and typologically dissimilar languages. Importantly we identify the biases of the alignment methods to the type of task and proximity to the transfer language. We also find that supervision from parallel corpus is generally superior to dictionary alignments.', 'externalIds': {'MAG': 3089820221.0, 'DBLP': 'journals/corr/abs-2009-14304', 'DOI': '10.18653/v1/2020.findings-emnlp.83', 'CorpusId': 222067073.0, 'ACL': '2020.findings-emnlp.83', 'ArXiv': 2009.14304}, 'label': 0}\n",
      "{'paperId': 'e3042ed7f7a5d38ce4d73e1bac775453c5a55c60', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/e3042ed7f7a5d38ce4d73e1bac775453c5a55c60', 'title': 'Extracting the Interaction Relation between Proteins from Biomedical Literature using NLP Techniques for Drug Repurposing', 'abstract': 'Protein-protein interaction identification is essential to reveal the functional mechanism in living cells. Hence, the identification and prediction of protein-protein interaction are one of the essential needs in biology. Various experimental and computational methods are developed for predicting the interactions. Most protein-protein interaction detection systems have made predictions only based on the evidence from a single sentence which affects the model’s accuracy. In this paper, we approach protein-protein interaction through a different view where sequence-based approaches are used to identify the interactions which improve the performance of the system. This paper also deals with the protein pairs identification from a large corpus dataset using NLP techniques and text mining methods. These predictions play a significant role in drug repurposing.', 'externalIds': {'CorpusId': 245216973.0}, 'label': 1}\n",
      "{'paperId': '2d871bb34be5e5d824e6e2af313f47ae025f93ce', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/2d871bb34be5e5d824e6e2af313f47ae025f93ce', 'title': 'BANNER: An Executable Survey of Advances in Biomedical Named Entity Recognition', 'abstract': 'There has been an increasing amount of research on biomedical named entity recognition, the most basic text extraction problem, resulting in significant progress by different research teams around the world. This has created a need for a freely-available, open source system implementing the advances described in the literature. In this paper we present BANNER, an open-source, executable survey of advances in biomedical named entity recognition, intended to serve as a benchmark for the field. BANNER is implemented in Java as a machine-learning system based on conditional random fields and includes a wide survey of the best techniques recently described in the literature. It is designed to maximize domain independence by not employing brittle semantic features or rule-based processing steps, and achieves significantly better performance than existing baseline systems. It is therefore useful to developers as an extensible NER implementation, to researchers as a standard for comparing innovative techniques, and to biologists requiring the ability to find novel entities in large amounts of text.', 'externalIds': {'MAG': 2107005506.0, 'DBLP': 'conf/psb/LeamanG08', 'DOI': '10.1142/9789812776136_0062', 'CorpusId': 7666100.0, 'PubMed': 18229723.0}, 'label': 1}\n",
      "{'paperId': 'e302cb3e6b0f3553934c04b3da98d4028b6b7e10', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/e302cb3e6b0f3553934c04b3da98d4028b6b7e10', 'title': 'A Study of Recent Contributions on Information Extraction', 'abstract': 'This paper reports on modern approaches in Information Extraction (IE) and its two main sub-tasks of Named Entity Recognition (NER) and Relation Extraction (RE). Basic concepts and the most recent approaches in this area are reviewed, which mainly include Machine Learning (ML) based approaches and the more recent trend to Deep Learning (DL) based methods.', 'externalIds': {'MAG': 2790528770.0, 'DBLP': 'journals/corr/abs-1803-05667', 'CorpusId': 3902687.0, 'ArXiv': 1803.05667}, 'label': 0}\n",
      "{'paperId': 'a27d333d8638ee43b839ffb0778380fe318e9455', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/a27d333d8638ee43b839ffb0778380fe318e9455', 'title': 'Named entity recognition based on semi-supervised ensemble learning with the improved tri-training algorithm', 'abstract': 'Named entity recognition is one of the hot topics in natural language processing. The purpose is to identify named entities in text and summarize them into corresponding entity types. The deep learning model has achieved good results for the task of named entity recognition. Due to the lack of annotated corpus data for named entity recognition tasks in specific domains, it is difficult for a single deep learning model to achieve excellent performance. To this end, by ensembling Conditional Random Field (CRF) model, Bidirectional Gated Recurrent Unit (BiGRU) network model, and Bidirectional Long Short-Term Memory (BiLSTM) network model, with collaborative training Tri -training algorithm, we proposed a named entity recognition method based on semi-supervised ensemble learning (NER-SSEL). It aims to improve model performance through iterative training with a small amount of labeled data and a large amount of unlabeled data. First, a small amount of labeled data is used for pre-training on the three base learners, and then a collaborative training tri-training algorithm is used to provide reliable labels for the unlabeled raw data. To avoid the introduction of noisy data, we propose a repeated labeling strategy to select high-confidence samples and iteratively expand the training set through the consistency evaluation function. Finally, the model is integrated through the weighted voting method. This article conducts experiments on the ATIS data set. Experimental results show that the model proposed in this paper can effectively use a large amount of unlabeled data and significantly improve the F1 measure in the task of named entity recognition.', 'externalIds': {'MAG': 3156481584.0, 'DBLP': 'conf/icit/MaDJL20', 'DOI': '10.1145/3446999.3447002', 'CorpusId': 233194680.0}, 'label': 0}\n",
      "{'paperId': 'f6a6866cfa1ed69484e71335cedf52206420ef4b', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/f6a6866cfa1ed69484e71335cedf52206420ef4b', 'title': 'Research on Relation Extraction Method Based on Multi-channel Convolution and BiLSTM Model', 'abstract': 'Deep learning methods have achieved good results in relation extraction research and have received widespread attention. However, the existing deep learning methods use a single word vector model, which cannot fully utilize the rich semantic information and syntactic structure in the corpus. The high parameter dimension causes information overload and cannot make full use of context information. Aiming at the problems of the current method, this paper proposes a multichannel relation extraction framework that uses multiple word vector models to map the corpus to form a multi-channel. Feature extraction is performed through the neural network model fused with convolutional neural network, BiLSTM and attention mechanism, and finally completes the relationship extraction task through the classifier. The experimental results on the SemEval 2010 task 8 data set show that this method can not only acquire rich semantic information in the corpus, but also better learn local features and use contextual information. Compared with other methods, the method in this paper achieves competitive performance.', 'externalIds': {'DBLP': 'conf/ispa/SunW20', 'DOI': '10.1109/ISPA-BDCloud-SocialCom-SustainCom51426.2020.00162', 'CorpusId': 235340089.0}, 'label': 0}\n",
      "{'paperId': '55b4b9b303da1b0e8f938a80636ec95f7af235fd', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/55b4b9b303da1b0e8f938a80636ec95f7af235fd', 'title': 'Neural Question Answering at BioASQ 5B', 'abstract': 'This paper describes our submission to the 2017 BioASQ challenge. We participated in Task B, Phase B which is concerned with biomedical question answering (QA). We focus on factoid and list question, using an extractive QA model, that is, we restrict our system to output substrings of the provided text snippets. At the core of our system, we use FastQA, a state-of-the-art neural QA system. We extended it with biomedical word embeddings and changed its answer layer to be able to answer list questions in addition to factoid questions. We pre-trained the model on a large-scale open-domain QA dataset, SQuAD, and then fine-tuned the parameters on the BioASQ training set. With our approach, we achieve state-of-the-art results on factoid questions and competitive results on list questions.', 'externalIds': {'MAG': 2951666844.0, 'DBLP': 'conf/bionlp/WieseWN17', 'DOI': '10.18653/v1/W17-2309', 'CorpusId': 1915951.0, 'ACL': 'W17-2309', 'ArXiv': 1706.08568}, 'label': 1}\n",
      "{'paperId': '2679dbc4682b434ab5071f2c68b76a06954b96c0', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/2679dbc4682b434ab5071f2c68b76a06954b96c0', 'title': 'Robust Named Entity Recognition in Idiosyncratic Domains', 'abstract': 'Named entity recognition often fails in idiosyncratic domains. That causes a problem for depending tasks, such as entity linking and relation extraction. We propose a generic and robust approach for high-recall named entity recognition. Our approach is easy to train and offers strong generalization over diverse domain-specific language, such as news documents (e.g. Reuters) or biomedical text (e.g. Medline). Our approach is based on deep contextual sequence learning and utilizes stacked bidirectional LSTM networks. Our model is trained with only few hundred labeled sentences and does not rely on further external knowledge. We report from our results F1 scores in the range of 84-94% on standard datasets.', 'externalIds': {'MAG': 2512822132.0, 'DBLP': 'journals/corr/ArnoldGKL16', 'CorpusId': 17712146.0, 'ArXiv': 1608.06757}, 'label': 0}\n",
      "{'paperId': 'bf6ff60a107027d771c90650454a62e962ec4bd1', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/bf6ff60a107027d771c90650454a62e962ec4bd1', 'title': 'Results of the BioASQ Track of the Question Answering Lab at CLEF 2014', 'abstract': '. The goal of this task is to push the research frontier towards hybrid information systems. We aim to promote systems and approaches that are able to deal with the whole diversity of the Web, especially for, but not restricted to, the context of bio-medicine. This goal is pursued by the organization of challenges. The second challenge consisted of two tasks: semantic indexing and question answering. 61 systems participated by 18 diﬀerent participating teams for the semantic indexing task, of which between 25 and 45 participated in each batch. The semantic indexing task was tackled by 22 systems, which were developed by 8 diﬀerent organizations. Between 15 and 19 of these systems addressed each batch. The question answering task was tackled by 18 diﬀerent systems, developed by 7 diﬀerent organizations. Between 9 and 15 of these systems submitted results in each batch. Overall, the best systems were able to outperform the strong baselines provided by the organizers.', 'externalIds': {'DBLP': 'conf/clef/BalikasPNKP14', 'CorpusId': 15574601.0}, 'label': 1}\n",
      "{'paperId': '3eb108a27ed2739924d2b1d410f74ce8afc3e75e', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/3eb108a27ed2739924d2b1d410f74ce8afc3e75e', 'title': 'Edlin: an Easy to Read Linear Learning Framework', 'abstract': 'The Edlin toolkit provides a machine learning framework for linear models, designed to be easy to read and understand. The main goal is to provide easy to edit working examples of implementations for popular learning algorithms. The toolkit consists of 27 Java classes with a total of about 1400 lines of code, of which about 25% are I/O and driver classes for examples. A version of Edlin has been integrated as a processing resource for the GATE architecture, and has been used for gene tagging, gene name normalization, named entity recognition in Bulgarian and biomedical relation extraction.', 'externalIds': {'MAG': 2128751639.0, 'DBLP': 'conf/ranlp/GanchevG09', 'CorpusId': 17347394.0, 'ACL': 'R09-1018'}, 'label': 0}\n",
      "{'paperId': '2ad0995caffd67925abc86197d21f97bcfc9fc6f', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/2ad0995caffd67925abc86197d21f97bcfc9fc6f', 'title': 'Semi-Automated Clinical Lexicon Induction and Its Use in Cohort Selection from Clinical Notes', 'abstract': 'Special purpose lexicons are invaluable in biomedical natural language processing. They are especially crucial for a task such as the 13-criteria based cohort identification from clinical notes, process in N2C2 2018 Track 1 Challenge. While manually developed lexicons helped us achieve high performance, the process was ad hoc and nonreproducible. This paper presents a semi-automated lexicon induction method, using Logistic Regression (LR) and word embeddings, which brings rigor to the process. The key idea was to use n-grams in the training corpus as features of LR and identify those features (n-grams) with the most impact on the outcome as the lexicon. The semi-automatically generated lexicons achieved overall F measure of 0.9166 versus 0.9003 with manually generated lexicons. Therefore, this study shows that lexicons generated using a rigorous, semi-automated approach can retain performance while bringing rigor to the process.', 'externalIds': {'DBLP': 'conf/ichi/RawalPAKABD20', 'DOI': '10.1109/ICHI48887.2020.9374374', 'CorpusId': 232267311.0}, 'label': 1}\n",
      "{'paperId': 'd00dc6d72dcbca2ec75b48c97b9b47d018923883', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/d00dc6d72dcbca2ec75b48c97b9b47d018923883', 'title': 'Asserted Predica , on Inferred Predica , on Med 1 Med 2 Med 3 Disease *', 'abstract': 'Semantic MEDLINE applies automatic summarization techniques to manage the semantic predications extracted from the biomedical literature by SemRep. It does so by selecting salient predications based on several criteria. In this study, we investigated a new technique to automatically summarize SemRep predications. Our technique leverages hierarchical relations from the UMLS Metathesaurus for aggregating the semantic predications. We also generated new inferences from the aggregated semantic predications. Several quantitative measures are defined to evaluate the system. We applied our method to summarize medications used to treat diseases and also adverse drug events reported in the biomedical literature. Our preliminary experimental results are promising in terms of summarization rate. They also indicate that less than half of the newly generated inferences correspond to existing relations. Further work is needed to evaluate the rest of the inferences.', 'externalIds': {'CorpusId': 39831355.0}, 'label': 1}\n",
      "{'paperId': '79a087c8e6ee6ce5168e7e0232a85c344c28c8ec', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/79a087c8e6ee6ce5168e7e0232a85c344c28c8ec', 'title': 'Overview of the chemical compound and drug name recognition ( CHEMDNER ) task', 'abstract': 'There is an increasing need to facilitate automated access to information relevant for chemical compounds and drugs described in text, including scientific articles, patents or health agency reports. A number of recent efforts have implemented natural language processing (NLP) and text mining technologies for the chemical domain (ChemNLP or chemical text mining). Due to the lack of manually labeled Gold Standard datasets together with comprehensive annotation guidelines, both the implementation as well as the comparative assessment of ChemNLP technologies BSF opaque. Two key components for most chemical text mining technologies are the indexing of documents with chemicals (chemical document indexing CDI ) and finding the mentions of chemicals in text (chemical entity mention recognition CEM ). These two tasks formed part of the chemical compound and drug named entity recognition (CHEMDNER) task introduced at the fourth BioCreative challenge, a community effort to evaluate biomedical text mining applications. For this task, the CHEMDNER text corpus was constructed, consisting of 10,000 abstracts containing a total of 84,355 mentions of chemical compounds and drugs that have been manually labeled by domain experts following specific annotation guidelines. This corpus covers representative abstracts from major chemistry-related sub-disciplines such as medicinal chemistry, biochemistry, organic chemistry and toxicology. A total of 27 teams – 23 academic and 4 commercial HSPVQT, comprised of 87 researchers – submitted results for this task. Of these teams, 26 provided submissions for the CEM subtask and 23 for the CDI subtask. Teams were provided with the manual annotations of 7,000 abstracts to implement and train their systems and then had to return predictions for the 3,000 test set abstracts during a short period of time. When comparing exact matches of the automated results against the manually labeled Gold Standard annotations, the best teams reached an F-score ⋆ Corresponding author Proceedings of the fourth BioCreative challenge evaluation workshop, vol. 2 of 87.39% JO the CEM task and of 88.20% JO the CDI task. This can be regarded as a very competitive result when compared to the expected upper boundary, the agreement between to human annotators, at 91%. In general, the technologies used to detect chemicals and drugs by the teams included machine learning methods (particularly CRFs using a considerable range of different features), interaction of chemistry-related lexical resources and manual rules (e.g., to cover abbreviations, chemical formula or chemical identifiers). By promoting the availability of the software of the participating systems as well as through the release of the CHEMDNER corpus to enable implementation of new tools, this work fosters the development of text mining applications like the automatic extraction of biochemical reactions, toxicological properties of compounds, or the detection of associations between genes or mutations BOE drugs in the context pharmacogenomics.', 'externalIds': {'CorpusId': 18017390.0}, 'label': 1}\n",
      "{'paperId': '05e2e0ffc2f580db85d8e04b68641adbe214860b', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/05e2e0ffc2f580db85d8e04b68641adbe214860b', 'title': 'RNN Transducers for Nested Named Entity Recognition with constraints on alignment for long sequences', 'abstract': 'Popular solutions to Named Entity Recognition (NER) include conditional random fields, sequence-to-sequence models, or utilizing the question-answering framework. However, they are not suitable for nested and overlapping spans with large ontologies and for predicting the position of the entities. To fill this gap, we introduce a new model for NER task -- an RNN transducer (RNN-T). These models are trained using paired input and output sequences without explicitly specifying the alignment between them, similar to other seq-to-seq models. RNN-T models learn the alignment using a loss function that sums over all alignments. In NER tasks, however, the alignment between words and target labels are available from the human annotations. We propose a fixed alignment RNN-T model that utilizes the given alignment, while preserving the benefits of RNN-Ts such as modeling output dependencies. As a more general case, we also propose a constrained alignment model where users can specify a relaxation of the given input alignment and the model will learn an alignment within the given constraints. In other words, we propose a family of seq-to-seq models which can leverage alignments between input and target sequences when available. Through empirical experiments on a challenging real-world medical NER task with multiple nested ontologies, we demonstrate that our fixed alignment model outperforms the standard RNN-T model, improving F1-score from 0.70 to 0.74.', 'externalIds': {'DBLP': 'journals/corr/abs-2203-03543', 'DOI': '10.48550/arXiv.2203.03543', 'CorpusId': 247292211.0, 'ArXiv': 2203.03543}, 'label': 0}\n",
      "{'paperId': '7d6e997146ff3c0fd8e0ac2b8e22b4e78ad80267', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/7d6e997146ff3c0fd8e0ac2b8e22b4e78ad80267', 'title': 'Relation extraction methods for biomedical literature', 'abstract': 'This chapter provides a background and a review of existing techniques for extracting relations from biomedical text. We start with an overview of a relation extraction system. We then focus on each component employed in the extraction system, namely name entity recognition (NER), NLP tools, and ML methods. For each component being discussed, we provide a list of popular tools that are available for use. Furthermore, we also discuss the role of annotated corpora, how they influence the selection extraction methods. Finally, we present main approaches and their state-of-the-art results of relation extraction from biomedical text.', 'externalIds': {'CorpusId': 268858586.0}, 'label': 1}\n",
      "{'paperId': 'c21e5112bf3a739a5729371ae06abf63fb0ac224', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/c21e5112bf3a739a5729371ae06abf63fb0ac224', 'title': 'Relation extraction methods for biomedical literature', 'abstract': 'Disclaimer/Complaints regulations If you believe that digital publication of certain material infringes any of your rights or (privacy) interests, please let the Library know, stating your reasons. In case of a legitimate complaint, the Library will make the material inaccessible and/or remove it from the website. Please Ask the Library: https://uba.uva.nl/en/contact, or a letter to: Library of the University of Amsterdam, Secretariat, Singel 425, 1012 WP Amsterdam, The Netherlands. You will be contacted as soon as possible.', 'externalIds': {'CorpusId': 265680532.0}, 'label': 1}\n",
      "{'paperId': '6670546864bd235ea13669dae51c7dfe65944439', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/6670546864bd235ea13669dae51c7dfe65944439', 'title': 'BioKGBench: A Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science', 'abstract': 'Pursuing artificial intelligence for biomedical science, a.k.a. AI Scientist, draws increasing attention, where one common approach is to build a copilot agent driven by Large Language Models (LLMs). However, to evaluate such systems, people either rely on direct Question-Answering (QA) to the LLM itself, or in a biomedical experimental manner. How to precisely benchmark biomedical agents from an AI Scientist perspective remains largely unexplored. To this end, we draw inspiration from one most important abilities of scientists, understanding the literature, and introduce BioKGBench. In contrast to traditional evaluation benchmark that only focuses on factual QA, where the LLMs are known to have hallucination issues, we first disentangle\"Understanding Literature\"into two atomic abilities, i)\"Understanding\"the unstructured text from research papers by performing scientific claim verification, and ii) Ability to interact with structured Knowledge-Graph Question-Answering (KGQA) as a form of\"Literature\"grounding. We then formulate a novel agent task, dubbed KGCheck, using KGQA and domain-based Retrieval-Augmented Generation (RAG) to identify the factual errors of existing large-scale knowledge graph databases. We collect over two thousand data for two atomic tasks and 225 high-quality annotated data for the agent task. Surprisingly, we discover that state-of-the-art agents, both daily scenarios and biomedical ones, have either failed or inferior performance on our benchmark. We then introduce a simple yet effective baseline, dubbed BKGAgent. On the widely used popular knowledge graph, we discover over 90 factual errors which provide scenarios for agents to make discoveries and demonstrate the effectiveness of our approach. The code and data are available at https://github.com/westlake-autolab/BioKGBench.', 'externalIds': {'CorpusId': 270870328.0, 'ArXiv': 2407.00466}, 'label': 1}\n",
      "{'paperId': 'd8e3f41428691a450cb6b27bf02fc3cb3c539f11', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/d8e3f41428691a450cb6b27bf02fc3cb3c539f11', 'title': 'SynSigGAN: Generative Adversarial Networks for Synthetic Biomedical Signal Generation', 'abstract': 'Simple Summary This paper proposes a novel generative adversarial networks model, SynSigGAN, to generate any kind of synthetic biomedical signals. The generation of synthetic signals eliminates confidentiality concerns and accessibility problem of medical data. Synthetic data can be utilized for training medical students and machine learning models for the advancement and automation of healthcare systems. Our proposed model performs significantly better than existing models with a high correlation coefficient that measures the generated synthetic signals’ similarity with the original signals. Abstract Automating medical diagnosis and training medical students with real-life situations requires the accumulation of large dataset variants covering all aspects of a patient’s condition. For preventing the misuse of patient’s private information, datasets are not always publicly available. There is a need to generate synthetic data that can be trained for the advancement of public healthcare without intruding on patient’s confidentiality. Currently, rules for generating synthetic data are predefined and they require expert intervention, which limits the types and amount of synthetic data. In this paper, we propose a novel generative adversarial networks (GAN) model, named SynSigGAN, for automating the generation of any kind of synthetic biomedical signals. We have used bidirectional grid long short-term memory for the generator network and convolutional neural network for the discriminator network of the GAN model. Our model can be applied in order to create new biomedical synthetic signals while using a small size of the original signal dataset. We have experimented with our model for generating synthetic signals for four kinds of biomedical signals (electrocardiogram (ECG), electroencephalogram (EEG), electromyography (EMG), photoplethysmography (PPG)). The performance of our model is superior wheen compared to other traditional models and GAN models, as depicted by the evaluation metric. Synthetic biomedical signals generated by our approach have been tested while using other models that could classify each signal significantly with high accuracy.', 'externalIds': {'MAG': 3107668265.0, 'PubMedCentral': 7761837.0, 'DOI': '10.3390/biology9120441', 'CorpusId': 227953995.0, 'PubMed': 33287366.0}, 'label': 1}\n",
      "{'paperId': '873d60a5ced9cd00bbb94a0ac4977e49c6a8626e', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/873d60a5ced9cd00bbb94a0ac4977e49c6a8626e', 'title': 'Coreference Resolution in Biomedical Texts: a Machine Learning Approach', 'abstract': 'Motivation: Coreference resolution, the process of identifying different', 'externalIds': {'MAG': 1577815940.0, 'DBLP': 'conf/dagstuhl/SuYHTT08', 'CorpusId': 46177055.0}, 'label': 1}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'mentions of an entity, is a very important component in a', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'text-mining system. Compared with the work in news articles, the', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'existing study of coreference resolution in biomedical texts is quite', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'preliminary by only focusing on specific types of anaphors like pronouns', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'or definite noun phrases, using heuristic methods, and running', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'on small data sets. Therefore, there is a need for an in-depth', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'exploration of this task in the biomedical domain.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Results: In this article, we presented a learning-based approach', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'to coreference resolution in the biomedical domain. We made three', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'contributions in our study. Firstly, we annotated a large scale coreference', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'corpus, MedCo, which consists of 1,999 medline abstracts', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'in the GENIA data set. Secondly, we proposed a detailed framework', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'for the coreference resolution task, in which we augmented the traditional', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'learning model by incorporating non-anaphors into training.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Lastly, we explored various sources of knowledge for coreference', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'resolution, particularly, those that can deal with the complexity of', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'biomedical texts. The evaluation on the MedCo corpus showed promising', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'results. Our coreference resolution system achieved a high', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'precision of 85.2% with a reasonable recall of 65.3%, obtaining an', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'F-measure of 73.9%. The results also suggested that our augmented', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'learning model significantly boosted precision (up to 24.0%) without', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'much loss in recall (less than 5%), and brought a gain of over 8% in', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'F-measure.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': '45d98f7a834cd1351b6d9ee0da38a839eab3b31c', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/45d98f7a834cd1351b6d9ee0da38a839eab3b31c', 'title': 'Evaluating the Utility of Model Configurations and Data Augmentation on Clinical Semantic Textual Similarity', 'abstract': 'In this paper, we apply pre-trained language models to the Semantic Textual Similarity (STS) task, with a specific focus on the clinical domain. In low-resource setting of clinical STS, these large models tend to be impractical and prone to overfitting. Building on BERT, we study the impact of a number of model design choices, namely different fine-tuning and pooling strategies. We observe that the impact of domain-specific fine-tuning on clinical STS is much less than that in the general domain, likely due to the concept richness of the domain. Based on this, we propose two data augmentation techniques. Experimental results on N2C2-STS 1 demonstrate substantial improvements, validating the utility of the proposed methods.', 'externalIds': {'MAG': 3037439385.0, 'DBLP': 'conf/bionlp/WangLVB20', 'DOI': '10.18653/v1/2020.bionlp-1.11', 'CorpusId': 220057135.0, 'ACL': '2020.bionlp-1.11'}, 'label': 1}\n",
      "{'paperId': '24f8c6870af78a65929dcf926691e4cbe95d94e6', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/24f8c6870af78a65929dcf926691e4cbe95d94e6', 'title': 'Rethinking Boundaries: End-To-End Recognition of Discontinuous Mentions with Pointer Networks', 'abstract': 'A majority of research interests in irregular (e.g., nested or discontinuous) named entity recognition (NER) have been paid on nested entities, while discontinuous entities received limited attention. Existing work for discontinuous NER, however, either suffers from decoding ambiguity or predicting using token-level local features. In this work, we present an innovative model for discontinuous NER based on pointer networks, where the pointer simultaneously decides whether a token at each decoding frame constitutes an entity mention and where the next constituent token is. Our model has three major merits compared with previous work: (1) The pointer mechanism is memory-augmented, which enhances the mention boundary detection and interactions between the current decision and prior recognized mentions. (2) The encoder-decoder architecture can linearize the complexity of structure prediction, and thus reduce search costs. (3) The model makes every decision using global information, i.e., by consulting all the input, encoder and previous decoder output in a global view. Experimental results on the CADEC and ShARe13 datasets show that our model outperforms flat and hypergraph models as well as a state-of-the-art transition-based model for discontinuous NER. Further in-depth analysis demonstrates that our model performs well in recognizing various entities including flat, overlapping and discontinuous ones. More crucially, our model is effective on boundary detection, which is the kernel source to NER.', 'externalIds': {'DBLP': 'conf/aaai/0001JLLRL21', 'DOI': '10.1609/aaai.v35i14.17513', 'CorpusId': 235349256.0}, 'label': 0}\n",
      "{'paperId': '18d85088e8f79ae0fea00772ac346f76780e9b03', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/18d85088e8f79ae0fea00772ac346f76780e9b03', 'title': 'Modeling Multi-Granularity Hierarchical Features for Relation Extraction', 'abstract': 'Relation extraction is a key task in Natural Language Processing (NLP), which aims to extract relations between entity pairs from given texts. Recently, relation extraction (RE) has achieved remarkable progress with the development of deep neural networks. Most existing research focuses on constructing explicit structured features using external knowledge such as knowledge graph and dependency tree. In this paper, we propose a novel method to extract multi-granularity features based solely on the original input sentences. We show that effective structured features can be attained even without external knowledge. Three kinds of features based on the input sentences are fully exploited, which are in entity mention level, segment level, and sentence level. All the three are jointly and hierarchically modeled. We evaluate our method on three public benchmarks: SemEval 2010 Task 8, Tacred, and Tacred Revisited. To verify the effectiveness, we apply our method to different encoders such as LSTM and BERT. Experimental results show that our method significantly outperforms existing state-of-the-art models that even use external knowledge. Extensive analyses demonstrate that the performance of our model is contributed by the capture of multi-granularity features and the model of their hierarchical structure.', 'externalIds': {'DBLP': 'conf/naacl/LiangW0022', 'DOI': '10.48550/arXiv.2204.04437', 'CorpusId': 248085496.0, 'ACL': '2022.naacl-main.375', 'ArXiv': 2204.04437}, 'label': 0}\n",
      "{'paperId': 'f8f784344b0bae0cc0fb968a1cac599391e8a8c7', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/f8f784344b0bae0cc0fb968a1cac599391e8a8c7', 'title': 'Pre-trained models, data augmentation, and ensemble learning for biomedical information extraction and document classification', 'abstract': 'Abstract Large volumes of publications are being produced in biomedical sciences nowadays with ever-increasing speed. To deal with the large amount of unstructured text data, effective natural language processing (NLP) methods need to be developed for various tasks such as document classification and information extraction. BioCreative Challenge was established to evaluate the effectiveness of information extraction methods in biomedical domain and facilitate their development as a community-wide effort. In this paper, we summarize our work and what we have learned from the latest round, BioCreative Challenge VII, where we participated in all five tracks. Overall, we found three key components for achieving high performance across a variety of NLP tasks: (1) pre-trained NLP models; (2) data augmentation strategies and (3) ensemble modelling. These three strategies need to be tailored towards the specific tasks at hands to achieve high-performing baseline models, which are usually good enough for practical applications. When further combined with task-specific methods, additional improvements (usually rather small) can be achieved, which might be critical for winning competitions. Database URL: https://doi.org/10.1093/database/baac066', 'externalIds': {'DBLP': 'journals/biodb/ErdengasilengHZ22', 'PubMedCentral': 9375052.0, 'DOI': '10.1093/database/baac066', 'CorpusId': 251539963.0, 'PubMed': 35962559.0}, 'label': 1}\n",
      "{'paperId': '1089b1122c36e3c6204deeccd0f029891a969391', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/1089b1122c36e3c6204deeccd0f029891a969391', 'title': \"Evidence-based modeling of mode-of-action for functional ingredients influencing Alzheimer's disease through neurotrophin pathway\", 'abstract': 'Background : Brain-derived neurotrophic factor (BDNF) is the most widely expressed member of the neurotrophin family in the human brain and is crucially involved in the development of neural circuits, modulation of synaptic plasticity, and regulation of cognitive functions, including learning and memory. Many studies have shown the association of altered BDNF levels with neurodegenerative and neuropsychiatric disorders. However, BDNF is not able to cross the blood-brain barrier and, thus, its delivery to the nervous system is a challenge. Therefore, functional diets with the ability to induce production of BDNF in the brain may offer an alternative route. The objective of this study was three-fold: first, to find out diets that are causally linked to the agonistic activity of BDNF in the neurotrophin signaling pathway; second and mainly, to investigate mode-of-action of these functional diets through systems-based mechanistic modeling in the context of Alzheimer’s disease; and third, to demonstrate the proof-of-concept application of systems biology methods, that are well established in the pharmaceutical sector, to the emerging field of functional food. Methods : In the first step, two cause-and-effect models of BDNF signaling in two states, i.e. normal state and Alzheimer’s disease state, were constructed using published knowledge in scientific literature and pathway databases. A “differential model analysis” between the two states was performed by which mechanistic mode-of-action of BDNF in neurotrophin signaling pathway could be explained with a high molecular resolution in both normal and disease states. The BDNF mode-of-action model was further validated using the “biomarkerguided validation” approach. In the second step, scientific evidence on the effect of various functional diets on BDNF levels and BDNF-related biological processes or outcomes was harvested from biomedical literature using a disease-specific semantic search. This information was then added to the mechanistic model of BDNF mode-of-action and used to substantiate the mode-of-action model. Results : The differential model analysis resulted in a mechanistic mode-of-action model for \\xa0the effector BDNF signaling pathway through NTRK receptors (Neurotrophic tyrosine kinase receptor type 2) in neurons. The model revealed an amyloid-mediated neurotrophin switch mechanism by which the amyloid-beta protein competitively blocks BDNF-NTRK2 downstream signaling under Alzheimer’s conditions, thereby “switching” the entire pathway from its normal state with neuroprotective effect to the disease state with a strong push towards neuron apoptosis. This hypothetical switch mechanism was validated by expressed biomarkers as well as empirical data obtained from experimentation of BDNF mimetics in animal models. Several functional diets were found in the literature that showed agonistic effects on the effector BDNF pathway. These effects are exerted through increased levels of BDNF and subsequently, activating the BDNF survival pathway, which leads to similar observations that have been made with BDNF mimetics in animal models. Conclusions : To our knowledge, this is the first study to investigate mode-of-action of functional foods using systems-based modeling approaches. Moreover, such models can answer the question how functional diets can possibly act at the molecular level and interfere with the disease mechanism. Using scientific evidence supporting such models, there is a possibility to introduce new functional formulations by combining functional ingredients of these diets. Keywords : evidence-based modeling, mode-of-action, functional ingredient, BDNF, Alzheimer’s disease', 'externalIds': {'MAG': 2112307089.0, 'DOI': '10.31989/FFHD.V4I8.147', 'CorpusId': 14407676.0}, 'label': 0}\n",
      "{'paperId': 'c774713b2598c550852d1fcddb75db69db2a43f6', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/c774713b2598c550852d1fcddb75db69db2a43f6', 'title': 'Biomedical concept extraction based on combining the content-based and word order similarities', 'abstract': 'It is well known that the main objective of conceptual retrieval models is to go beyond simple term matching by relaxing term independence assumption through concept recognition. In this paper, we present an approach of semantic indexing and retrieval of biomedical documents through the process of identifying domain concepts extracted from the Medical Subject Headings (MeSH) thesaurus. Our indexing approach relies on a purely statistical vector space model, which represents medical documents and MeSH concepts as term vectors. By leveraging a combination of the bag-of-words concept representation and word positions in the textual features, we demonstrate that our mapping method is able to extract valuable concepts from documents. The output of this semantic mapping serves as the input to our relevance document scoring in response to a query. Experiments on the OHSUMED collection show that our semantic indexing method significantly outperforms state-of-art baselines that employ word or term statistics.', 'externalIds': {'MAG': 2067611762.0, 'DBLP': 'conf/sac/DinhT11', 'DOI': '10.1145/1982185.1982438', 'CorpusId': 14226472.0}, 'label': 1}\n",
      "{'paperId': '03808261627a8503284adccb780961b69bfb300e', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/03808261627a8503284adccb780961b69bfb300e', 'title': 'Improving Relation Classification by Entity Pair Graph', 'abstract': 'Relation classification is one of the most important tasks in the field of information extraction, and also a key component of systems that require relational understanding of unstructured text. Existing relation classification approaches mainly rely on exploiting external resources and background knowledge to improve the performance and ignore the correlations between entity pairs which are helpful for relation classification. We present the concept of entity pair graph to represent the correlations between entity pairs and propose a novel entity pair graph based neural network (EPGNN) model, relying on graph convolutional network to capture the topological features of an entity pair graph. EPGNN combines sentence semantic features generated by pre-trained BERT model with graph topological features for relation classification. Our proposed model makes full use of a given corpus and forgoes the need of external resources and background knowledge. The experimental results on two widely used dataset: SemEval 2010 Task 8 and ACE 2005, show that our method outperforms the state-of-the-art approaches.', 'externalIds': {'MAG': 2983506369.0, 'DBLP': 'conf/acml/ZhaoWGL19', 'CorpusId': 204826123.0}, 'label': 0}\n",
      "{'paperId': 'beffea1f77b72f0468b9bcb6dc04de24ac38b8bf', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/beffea1f77b72f0468b9bcb6dc04de24ac38b8bf', 'title': 'Sequence-Specific Probe-Mediated Isothermal Amplification for the Single-Copy Sensitive Detection of Nucleic Acid.', 'abstract': 'There is currently the lack of a method for precisely monitoring the progress of isothermal amplification reactions by means of sequence-specific fluorescent probes like the TaqMan probe used in the PCR system. Here, we created a circular fluorescent probe-mediated isothermal amplification (CFPA) method. This novel method uses two circular fluorescent probes and Bst DNA polymerase to construct an overlapping structure that can be cut off by flap structure-specific endonuclease 1, separating the fluorescence and quenching groups on the probes. The results showed single-copy sensitivity, ultrahigh specificity, stability (C.V. < 0.1), and anti-interference ability in detecting nucleic acid samples. A clinical trial demonstrated the perfect effectiveness of this method in the diagnosis of rotavirus infection and consistency with the gold standard method used in the clinic ( p > 0.05). In summary, we present a new, reliable, and precise isothermal amplification approach for applications in biomedical research and the clinical accurate diagnosis of pathogen infections.', 'externalIds': {'MAG': 2942952423.0, 'DOI': '10.1021/acs.analchem.9b00812', 'CorpusId': 143434087.0, 'PubMed': 31046251.0}, 'label': 0}\n",
      "{'paperId': 'd400ab22e100dd4d24672ad69b4f0546439fb000', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/d400ab22e100dd4d24672ad69b4f0546439fb000', 'title': 'Ontology Enrichment from Texts: A Biomedical Dataset for Concept Discovery and Placement', 'abstract': 'Mentions of new concepts appear regularly in texts and require automated approaches to harvest and place them into Knowledge Bases (KB), e.g., ontologies and taxonomies. Existing datasets suffer from three issues, (i) mostly assuming that a new concept is pre-discovered and cannot support out-of-KB mention discovery; (ii) only using the concept label as the input along with the KB and thus lacking the contexts of a concept label; and (iii) mostly focusing on concept placement w.r.t a taxonomy of atomic concepts, instead of complex concepts, i.e., with logical operators. To address these issues, we propose a new benchmark, adapting MedMentions dataset (PubMed abstracts) with SNOMED CT versions in 2014 and 2017 under the Diseases sub-category and the broader categories of Clinical finding, Procedure, and Pharmaceutical / biologic product. We provide usage on the evaluation with the dataset for out-of-KB mention discovery and concept placement, adapting recent Large Language Model based methods.', 'externalIds': {'DBLP': 'conf/cikm/0002C0023', 'DOI': '10.1145/3583780.3615126', 'CorpusId': 259252051.0, 'ArXiv': 2306.14704}, 'label': 1}\n",
      "{'paperId': '3b29cd179f13d69de139a1cd73877f7ab5c2841c', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/3b29cd179f13d69de139a1cd73877f7ab5c2841c', 'title': 'MEDICAL BOT USING ARTIFICIAL INTELLIGENCE', 'abstract': 'Nowadays people hardly try to consult a doctor for diagnosing disease, they instead search in internet sources, where the information is scattered and sometimes, required medical advice is not available. So, it is impractical to find the required information. People sometimes ignore the symptoms and later regret their decision. Healthcare is very important to lead a good life. However, it is very difficult to obtain the consultation with the doctor for every health problem. The idea is to create a medical chatbot using Artificial Intelligence that can diagnose the disease and provide basic details about the disease before consulting a doctor. This will help to reduce healthcare costs and improve accessibility to medical knowledge through medical chatbot. Chatbots are computer programs that use natural language to interact with users. The chatbot stores the data in the database to identify the sentence keywords and to make a query decision and answer the question. Named Entity recognition and cosine similarity is performed to make a reliable reply to the user.', 'externalIds': {'DOI': '10.26562/irjcs.2022.v0909.06', 'CorpusId': 259902264.0}, 'label': 1}\n",
      "{'paperId': 'db328685d00ec35fe35f9350f884c7b4b8db3f4c', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/db328685d00ec35fe35f9350f884c7b4b8db3f4c', 'title': 'Unsupervised Ontology Induction from Text', 'abstract': 'Extracting knowledge from unstructured text is a long-standing goal of NLP. Although learning approaches to many of its subtasks have been developed (e.g., parsing, taxonomy induction, information extraction), all end-to-end solutions to date require heavy supervision and/or manual engineering, limiting their scope and scalability. We present OntoUSP, a system that induces and populates a probabilistic ontology using only dependency-parsed text as input. OntoUSP builds on the USP unsupervised semantic parser by jointly forming ISA and IS-PART hierarchies of lambda-form clusters. The ISA hierarchy allows more general knowledge to be learned, and the use of smoothing for parameter estimation. We evaluate OntoUSP by using it to extract a knowledge base from biomedical abstracts and answer questions. OntoUSP improves on the recall of USP by 47% and greatly outperforms previous state-of-the-art approaches.', 'externalIds': {'MAG': 2121855012.0, 'DBLP': 'conf/acl/PoonD10', 'CorpusId': 1473515.0, 'ACL': 'P10-1031'}, 'label': 0}\n",
      "{'paperId': '6ac9a58a3be9d2840bdf5acd0fb8d1cbb9482d95', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/6ac9a58a3be9d2840bdf5acd0fb8d1cbb9482d95', 'title': 'Multi-view Embedding for Biomedical Ontology Matching', 'abstract': '. The goal of ontology matching (OM) is to identify mappings be-tween entities from different yet overlapping ontologies so as to facilitate semantic integration, reuse and interoperability. Representation learning methods have been applied to OM tasks with the development of deep learning. However, there still exist two limitations. Firstly, these methods are of poor capability of encoding sparse entities in ontologies. Secondly, most methods focus on the terminological-based features to learn word vectors for discovering mappings, but they do not make full use of structural relations in ontologies. It may cause that these methods heavily rely on the performance of pre-training and are limited without dictionaries or sufﬁcient textual corpora. To address these issues, we pro-pose an alternative ontology matching framework called MultiOM, which models the matching process by embedding techniques from multiple views. We design different loss functions based on cross-entropy to learn the vector representations of concepts, and further propose a novel negative sampling skill tailored for the structural relations asserted in ontologies. The preliminary result on real-world biomedical ontologies indicates that MultiOM is competitive with several OAEI top-ranked systems in terms of F1-measure.', 'externalIds': {'MAG': 3003565723.0, 'DBLP': 'conf/semweb/LiDWZQ19', 'CorpusId': 208268509.0}, 'label': 1}\n",
      "{'paperId': 'a10909a95a786243aa5b9b620964336ffeda60ae', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/a10909a95a786243aa5b9b620964336ffeda60ae', 'title': 'An Empirical Study on Relation Extraction in the Biomedical Domain', 'abstract': 'Relation extraction is a fundamental problem in natural language processing. Most existing models are defined for relation extraction in the general domain. However, their performance on specific domains (e.g., biomedicine) is yet unclear. To fill this gap, this paper carries out an empirical study on relation extraction in biomedical research articles. Specifically, we consider both sentence-level and document-level relation extraction, and run a few state-of-the-art methods on several benchmark datasets. Our results show that (1) current document-level relation extraction methods have strong generalization ability; (2) existing methods require a large amount of labeled data for model fine-tuning in biomedicine. Our observations may inspire people in this field to develop more effective models for biomedical relation extraction.', 'externalIds': {'DBLP': 'journals/corr/abs-2112-05910', 'CorpusId': 245124471.0, 'ArXiv': 2112.0591}, 'label': 1}\n",
      "{'paperId': '2564311193e73e735c6652f2f51962d7d31f926d', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/2564311193e73e735c6652f2f51962d7d31f926d', 'title': 'An overview of the BIOASQ large-scale biomedical semantic indexing and question answering competition', 'abstract': 'George Tsatsaronis (george.tsatsaronis@biotec.tu-dresden.de) Georgios Balikas (georgios.balikas@imag.fr) Prodromos Malakasiotis (rulller@gmail.com) Ioannis Partalas (ioannis.partalas@imag.fr) Matthias Zschunke (mzschunke@transinsight.com) Michael R Alvers (malvers@transinsight.com) Dirk Weissenborn (dirk.weissenborn@gmail.com) Anastasia Krithara (akrithara@iit.demokritos.gr) Sergios Petridis (eserxio@gmail.com) Dimitris Polychronopoulos (dpolychr@gmail.com) Yannis Almirantis (yalmir@bio.demokritos.gr) John Pavlopoulos (annis@aueb.gr) Nicolas Baskiotis (nicolas.baskiotis@lip6.fr) Patrick Gallinari (Patrick.Gallinari@lip6.fr) Thierry Artiéres (thierry.artieres@lip6.fr) Axel Ngonga (axel.ngonga@gmail.com) Norman Heino (heino@informatik.uni-leipzig.de) Eric Gaussier (eric.gaussier@imag.fr) Liliana Barrio-Alvers (lalvers@transinsight.com) Michael Schroeder (ms@biotec.tu-dresden.de) Ion Androutsopoulos (ion@aueb.gr) Georgios Paliouras (paliourg@iit.demokritos.gr)', 'externalIds': {'CorpusId': 267836514.0}, 'label': 1}\n",
      "{'paperId': '615c34193a26b8a5dc04407d777ea0ff81114fb5', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/615c34193a26b8a5dc04407d777ea0ff81114fb5', 'title': 'An Analysis on Large Language Models in Healthcare: A Case Study of BioBERT', 'abstract': \"This paper conducts a comprehensive investigation into applying large language models, particularly on BioBERT, in healthcare. It begins with thoroughly examining previous natural language processing (NLP) approaches in healthcare, shedding light on the limitations and challenges these methods face. Following that, this research explores the path that led to the incorporation of BioBERT into healthcare applications, highlighting its suitability for addressing the specific requirements of tasks related to biomedical text mining. The analysis outlines a systematic methodology for fine-tuning BioBERT to meet the unique needs of the healthcare domain. This approach includes various components, including the gathering of data from a wide range of healthcare sources, data annotation for tasks like identifying medical entities and categorizing them, and the application of specialized preprocessing techniques tailored to handle the complexities found in biomedical texts. Additionally, the paper covers aspects related to model evaluation, with a focus on healthcare benchmarks and functions like processing of natural language in biomedical, question-answering, clinical document classification, and medical entity recognition. It explores techniques to improve the model's interpretability and validates its performance compared to existing healthcare-focused language models. The paper thoroughly examines ethical considerations, particularly patient privacy and data security. It highlights the benefits of incorporating BioBERT into healthcare contexts, including enhanced clinical decision support and more efficient information retrieval. Nevertheless, it acknowledges the impediments and complexities of this integration, encompassing concerns regarding data privacy, transparency, resource-intensive requirements, and the necessity for model customization to align with diverse healthcare domains.\", 'externalIds': {'DBLP': 'journals/corr/abs-2310-07282', 'DOI': '10.48550/arXiv.2310.07282', 'CorpusId': 263835277.0, 'ArXiv': 2310.07282}, 'label': 1}\n",
      "{'paperId': '02809fc23aecf33e3ed95b83d1d03b54fb5c3d0a', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/02809fc23aecf33e3ed95b83d1d03b54fb5c3d0a', 'title': 'An Empirical Study of Multi-Task Learning on BERT for Biomedical Text Mining', 'abstract': 'Multi-task learning (MTL) has achieved remarkable success in natural language processing applications. In this work, we study a multi-task learning model with multiple decoders on varieties of biomedical and clinical natural language processing tasks such as text similarity, relation extraction, named entity recognition, and text inference. Our empirical results demonstrate that the MTL fine-tuned models outperform state-of-the-art transformer models (e.g., BERT and its variants) by 2.0% and 1.3% in biomedical and clinical domain adaptation, respectively. Pairwise MTL further demonstrates more details about which tasks can improve or decrease others. This is particularly helpful in the context that researchers are in the hassle of choosing a suitable model for new problems. The code and models are publicly available at https://github.com/ncbi-nlp/bluebert.', 'externalIds': {'MAG': 3021010716.0, 'DBLP': 'journals/corr/abs-2005-02799', 'DOI': '10.18653/v1/2020.bionlp-1.22', 'CorpusId': 218516872.0, 'ACL': '2020.bionlp-1.22', 'ArXiv': 2005.02799}, 'label': 1}\n",
      "{'paperId': '5dfadaabd95a2efa3219d07b009a4188f2a1bf50', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/5dfadaabd95a2efa3219d07b009a4188f2a1bf50', 'title': 'Improving biomedical document retrieval using domain knowledge', 'abstract': 'Research articles typically introduce new results or findings and relate them to knowledge entities of immediate relevance. However, a large body of context knowledge related to the results is often not explicitly mentioned in the article. To overcome this limitation the state-of-the-art information retrieval approaches rely on the latent semantic analysis in which terms in articles are projected to a lower dimensional latent space and best possible matches in this space are identified. However, this approach may not perform well enough if the number of explicit knowledge entities in the articles is too small compared to the amount of knowledge in the domain. We address the problem by exploiting a domain knowledge layer, a rich network of relations among knowledge entities in the domain extracted from a large corpus of documents. The knowledge layer supplies the context knowledge that lets us relate different knowledge entities and hence improve the information retrieval performance. We develop and study a new framework for i) learning and aggregating the relations in the knowledge layer from the literature corpus; ii) and for exploiting these relations to improve the information-retrieval of relevant documents.', 'externalIds': {'MAG': 2027709437.0, 'DBLP': 'conf/sigir/WangH08', 'DOI': '10.1145/1390334.1390503', 'CorpusId': 11938420.0}, 'label': 1}\n",
      "{'paperId': 'a5dd230970c90f311f10b9c59283eb4131f4fc79', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/a5dd230970c90f311f10b9c59283eb4131f4fc79', 'title': 'Domain adaptive bootstrapping for named entity recognition', 'abstract': 'Bootstrapping is the process of improving the performance of a trained classifier by iteratively adding data that is labeled by the classifier itself to the training set, and retraining the classifier. It is often used in situations where labeled training data is scarce but unlabeled data is abundant. In this paper, we consider the problem of domain adaptation: the situation where training data may not be scarce, but belongs to a different domain from the target application domain. As the distribution of unlabeled data is different from the training data, standard bootstrapping often has difficulty selecting informative data to add to the training set. We propose an effective domain adaptive bootstrapping algorithm that selects unlabeled target domain data that are informative about the target domain and easy to automatically label correctly. We call these instances bridges, as they are used to bridge the source domain to the target domain. We show that the method outperforms supervised, transductive and bootstrapping algorithms on the named entity recognition task.', 'externalIds': {'MAG': 2649602478.0, 'DBLP': 'conf/emnlp/WuLYC09', 'DOI': '10.3115/1699648.1699699', 'CorpusId': 18958973.0, 'ACL': 'D09-1158'}, 'label': 0}\n",
      "{'paperId': 'be0735eaf6877602ebaa00af946afbd5fafb699e', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/be0735eaf6877602ebaa00af946afbd5fafb699e', 'title': 'PlatCOVID: A Novel Web Tool to Analyze, Curate and Share COVID-19 Literature', 'abstract': ' BackgroundIn the attempt to face the COVID-19 pandemic, the global scientific community has been expending great efforts to produce useful and reliable data aiming to help patients, physicians and guiding public health policies. A huge amount of information is being released every week, making impossible for a single person (or even for a research group) to read everything and get constantly updated on the scientific literature concerning COVID-19 and its etiological agent, SARS-CoV-2. Therefore, we developed PlatCOVID (www.platcovid.com), a Web platform designed to analyze, cluster, classify and discuss COVID-19 literature available on LitCovid (NCBI). ResultsPlatCOVID has been created as a novel COVID-19 hub able to add features of text mining and syntax analyses methods, such as word and sentence atomization and tokenization, clusterization and classification. The main division of the literature comprehends five categories: 1) Diagnosis; 2) Epidemiology; 3) Clinical, Signs & Symptoms; 4) Transmission; and 5) Treatment & Prevention. Consequently, it is possible to reduce the amount of text to be read with minimal loss of information, identifying target subjects by mining as new insights arise, enhancing data analysis efficiency. PlatCOVID has been designed with central panels (Gene, Drug and Tissue panels) to easily gather and share with the scientific community important COVID-19 information.ConclusionsAlthough most of the text mining and syntax analysis is made by using automated computing processes, the final results must to be humanly curated. With this in mind, PlatCOVID allows researchers to be part of our effort to curate, analyze, discuss and rate each matter of interest (helpus.platcovid.com). We welcome user feedback for further enhancement.', 'externalIds': {'MAG': 3117947035.0, 'DOI': '10.21203/rs.3.rs-42169/v1', 'CorpusId': 234634389.0}, 'label': 1}\n",
      "{'paperId': '26170ccf16308898faa4c28fc5da68524dbb5a66', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/26170ccf16308898faa4c28fc5da68524dbb5a66', 'title': 'ICB-UMA at CLEF e-Health 2020 Task 1: Automatic ICD-10 coding in Spanish with BERT', 'abstract': '. This working notes paper presents our contribution to the CLEF eHealth 2020 Task 1. Our team has participated in the CodiEsp-D subtask, the ﬁrst shared task consisted in the automatic clinical coding of medical cases in Spanish, annotated with ICD-10-CM codes. We tackled the task as a multi-label classiﬁcation problem using BERT model [4]. With the aim of leveraging all the language modeling capacities of the deep bidirectional encoder architecture of BERT, we developed a tailored approach to annotate short fragments of text extracted from the long clinical cases present in the CodiEsp corpus and use them as input to the model. Two publicly available Spanish versions of BERT, namely BETO [3] and BERT-SciELO [1], were ﬁne-tuned on the CodiEsp-D corpus extended by a set of abstracts annotated with ICD-10 codes, following our fragment-based classiﬁcation approach. BERT-SciELO, a BERT-Base model pre-trained from scratch on an unlabeled corpus of biomedical articles in Spanish, achieved the best results among our three submitted systems, obtaining a ﬁnal Mean Average Precision (MAP) metric score of 0.482 on the evaluation set.', 'externalIds': {'MAG': 3097007564.0, 'DBLP': 'conf/clef/Lopez-GarciaJV20', 'CorpusId': 225073855.0}, 'label': 1}\n",
      "{'paperId': '52c22ada15ec16b724c44eb5e403fee67ee667da', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/52c22ada15ec16b724c44eb5e403fee67ee667da', 'title': 'A Probabilistic Key phrase extraction approach on large biomedical documents', 'abstract': '— As the size of the biomedical databases are increasing day-by-day, finding an essential feature set for classification problem is complex due to large data size and sparsity problems. Text feature ranking and clustering is one of the major challenges to scientific and medical researchers due to its high dimensional feature space and limited number of samples. High dimensionality of the feature space is one of the major issues in biomedical document clustering due to large number of candidates sets. Selection of high probabilistic features for clustering is therefore essential for biomedical document analysis such as classification and clustering. In this paper, a novel probabilistic key phrase extraction and preprocessing model is designed and implemented on large number of biomedical documents. In this framework, a novel key-phrase extraction method is used to filter the large biomedical document sets. Experimental results show that the present key phrase extraction approach is better than existing key-phrase extraction approaches in terms of runtime and accuracy are concerned', 'externalIds': {'CorpusId': 235399030.0}, 'label': 1}\n",
      "{'paperId': '34b6dba255e98fdcddcc402f728df1be62e6fde0', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/34b6dba255e98fdcddcc402f728df1be62e6fde0', 'title': 'Instance-Based Learning of Span Representations: A Case Study through Named Entity Recognition', 'abstract': 'Interpretable rationales for model predictions play a critical role in practical applications. In this study, we develop models possessing interpretable inference process for structured prediction. Specifically, we present a method of instance-based learning that learns similarities between spans. At inference time, each span is assigned a class label based on its similar spans in the training set, where it is easy to understand how much each training instance contributes to the predictions. Through empirical analysis on named entity recognition, we demonstrate that our method enables to build models that have high interpretability without sacrificing performance.', 'externalIds': {'MAG': 3034861800.0, 'DBLP': 'conf/acl/OuchiSKYKKI20', 'DOI': '10.18653/v1/2020.acl-main.575', 'CorpusId': 216915281.0, 'ACL': '2020.acl-main.575', 'ArXiv': 2004.14514}, 'label': 0}\n",
      "{'paperId': '36ffbc5f14fab380516943f95e5f794fd4542977', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/36ffbc5f14fab380516943f95e5f794fd4542977', 'title': 'The overview of the NLM-Chem BioCreative VII track Full-text Chemical Identification and Indexing in PubMed articles', 'abstract': \"— The BioCreative NLM-Chem track calls for a community effort to fine-tune automated recognition of chemical names in biomedical literature. Chemical names are one of the most searched biomedical entities in PubMed and – as highlighted during the COVID-19 pandemic – their identification may significantly advance research in multiple biomedical subfields. While previous community challenges focused on identifying chemical names mentioned in titles and abstracts, the full text contains valuable additional detail. We organized the BioCreative NLM-Chem track to call for a community effort to address automated chemical entity recognition in full-text articles. The track consisted of two tasks: 1) Chemical Identification task, and 2) Chemical Indexing prediction task. For the Chemical Identification task, participants were expected to predict with high accuracy all chemicals mentioned in recently published full-text articles, both span (i.e., named entity recognition) and normalization (i.e., entity linking) using MeSH. For the Chemical Indexing task, participants identified which chemicals should be indexed as topics for the article's topic terms in the NLM article and indexing, i.e., appear in the listing of MeSH terms for the document. This manuscript summarizes the BioCreative NLM-Chem track. We received a total of 88 submissions in total from 17 teams worldwide. The highest performance achieved for the Chemical Identification task was 0.8672 f-score (0.8759 precision, 0.8587 recall) for strict NER performance and 0.8136 f-score (0.8621 precision, 0.7702 recall) for strict normalization performance. The highest performance achieved for the Chemical Indexing task was 0.4825 f-score (0.4397 precision, 0.5344 recall). The NLM-Chem track dataset and other challenge materials\", 'externalIds': {'CorpusId': 243984738.0}, 'label': 1}\n",
      "{'paperId': 'd2c0637fd1d8b817667841cf6f9397bc266dde91', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/d2c0637fd1d8b817667841cf6f9397bc266dde91', 'title': 'Contextual Information for Named Entity Recognition in Biomedical Texts', 'abstract': 'This article presents a study on Named Entities (NE) recognition using contextual information present on a Biomedical corpus. Related work indicates that the use of context (words surrounding a word) can assist the NE recognition. This work presents experimental results to evaluate the impact of different context settings, using machine learning, for the NE recognition.', 'externalIds': {'MAG': 2536250605.0, 'DOI': '10.1109/STIL.2009.28', 'CorpusId': 43656078.0}, 'label': 1}\n",
      "{'paperId': '752ab47c4ea6f076450b90cb5ad588c38557e79e', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/752ab47c4ea6f076450b90cb5ad588c38557e79e', 'title': 'Classification methods for finding articles describing protein-protein interactions in PubMed', 'abstract': 'Summary With the rapid expansion in the number of published papers in the biomedical field, finding relevant articles has become a demanding task for researchers. This has led to increasing interest in the use of text mining tools that help search the literature and identify the most relevant documents or information. One specific topic of interest is related to the identification of articles that might be used for extracting protein-protein interactions. Using the BioCreative III Article Classification Task dataset, composed of PubMed abstracts classified as relevant or non-relevant for describing protein-protein interactions, we compare different classification methods with different sets of features. The best results - area under the interpolated precision-recall curve of 0.654 - indicate that the proposed classification strategy could be incorporated in the database curation workflows in order to prioritize articles for extraction of protein-protein interactions. Furthermore, we also analysed the use of this method for ranking documents resulting from general PubMed queries, and propose that this approach could be useful for general researchers looking for publications describing protein-protein interactions within a particular topic of interest.', 'externalIds': {'MAG': 2188311884.0, 'DBLP': 'journals/jib/MatosO11', 'DOI': '10.1515/jib-2011-178', 'CorpusId': 17203205.0, 'PubMed': 21926441.0}, 'label': 1}\n",
      "{'paperId': 'fba6329fc9b1da747892efae8b89f4ef6d69fe21', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/fba6329fc9b1da747892efae8b89f4ef6d69fe21', 'title': 'Mining literature and pathway data to explore the relations of ketamine with neurotransmitters and gut microbiota using a knowledge-graph', 'abstract': 'Abstract Motivation Up-to-date pathway knowledge is usually presented in scientific publications for human reading, making it difficult to utilize these resources for semantic integration and computational analysis of biological pathways. We here present an approach to mining knowledge graphs by combining manual curation with automated named entity recognition and automated relation extraction. This approach allows us to study pathway-related questions in detail, which we here show using the ketamine pathway, aiming to help improve understanding of the role of gut microbiota in the antidepressant effects of ketamine. Results The thus devised ketamine pathway ‘KetPath’ knowledge graph comprises five parts: (i) manually curated pathway facts from images; (ii) recognized named entities in biomedical texts; (iii) identified relations between named entities; (iv) our previously constructed microbiota and pre-/probiotics knowledge bases; and (v) multiple community-accepted public databases. We first assessed the performance of automated extraction of relations between named entities using the specially designed state-of-the-art tool BioKetBERT. The query results show that we can retrieve drug actions, pathway relations, co-occurring entities, and their relations. These results uncover several biological findings, such as various gut microbes leading to increased expression of BDNF, which may contribute to the sustained antidepressant effects of ketamine. We envision that the methods and findings from this research will aid researchers who wish to integrate and query data and knowledge from multiple biomedical databases and literature simultaneously. Availability and implementation Data and query protocols are available in the KetPath repository at https://dx.doi.org/10.5281/zenodo.8398941 and https://github.com/tingcosmos/KetPath.', 'externalIds': {'DBLP': 'journals/bioinformatics/LiuFHH24', 'PubMedCentral': 10769815.0, 'DOI': '10.1093/bioinformatics/btad771', 'CorpusId': 266550583.0, 'PubMed': 38147362.0}, 'label': 1}\n",
      "{'paperId': 'b327adc539cd3fedf4e4f6be6ef026f5706a0552', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/b327adc539cd3fedf4e4f6be6ef026f5706a0552', 'title': 'BTM Topic Modeling Approach to Named Entity Linking', 'abstract': 'Named entity link is the process of linking a given named entity in a document to an unambiguous entity in a knowledge base, including the merging of synonymous entities, disambiguation of ambiguous entities, etc. Firstly, the paper construct the named entity knowledge base by using the offline version of Wikipedia. We improve the MPM co word measure which only considers the co-occurrence frequency without considering the frequency of individual words so that it can calculate word co-occurrence coefficient. Secondly, we propose a method named entity BTM link based on topic model. Finally, the named entity in the given text is linked to an ambiguous named entity in the knowledge base.', 'externalIds': {'MAG': 2554210178.0, 'DOI': '10.1088/1742-6596/1060/1/012027', 'CorpusId': 62933235.0}, 'label': 0}\n",
      "{'paperId': 'b730154e78cc65592aa641c3c133234fb73b73df', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/b730154e78cc65592aa641c3c133234fb73b73df', 'title': 'Empirical data on corpus design and usage in biomedical natural language processing', 'abstract': 'This paper describes the design of six publicly available biomedical corpora. We then present usage data for the six corpora. We show that corpora that are carefully annotated with respect to structural and linguistic characteristics and that are distributed in standard formats are more widely used than corpora that are not. These findings have implications for the design of the next generation of biomedical corpora.', 'externalIds': {'MAG': 1817582244.0, 'DBLP': 'conf/amia/CohenOFH05', 'CorpusId': 6566405.0, 'PubMed': 16779021.0}, 'label': 1}\n",
      "{'paperId': '67586632933d383bdd463321cd1dcc02dafdf04c', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/67586632933d383bdd463321cd1dcc02dafdf04c', 'title': 'Formative Evaluation of Ontology Learning Methods for Entity Discovery by Using Existing Ontologies as Reference Standards', 'abstract': 'Summary Objective: Developing a two-step method for formative evaluation of statistical Ontology Learning (OL) algorithms that leverages existing biomedical ontologies as reference standards. Methods: In the first step optimum parameters are established. A ‘gap list’ of entities is generated by finding the set of entities present in a later version of the ontology that are not present in an earlier version of the ontology. A named entity recognition system is used to identify entities in a corpus of biomedical documents that are present in the ‘gap list’, generating a reference standard. The output of the algorithm (new entity candidates), produced by statistical methods, is subsequently compared against this reference standard. An OL method that performs perfectly will be able to learn all of the terms in this reference stand ard. Using evaluation metrics and precision-recall curves for different thresholds and parameters, we compute the optimum parameters for each method. In the second step, human judges with exper tise in ontology development evaluate each candidate suggested by the algorithm con figured with the optimum parameters previously established. These judgments are used to compute two performance metrics developed from our previous work: Entity Suggestion Rate (ESR) and Entity Acceptance Rate (EAR). Results: Using this method, we evaluated two statistical OL methods for OL in two medical domains. For the pathology domain, we obtained 49% ESR, 28% EAR with the Lin method and 52% ESR, 39% EAR with the Church method. For the radiology domain, we obtain 87% ESA, 9% EAR using Lin method and 96% ESR, 16% EAR using Church method. Conclusion: This method is sufficiently general and flexible enough to permit comparison of any OL method for a specific corpus and ontology of interest.', 'externalIds': {'MAG': 2011628373.0, 'DOI': '10.3414/ME12-01-0029', 'CorpusId': 1444076.0, 'PubMed': 23666409.0}, 'label': 0}\n",
      "{'paperId': 'd680b29d34bd1c08d874d9c2eab43931b7602669', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/d680b29d34bd1c08d874d9c2eab43931b7602669', 'title': 'Mapping Dependencies Trees: An Application to Question Answering', 'abstract': 'We describe an approach for answer selection in a free form question answering task. In order to go beyond the key-word based matching in selecting answers to questions, one would like to incorporate both syntactic and semantic information in the question answering process. We achieve this goal by representing both questions and candidate passages using dependency trees, and incorporating semantic information such as named entities in this representation. The sentence that best answers a question is determined to be the one that minimizes the generalized edit distance between it and the question tree, computed via an approximate tree matching algorithm. We evaluate the approach on question-answer pairs taken from previous TREC Q/A competitions. Preliminary experiments show its potential by significantly outperforming common bag-of-word scoring methods.', 'externalIds': {'MAG': 62188290.0, 'CorpusId': 8214465.0}, 'label': 0}\n",
      "{'paperId': 'f9e459f3db616c0c5596c86c52c8d5d4cacdad87', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/f9e459f3db616c0c5596c86c52c8d5d4cacdad87', 'title': 'Deep Learning Approaches Substantially Improve Automated Extraction of Information from Free-Text Medical Reports.', 'abstract': 'Pathology reports store crucial information about clinicians’ observations and interpretations of tissue samples, as well as diagnoses. These reports usually summarize results of follow-up pathologic examinations conducted in response to abnormal radiologic imaging findings. Rapid and automatic extraction of information from these reports would greatly improve diagnostic workflow and provide clinical decision support. However, similar to radiology reports, medical findings in pathology reports are often captured in free-text format. As a result, it is challenging to effectively extract information from these reports because of a wide range of imaging observations and variations in natural language descriptions (1). In this issue of Radiology: Artificial Intelligence, Steinkamp and colleagues addressed this challenge and applied machine learning models to classify pathology reports into four major classes of organ systems to facilitate radiology follow-up recommendations (2). They demonstrated that state-of-the-art neural network–based approaches (F1 score, approximately 96%) consistently outperformed conventional machine learning algorithms (best F1 score, approximately 94% from extreme gradient boosting, or XGBoost) on this classification task. Moreover, they provided interpretations of the internal representations used by the neural network–based algorithms, elucidating important features the classifiers have learned. The computational approaches for automatic text classification of pathology reports presented in this study are applicable to other clinical scenarios facing similar challenges, such as information extraction from radiology reports. With the recent availability of large amounts of training data and computational power, neural network–based algorithms, also referred to as deep learning, have achieved remarkable accuracy in natural language processing (NLP) applications, such as speech recognition and language translation, and in computer vision tasks, including image classification and object detection. Deep neural network–based methods have also shown promising results in biomedical applications. The two major classes of methods are recurrent neural network (RNN) and convolutional neural network (CNN). RNN algorithms are most applicable to classification tasks involving sequential data or temporal sequences. Pathology and radiology reports typically consist of sequences of words (also called tokens in NLP), and thus semantic representations can be naturally encoded using RNN. CNN, initially developed for computer vision tasks, has been successfully applied to biomedical images for automated cell segmentation on microscopic images (3), cancer metastasis detection on pathologic images (4), and lesion segmentation on radiologic images. More recently, CNN has also been shown to have remarkable performance in classifying text data. In the study by Steinkamp et al, both CNN and RNN were applied to the classification task of pathology reports at the organ level (2). In addition to CNN and RNN, Steinkamp et al also trained classifiers using three widely used conventional machine learning methods. They demonstrated that CNN (sensitivity, 95.1%; specificity, 97.5%; and F1 score, 96.3%) and RNN (sensitivity, 94.3%; specificity, 99.1%; and F1 score, 96.7%) achieved better performance than random forest (sensitivity, 72.4%; specificity, 95.1%; and F1 score, 82.8%), XGBoost (sensitivity, 93.5%; specificity, 94.3%; and F1 score, 93.9%), and support vector machines (sensitivity, 82.9%; specificity, 98.0%; and F1 score, 89.9%) in classifying pathology reports to relevant organ classes (2). Another study by Chen et al applied deep learning to classify radiology free-text reports for extracting pulmonary embolism findings and showed that a CNNbased approach yielded better classification results than traditional NLP approaches (5). Qiu et al also confirmed superior performance of CNN to conventional methods in extracting International Classification of Diseases code from a large set of breast and lung cancer pathology reports (6). Traditional machine learning methods require additional feature engineering and extraction, which often', 'externalIds': {'MAG': 2966717178.0, 'DOI': '10.1148/RYAI.2019190118', 'CorpusId': 201128025.0, 'PubMed': 33939786.0}, 'label': 1}\n",
      "{'paperId': '8a5f99a37c409aafc0fcec61c93ded03d9b91810', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/8a5f99a37c409aafc0fcec61c93ded03d9b91810', 'title': 'Integrating semantic web and unstructured information processing environments : a visual rule-based approach', 'abstract': \"Les informations non-structurees referent principalement au texte, mais aussi a toutes les informations stockees sans une structure de donnees predefinie. Des progres significatifs ont ete realises dans le Traitement automatique du langage naturel (TALN), avec des annotations syntaxique et toponymique tres fiables utilisant l’etiquetage morpho-syntaxique (Part of Speech (POS) tagging), la segmentation des phrases (Noun Phrase (NP) chunking), et la reconnaissance d'entites nommees (Named-Entity Recognition, NER).\", 'externalIds': {'MAG': 2887111668.0, 'CorpusId': 171651035.0}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' ', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': \"Cependant, l'annotation semantique reste une tâche difficile, dont la precision et le rappel varient considerablement selon les types de documents et domaines d'application. Tandis que les textes simples tels que des messages electroniques dans un seul domaine peuvent etre analyses avec des resultats coherents, des documents professionnels et scientifiques de taille similaire, comme les nouvelles et les resumes, presentent trop de complexite avec divers vocabulaires et significations ambigues a travers des phrases et des sections du document. Les principales difficultes restent la relation des concepts entre eux sous forme de graphiques d'annotation, et leur combinaison pour un classement dans une hierarchie de classes semantiquement valide et exhaustive.\", 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' ', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': \"Dans cette these, nous demontrons comment utiliser les technologies du web semantique, en particulier les ontologies et bases de donnees de graphes, pour aider a ameliorer la qualite (F-score) de ces tâches d'annotation et de classification. Nous integrons une ontologie formelle avec une plate-forme de TALN standard, la testons sur un corpus de la recherche publique, et rapportons des F-scores superieurs aux algorithmes d'apprentissage machine anterieurs.\", 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' ', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': \"Nous developpons et testons une plate-forme innovante, soit une Architecture adaptative a base de regles pour l’extraction de connaissances (Adaptive Rules-Driven Architecture for Knowledge Extraction, ARDAKE). Notre logiciel integre la norme Architecture de gestion de l’information non-structuree (Unstructured Information Management Architecture, UIMA) avec une base de donnees graphique standard pour stocker nos ontologies. Nous developpons des extensions au langage de regles UIMA Ruta pour invoquer et verifier les rapports entre classes de l'ontologie. D’autres extensions comprennent le calcul de mesures complementaire utiles pour integrer les regles de correspondance (matching) entre mots et classes, soient conditionnelles, statistiques, et basees sur les distances semantiques. Nous developpons egalement un nouvel algorithme iteratif des n-grammes afin de combiner les regles de correspondance et d’optimiser les F-scores et l’aire sous les courbes de Caracteristique de fonctionnement du recepteur (Receiver Operating Characteristic, ROC). Nous proposons un nouveau style graphique circulaire (pie-chart) pour faciliter la visualisation de l'evaluation de la performance d'annotation. Ces composants sont integres dans une interface graphique permettant aux experts du domaine de regles de composer visuellement des ensembles de regles, dans des hierarchies de complexite variable, de scorer et comparer leur performance relative, et enfin les ameliorer en integrant des sources d'ontologies supplementaires.\", 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' ', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': \"Notre plate-forme est testee sur un cas d'utilisation particulier dans les sciences de la sante : une methode d'analyse de la litterature medicale selon la population, l’intervention, le controle, et les resultats (Population, Intervention, Control, and Outcome, PICO). Nous montrons que notre plate-forme peut efficacement et automatiquement produire des ensembles de regles parcimonieux, avec des F-scores plus eleves sur les classes P et I que les auteurs anterieurs utilisant des algorithmes d'apprentissage machine.\", 'externalIds': {}, 'label': 0}\n",
      "{'paperId': 'b4957f217df645d78ec37849c9bfb24ed56741c8', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/b4957f217df645d78ec37849c9bfb24ed56741c8', 'title': 'Gene Set to Diseases (GS2D): disease enrichment analysis on human gene sets with literature data', 'abstract': 'Large sets of candidate genes derived from high-throughput biological experiments can be characterized by functional enrichment analysis. The analysis consists of comparing the functions of one gene set against that of a background gene set. Then, functions related to a significant number of genes in the gene set are expected to be relevant. Web tools offering disease enrichment analysis on gene sets are often based on gene-disease associations from manually curated or experimental data that is accurate but does not cover all diseases discussed in the literature. Using associations automatically derived from literature data could be a cost effective method to improve the coverage of diseases for enrichment analysis at comparable levels of accuracy.', 'externalIds': {'MAG': 2560819412.0, 'DOI': '10.18547/GCB.2016.VOL2.ISS1.E33', 'CorpusId': 56356064.0}, 'label': 1}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'We have implemented a method named Gene set to Diseases, GS2D, as a web tool performing disease enrichment analysis on human protein coding gene sets. It uses an automatically built dataset of more than 63 thousand gene-disease associations defined as statistically significant co-occurrences of genes and diseases in annotations of biomedical citations from PubMed. The dataset covers more diseases for enrichment analysis than the largest comparable curated database (Comparative Toxicogenomics Database) and its performance compared favourably to similar approaches based on manually curated or experimental data. Graphical and programmatic interfaces are available at http://cbdm.uni-mainz.de/geneset2diseases.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': 'ad9b4fe0727e1378a8c92ae08fae96a373fc3fdb', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/ad9b4fe0727e1378a8c92ae08fae96a373fc3fdb', 'title': 'Generalizing biomedical relation classification with neural adversarial domain adaptation', 'abstract': 'Motivation', 'externalIds': {'MAG': 2792864647.0, 'DBLP': 'journals/bioinformatics/RiosKL18', 'DOI': '10.1093/bioinformatics/bty190', 'CorpusId': 4456371.0, 'PubMed': 29590309.0}, 'label': 1}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Creating large datasets for biomedical relation classification can be prohibitively expensive. While some datasets have been curated to extract protein-protein and drug-drug interactions (PPIs and DDIs) from text, we are also interested in other interactions including gene-disease and chemical-protein connections. Also, many biomedical researchers have begun to explore ternary relationships. Even when annotated data are available, many datasets used for relation classification are inherently biased. For example, issues such as sample selection bias typically prevent models from generalizing in the wild. To address the problem of cross-corpora generalization, we present a novel adversarial learning algorithm for unsupervised domain adaptation tasks where no labeled data are available in the target domain. Instead, our method takes advantage of unlabeled data to improve biased classifiers through learning domain-invariant features via an adversarial process. Finally, our method is built upon recent advances in neural network (NN) methods.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Results', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'We experiment by extracting PPIs and DDIs from text. In our experiments, we show domain invariant features can be learned in NNs such that classifiers trained for one interaction type (protein-protein) can be re-purposed to others (drug-drug). We also show that our method can adapt to different source and target pairs of PPI datasets. Compared to prior convolutional and recurrent NN-based relation classification methods without domain adaptation, we achieve improvements as high as 30% in F1-score. Likewise, we show improvements over state-of-the-art adversarial methods.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Availability and implementation', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Experimental code is available at https://github.com/bionlproc/adversarial-relation-classification.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Supplementary information', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Supplementary data are available at Bioinformatics online.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': 'fc21cec91adca852a9390c021f8afeb8bc8a44ec', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/fc21cec91adca852a9390c021f8afeb8bc8a44ec', 'title': 'Mining answers for causal questions in a medical example', 'abstract': 'The aim of this paper is to approach causal questions in a medical domain. Causal questions par excellence are what, how and why-questions. The ‘pyramid of questions’ shows this. At the top, why-questions are the prototype of causal questions. Usually why-questions are related to scientific explanations. Although cover law explanation is characteristically of physical sciences, it is less common in biological or medical knowledge. In medicine, laws applied to all cases are rare. It seems that doctors express their knowledge using mechanisms instead of natural laws. In this paper we will approach causal questions with the aim of: (1) answering what-questions as identifying the cause of an effect; (2) answering how-questions as selecting an appropriate part of a mechanism that relates pairs of cause-effect (3) answering why-questions as identifying ultimate causes in the answers of how-questions. In this task, we hypothesize that why-questions are related to scientific explanations in a negative and a positive note: (i) as previously said, scientific explanations in biology are based on mechanisms instead of natural laws; (ii) scientific explanations are generally concerned with deepening, providing explanations as detailed as possible. Thus, we conjecture that answers to why-questions have to find the ultimate causes in a mechanism and link them to the prior cause summarizing the intermediate nodes in order to provide a comprehensible answer. The Mackie´s INUS causality offers a theoretical support for this solution.', 'externalIds': {'MAG': 2086916703.0, 'DBLP': 'conf/isda/SobrinoOP11', 'DOI': '10.1109/ISDA.2011.6121694', 'CorpusId': 8947956.0}, 'label': 1}\n",
      "{'paperId': '02f3c97ada83664938d2026f110c4a17c7e4db16', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/02f3c97ada83664938d2026f110c4a17c7e4db16', 'title': 'Relation Classification in Scientific Article Abstracts using SciBERT with Entity Marker', 'abstract': 'In recent years, relation classification has become one of the important stages in relation extraction for the construction of a knowledge graph. Relation classification is used to classify the relation of each entity in a text or paragraph. In one paragraph, there will be many entities, so it requires accurate information about the position of entities in the text. To solve this problem, we used entity markers and compared the results with the standard entity. This research proposes two pretrained BERT models, BERT-Base and SciBERT-Scivocab. SciBERT is a BERT model that has been specially trained on scientific datasets, while BERT-Base is trained on general datasets. We tested both models with the SciERC dataset, which is a collection of biomedical and computer science article abstracts. The results of relation classification are annotated in the form of F2-score which in this case is more concerned with recall than precision. The F2 score on the BERT-Base model is 82.33% and the SciBERT-Scivocab model is 83.75% using standard entities, while the F2 score using entity markers on the BERT-Base model is 82.30% and the SciBERT-Scivocab model is 84.18%.', 'externalIds': {'DOI': '10.1109/CITSM60085.2023.10455639', 'CorpusId': 268277453.0}, 'label': 1}\n",
      "{'paperId': '9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/9e89e07ad1b5c8b47d6543dbf3795601a48b6fd0', 'title': 'Answering Clinical Questions with Knowledge-Based and Statistical Techniques', 'abstract': \"The combination of recent developments in question-answering research and the availability of unparalleled resources developed specifically for automatic semantic processing of text in the medical domain provides a unique opportunity to explore complex question answering in the domain of clinical medicine. This article presents a system designed to satisfy the information needs of physicians practicing evidence-based medicine. We have developed a series of knowledge extractors, which employ a combination of knowledge-based and statistical techniques, for automatically identifying clinically relevant aspects of MEDLINE abstracts. These extracted elements serve as the input to an algorithm that scores the relevance of citations with respect to structured representations of information needs, in accordance with the principles of evidence-based medicine. Starting with an initial list of citations retrieved by PubMed, our system can bring relevant abstracts into higher ranking positions, and from these abstracts generate responses that directly answer physicians' questions. We describe three separate evaluations: one focused on the accuracy of the knowledge extractors, one conceptualized as a document reranking task, and finally, an evaluation of answers by two physicians. Experiments on a collection of real-world clinical questions show that our approach significantly outperforms the already competitive PubMed baseline.\", 'externalIds': {'MAG': 2134568263.0, 'DBLP': 'journals/coling/Demner-FushmanL07', 'DOI': '10.1162/coli.2007.33.1.63', 'CorpusId': 339805.0, 'ACL': 'J07-1005'}, 'label': 1}\n",
      "{'paperId': 'e0d2c0627c19da645d6711361b747568488e71ef', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/e0d2c0627c19da645d6711361b747568488e71ef', 'title': 'Results of the sixth edition of the BioASQ Challenge', 'abstract': 'This paper presents the results of the sixth edition of the BioASQ challenge. The BioASQ challenge aims at the promotion of systems and methodologies through the organization of a challenge on two tasks: semantic indexing and question answering. In total, 26 teams with more than 90 systems participated in this year’s challenge. As in previous years, the best systems were able to outperform the strong baselines. This suggests that state-of-the-art systems are continuously improving, pushing the frontier of research.', 'externalIds': {'MAG': 2953868496.0, 'DOI': '10.18653/v1/W18-5301', 'CorpusId': 19347174.0, 'ACL': 'W18-5301'}, 'label': 1}\n",
      "{'paperId': 'dcc3d0e9f384bab5ea349d726994d0ef75a5f275', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/dcc3d0e9f384bab5ea349d726994d0ef75a5f275', 'title': 'A Cognitive Evaluation of Four Online Search Engines for Answering Definitional Questions Posed by Physicians', 'abstract': 'The Internet is having a profound impact on physicians\\' medical decision making. One recent survey of 277 physicians showed that 72% of physicians regularly used the Internet to research medical information and 51% admitted that information from web sites influenced their clinical decisions. This paper describes the first cognitive evaluation of four state-of-the-art Internet search engines: Google (i.e., Google and Scholar.Google), MedQA, Onelook, and PubMed for answering definitional questions (i.e., questions with the format of \"What is X?\") posed by physicians. Onelook is a portal for online definitions, and MedQA is a question answering system that automatically generates short texts to answer specific biomedical questions. Our evaluation criteria include quality of answer, ease of use, time spent, and number of actions taken. Our results show that MedQA outperforms Onelook and PubMed in most of the criteria, and that MedQA surpasses Google in time spent and number of actions, two important efficiency criteria. Our results show that Google is the best system for quality of answer and ease of use. We conclude that Google is an effective search engine for medical definitions, and that MedQA exceeds the other search engines in that it provides users direct answers to their questions; while the users of the other search engines have to visit several sites before finding all of the pertinent information.', 'externalIds': {'MAG': 2142541800.0, 'DBLP': 'conf/psb/YuK07', 'DOI': '10.1142/9789812772435_0031', 'CorpusId': 27315495.0, 'PubMed': 17990503.0}, 'label': 1}\n",
      "{'paperId': '058ff2dea5937d53f36d358baf72277d39e0fda7', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/058ff2dea5937d53f36d358baf72277d39e0fda7', 'title': 'Biological Entity Mapping Database Based on Web Service', 'abstract': 'Biological entity mapping is to implement the transformation of different identifiers or names of biological entities,such as genes,proteins,small molecules,chemicals or drugs.It could help biomedical researchers to relate their experimental results to relevant data within the mass online biomedical resources,as well as provide technical support for the researchers of biomedical text mining and information retrieval in terms of named entity recognition and query keyword extension.In this study,a biological entity mapping database was established,in which great amount information of biological entity mapping was stored.A web service based web application system of biological entity mapping was set up.The user could access the biological entity mapping database by both browser and web service.', 'externalIds': {'MAG': 2364090432.0, 'CorpusId': 62958505.0}, 'label': 1}\n",
      "{'paperId': 'f0e5bc313bc9ed83f6e0b1a77579d05dfb598010', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/f0e5bc313bc9ed83f6e0b1a77579d05dfb598010', 'title': 'Extractive Text Summarization Using Ontology and Graph-Based Method', 'abstract': 'In recent years, many people started to take care of the physical health. The biomedical article is the trendy issue at the moment leading to the huge amount of knowledge created rapidly. In this paper, we propose a new automatic extractive text summarization technique based on graph representation that makes use of the Unified Medical Language System (UMLS), an ontology knowledge from the National Library of Medicine (NLM). We combined the graph building rules with a distance function between text documents, called Word Mover’s Distance. To prioritize the core sentences, we extracted the summary by using a popular graph-based method from Google, PageRank. We compared our results with other text summarization software using 400 biological review papers as a corpus randomly sampled from PubMed Central. Our approach outperformed the baseline comparators in terms of Recall-Oriented Understudy for Gisting Evaluation (ROUGE) scores.', 'externalIds': {'MAG': 2971670955.0, 'DBLP': 'conf/ccoms/YongkiatpanichW19', 'DOI': '10.1109/CCOMS.2019.8821755', 'CorpusId': 201833414.0}, 'label': 1}\n",
      "{'paperId': '0cf18cdb2ae5e820e30fb4fc071a3229ed625b3c', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/0cf18cdb2ae5e820e30fb4fc071a3229ed625b3c', 'title': 'Relation Extraction From Biomedical and Clinical Text: Unified Multitask Learning Framework', 'abstract': 'Motivation: To minimize the accelerating amount of time invested on the biomedical literature search, numerous approaches for automated knowledge extraction have been proposed. Relation extraction is one such task where semantic relations between the entities are identified from the free text. In the biomedical domain, extraction of regulatory pathways, metabolic processes, adverse drug reaction or disease models necessitates knowledge from the individual relations, for example, physical or regulatory interactions between genes, proteins, drugs, chemical, disease or phenotype. Results: In this paper, we study the relation extraction task from three major biomedical and clinical tasks, namely drug-drug interaction, protein-protein interaction, and medical concept relation extraction. Towards this, we model the relation extraction problem in a multi-task learning (MTL)framework, and introduce for the first time the concept of structured self-attentive network complemented with the adversarial learning approach for the prediction of relationships from the biomedical and clinical text. The fundamental notion of MTL is to simultaneously learn multiple problems together by utilizing the concepts of the shared representation. Additionally, we also generate the highly efficient single task model which exploits the shortest dependency path embedding learned over the attentive gated recurrent unit to compare our proposed MTL models. The framework we propose significantly improves over all the baselines (deep learning techniques)and single-task models for predicting the relationships, without compromising on the performance of all the tasks.', 'externalIds': {'MAG': 3087169961.0, 'DBLP': 'journals/tcbb/YadavJSE22', 'DOI': '10.1109/TCBB.2020.3020016', 'CorpusId': 221359333.0, 'PubMed': 32853152.0, 'ArXiv': 2009.09509}, 'label': 1}\n",
      "{'paperId': '3899f87a2031f3434f89beb68c11a1ca6428328a', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/3899f87a2031f3434f89beb68c11a1ca6428328a', 'title': 'End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures', 'abstract': 'We present a novel end-to-end neural model to extract entities and relations between them. Our recurrent neural network based model captures both word sequence and dependency tree substructure information by stacking bidirectional tree-structured LSTM-RNNs on bidirectional sequential LSTM-RNNs. This allows our model to jointly represent both entities and relations with shared parameters in a single model. We further encourage detection of entities during training and use of entity information in relation extraction via entity pretraining and scheduled sampling. Our model improves over the state-of-the-art feature-based model on end-to-end relation extraction, achieving 12.1% and 5.7% relative error reductions in F1-score on ACE2005 and ACE2004, respectively. We also show that our LSTM-RNN based model compares favorably to the state-of-the-art CNN based model (in F1-score) on nominal relation classification (SemEval-2010 Task 8). Finally, we present an extensive ablation analysis of several model components.', 'externalIds': {'MAG': 2229639163.0, 'DBLP': 'conf/acl/MiwaB16', 'DOI': '10.18653/v1/P16-1105', 'CorpusId': 2476229.0, 'ACL': 'P16-1105', 'ArXiv': 1601.0077}, 'label': 0}\n",
      "{'paperId': 'fa492f1ced3d953140f2852376d94ef92cdc62e0', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/fa492f1ced3d953140f2852376d94ef92cdc62e0', 'title': 'Investigating of Disease Name Normalization Using Neural Network and Pre-Training', 'abstract': 'Normalizing disease names is a crucial task for biomedical and healthcare domains. Previous work explored various approaches, including rules, machine learning and deep learning, which focused on only one approach or one model. In this study, we systematically investigated the performances of various neural models and the effects of different features. Our investigation was performed on two benchmark datasets, namely the NCBI disease corpus and the BioCreative V Chemical Disease Relation (BC5CDR) corpus. The convolutional neural network (CNN) performed the best (F1 90.11%) in the NCBI disease corpus and the attention neural network (Attention) performed the best (F1 90.78%) in the BC5CDR corpus. Compared with the state-of-the-art system, DNorm, our models improved the F1s by 1.74% and 0.86% respectively. In terms of features, character information could improve the F1 by about 0.5-1.0% while sentence information worsened the F1 by about 3–4%. Moreover, we proposed a novel approach for pre-training models, which improved the F1 by up to 9%. The CNN and Attention models are comparable in the task of disease name normalization while the recurrent neural network performs much worse. In addition, character information and pre-training techniques are helpful for this task while sentence information hurts the performance. Our proposed models and pre-training approach can be easily adapted to the normalization task for any other type of entities. Our source code is available at: https://github.com/yx100/EntityNorm.', 'externalIds': {'MAG': 3021989992.0, 'DBLP': 'journals/access/LouQLZJC20', 'DOI': '10.1109/ACCESS.2020.2992130', 'CorpusId': 218676575.0}, 'label': 1}\n",
      "{'paperId': '123344ebf78dc67ed92320631220baf0318deb44', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/123344ebf78dc67ed92320631220baf0318deb44', 'title': 'ALIBABA: PubMed as a graph', 'abstract': 'UNLABELLED', 'externalIds': {'MAG': 2120736575.0, 'DBLP': 'journals/bioinformatics/PlakeSPHL06', 'DOI': '10.1093/bioinformatics/btl408', 'CorpusId': 263884177.0, 'PubMed': 16870931.0}, 'label': 1}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': \"The biomedical literature contains a wealth of information on associations between many different types of objects, such as protein-protein interactions, gene-disease associations and subcellular locations of proteins. When searching such information using conventional search engines, e.g. PubMed, users see the data only one-abstract at a time and 'hidden' in natural language text. AliBaba is an interactive tool for graphical summarization of search results. It parses the set of abstracts that fit a PubMed query and presents extracted information on biomedical objects and their relationships as a graphical network. AliBaba extracts associations between cells, diseases, drugs, proteins, species and tissues. Several filter options allow for a more focused search. Thus, researchers can grasp complex networks described in various articles at a glance.\", 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'AVAILABILITY', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'http://alibaba.informatik.hu-berlin.de/', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': 'ca7af57626ae037275e5c336c44f91388f49ca1c', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/ca7af57626ae037275e5c336c44f91388f49ca1c', 'title': 'Contextual Semantic-Guided Entity-Centric GCN for Relation Extraction', 'abstract': 'Relation extraction tasks aim to predict potential relations between entities in a target sentence. As entity mentions have ambiguity in sentences, some important contextual information can guide the semantic representation of entity mentions to improve the accuracy of relation extraction. However, most existing relation extraction models ignore the semantic guidance of contextual information to entity mentions and treat entity mentions in and the textual context of a sentence equally. This results in low-accuracy relation extractions. To address this problem, we propose a contextual semantic-guided entity-centric graph convolutional network (CEGCN) model that enables entity mentions to obtain semantic-guided contextual information for more accurate relational representations. This model develops a self-attention enhanced neural network to concentrate on the importance and relevance of different words to obtain semantic-guided contextual information. Then, we employ a dependency tree with entities as global nodes and add virtual edges to construct an entity-centric logical adjacency matrix (ELAM). This matrix can enable entities to aggregate the semantic-guided contextual information with a one-layer GCN calculation. The experimental results on the TACRED and SemEval-2010 Task 8 datasets show that our model can efficiently use semantic-guided contextual information to enrich semantic entity representations and outperform previous models.', 'externalIds': {'DOI': '10.3390/math10081344', 'CorpusId': 248283511.0}, 'label': 0}\n",
      "{'paperId': 'a28975648ab904347e012f6c05ef4200c645a445', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/a28975648ab904347e012f6c05ef4200c645a445', 'title': 'Annotating Genes Using Textual Patterns', 'abstract': 'Annotating genes with Gene Ontology (GO) terms is crucial for biologists to characterize the traits of genes in a standardized way. However, manual curation of textual data, the most reliable form of gene annotation by GO terms, requires significant amounts of human effort, is very costly, and cannot catch up with the rate of increase in biomedical publications. In this paper, we present GEANN, a system to automatically infer new GO annotations for genes from biomedical papers based on the evidence support linked to PubMed, a biological literature database of 14 million papers. GEANN (i) extracts from text significant terms and phrases associated with a GO term, (ii) based on the extracted terms, constructs textual extraction patterns with reliability scores for GO terms, (iii) expands the pattern set through \"pattern crosswalks\", (iv) employs semantic pattern matching, rather than syntactic pattern matching, which allows for the recognition of phrases with close meanings, and (iv) annotates genes based on the \"quality\" of the matched pattern to the genomic entity occurring in the text. On the average, in our experiments, GEANN has reached to the precision level of 78% at the 57% recall level.', 'externalIds': {'MAG': 2121777858.0, 'DBLP': 'conf/psb/CakmakO07', 'DOI': '10.1142/9789812772435_0022', 'CorpusId': 7655196.0, 'PubMed': 17990494.0}, 'label': 1}\n",
      "{'paperId': 'b50928ef0c878415d530a1ff19e5d7d83e330b21', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/b50928ef0c878415d530a1ff19e5d7d83e330b21', 'title': 'NERChem: adapting NERBio to chemical patents via full-token features and named entity feature with chemical sub-class composition', 'abstract': 'Chemical patents contain detailed information on novel chemical compounds that is valuable to the chemical and pharmaceutical industries. In this paper, we introduce a system, NERChem that can recognize chemical named entity mentions in chemical patents. NERChem is based on the conditional random fields model (CRF). Our approach incorporates (1) class composition, which is used for combining chemical classes whose naming conventions are similar; (2) BioNE features, which are used for distinguishing chemical mentions from other biomedical NE mentions in the patents; and (3) full-token word features, which are used to resolve the tokenization granularity problem. We evaluated our approach on the BioCreative V CHEMDNER-patent corpus, and achieved an F-score of 87.17% in the Chemical Entity Mention in Patents (CEMP) task and a sensitivity of 98.58% in the Chemical Passage Detection (CPD) task, ranking alongside the top systems. Database URL: Our NERChem web-based system is publicly available at iisrserv.csie.n cu.edu.tw/nerchem.', 'externalIds': {'MAG': 2542020674.0, 'DBLP': 'journals/biodb/TsaiHL16', 'PubMedCentral': 5091336.0, 'DOI': '10.1093/database/baw135', 'CorpusId': 17845993.0, 'PubMed': 31414701.0}, 'label': 1}\n",
      "{'paperId': '833b8d634236d64055f7ceea03fbfc2d3c41e7f1', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/833b8d634236d64055f7ceea03fbfc2d3c41e7f1', 'title': 'NCU1415 at ROCLING 2022 Shared Task: A light-weight transformer-based approach for Biomedical Name Entity Recognition', 'abstract': 'Name Entity Recognition (NER) is a very important and basic task in traditional NLP tasks. In the biomedical field, NER tasks have been widely used in various products developed by various manufacturers. These include parsing, QA system, key information extraction or replacement in dialogue systems, and the practical application of knowledge parsing. In different fields, including bio-medicine, communication technology, e-commerce etc., NER technology is needed to identify drugs, diseases, commodities and other objects. This implementation focuses on the CLING 2022 SHARED TASK’s(Lee et al. 2022) NER TASK in biomedical field, with a bit of tuning and experimentation based on the language models.', 'externalIds': {'DBLP': 'conf/rocling/FengCW22', 'CorpusId': 253628206.0, 'ACL': '2022.rocling-1.39'}, 'label': 1}\n",
      "{'paperId': 'ff17100b49e233f38180ad4b978ad35833778692', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/ff17100b49e233f38180ad4b978ad35833778692', 'title': 'Improving Distantly Supervised Relation Extraction using Word and Entity Based Attention', 'abstract': 'Relation extraction is the problem of classifying the relationship between two entities in a given sentence. Distant Supervision (DS) is a popular technique for developing relation extractors starting with limited supervision. We note that most of the sentences in the distant supervision relation extraction setting are very long and may benefit from word attention for better sentence representation. Our contributions in this paper are threefold. Firstly, we propose two novel word attention models for distantly- supervised relation extraction: (1) a Bi-directional Gated Recurrent Unit (Bi-GRU) based word attention model (BGWA), (2) an entity-centric attention model (EA), and (3) a combination model which combines multiple complementary models using weighted voting method for improved relation extraction. Secondly, we introduce GDS, a new distant supervision dataset for relation extraction. GDS removes test data noise present in all previous distant- supervision benchmark datasets, making credible automatic evaluation possible. Thirdly, through extensive experiments on multiple real-world datasets, we demonstrate the effectiveness of the proposed methods.', 'externalIds': {'MAG': 2796801810.0, 'DBLP': 'journals/corr/abs-1804-06987', 'CorpusId': 5000539.0, 'ArXiv': 1804.06987}, 'label': 0}\n",
      "{'paperId': '175dcaf0e3a8a6c702e13f1d1d656ff31484b66a', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/175dcaf0e3a8a6c702e13f1d1d656ff31484b66a', 'title': 'BioRED: a rich biomedical relation extraction dataset', 'abstract': 'Abstract Automated relation extraction (RE) from biomedical literature is critical for many downstream text mining applications in both research and real-world settings. However, most existing benchmarking datasets for biomedical RE only focus on relations of a single type (e.g. protein–protein interactions) at the sentence level, greatly limiting the development of RE systems in biomedicine. In this work, we first review commonly used named entity recognition (NER) and RE datasets. Then, we present a first-of-its-kind biomedical relation extraction dataset (BioRED) with multiple entity types (e.g. gene/protein, disease, chemical) and relation pairs (e.g. gene–disease; chemical–chemical) at the document level, on a set of 600 PubMed abstracts. Furthermore, we label each relation as describing either a novel finding or previously known background knowledge, enabling automated algorithms to differentiate between novel and background information. We assess the utility of BioRED by benchmarking several existing state-of-the-art methods, including Bidirectional Encoder Representations from Transformers (BERT)-based models, on the NER and RE tasks. Our results show that while existing approaches can reach high performance on the NER task (F-score of 89.3%), there is much room for improvement for the RE task, especially when extracting novel relations (F-score of 47.7%). Our experiments also demonstrate that such a rich dataset can successfully facilitate the development of more accurate, efficient and robust RE systems for biomedicine. Availability: The BioRED dataset and annotation guidelines are freely available at https://ftp.ncbi.nlm.nih.gov/pub/lu/BioRED/.', 'externalIds': {'DBLP': 'journals/bib/LuoLWAL22', 'PubMedCentral': 9487702.0, 'DOI': '10.1093/bib/bbac282', 'CorpusId': 249921231.0, 'PubMed': 35849818.0, 'ArXiv': 2204.04263}, 'label': 1}\n",
      "{'paperId': '0c40ed0c68d0c5d8647165a6f306057cbffca31c', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/0c40ed0c68d0c5d8647165a6f306057cbffca31c', 'title': 'Developing tools and resources for the biomedical domain of the Greek language', 'abstract': 'This paper presents the design and implementation of terminological and specialized textual resources that were produced in the framework of the Greek research project “IATROLEXI”. The aim of the project was to create the critical infrastructure for the Greek language, i.e. linguistic resources and tools for use in high level Natural Language Processing (NLP) applications in the domain of biomedicine. The project was built upon existing resources developed by the project partners and further enhanced within its framework, i.e. a Greek morphological lexicon of about 100,000 words, and language processing tools such as a lemmatiser and a morphosyntactic tagger. Christos Tsalidis, Additionally, it developed new assets, such as a specialized corpus of biomedical texts and an ontology of medical terminology.', 'externalIds': {'MAG': 2040790690.0, 'DBLP': 'journals/hij/VagelatosMPTK11', 'DOI': '10.1177/1460458211405007', 'CorpusId': 6423352.0, 'PubMed': 21712356.0}, 'label': 1}\n",
      "{'paperId': '6b90a18f4c49d753bec424a3b9241609493e5b64', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/6b90a18f4c49d753bec424a3b9241609493e5b64', 'title': 'An analysis on the entity annotations in biological corpora', 'abstract': 'Collection of documents annotated with semantic entities and relationships are crucial resources to support development and evaluation of text mining solutions for the biomedical domain. Here I present an overview of 36 corpora and show an analysis on the semantic annotations they contain. Annotations for entity types were classified into six semantic groups and an overview on the semantic entities which can be found in each corpus is shown. Results show that while some semantic entities, such as genes, proteins and chemicals are consistently annotated in many collections, corpora available for diseases, variations and mutations are still few, in spite of their importance in the biological domain.', 'externalIds': {'MAG': 2072725120.0, 'DBLP': 'journals/f1000research/Neves14', 'PubMedCentral': 4168744.0, 'DOI': '10.12688/f1000research.3216.1', 'CorpusId': 264785557.0, 'PubMed': 25254099.0}, 'label': 1}\n",
      "{'paperId': '497c717a864f63e2a73b582372aac2596e6d978c', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/497c717a864f63e2a73b582372aac2596e6d978c', 'title': 'Large Scale Application of Neural Network Based Semantic Role Labeling for Automated Relation Extraction from Biomedical Texts', 'abstract': 'To reduce the increasing amount of time spent on literature search in the life sciences, several methods for automated knowledge extraction have been developed. Co-occurrence based approaches can deal with large text corpora like MEDLINE in an acceptable time but are not able to extract any specific type of semantic relation. Semantic relation extraction methods based on syntax trees, on the other hand, are computationally expensive and the interpretation of the generated trees is difficult. Several natural language processing (NLP) approaches for the biomedical domain exist focusing specifically on the detection of a limited set of relation types. For systems biology, generic approaches for the detection of a multitude of relation types which in addition are able to process large text corpora are needed but the number of systems meeting both requirements is very limited. We introduce the use of SENNA (“Semantic Extraction using a Neural Network Architecture”), a fast and accurate neural network based Semantic Role Labeling (SRL) program, for the large scale extraction of semantic relations from the biomedical literature. A comparison of processing times of SENNA and other SRL systems or syntactical parsers used in the biomedical domain revealed that SENNA is the fastest Proposition Bank (PropBank) conforming SRL program currently available. 89 million biomedical sentences were tagged with SENNA on a 100 node cluster within three days. The accuracy of the presented relation extraction approach was evaluated on two test sets of annotated sentences resulting in precision/recall values of 0.71/0.43. We show that the accuracy as well as processing speed of the proposed semantic relation extraction approach is sufficient for its large scale application on biomedical text. The proposed approach is highly generalizable regarding the supported relation types and appears to be especially suited for general-purpose, broad-scale text mining systems. The presented approach bridges the gap between fast, cooccurrence-based approaches lacking semantic relations and highly specialized and computationally demanding NLP approaches.', 'externalIds': {'MAG': 2098408481.0, 'PubMedCentral': 2712690.0, 'DOI': '10.1371/journal.pone.0006393', 'CorpusId': 12101726.0, 'PubMed': 19636432.0}, 'label': 1}\n",
      "{'paperId': '12c3a8fdf04afee8b46a682bb9d9ed24bf68d9b3', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/12c3a8fdf04afee8b46a682bb9d9ed24bf68d9b3', 'title': 'Using a Question-Answering Approach in Machine Reading Task of Biomedical Texts about the Alzheimer Disease', 'abstract': 'For the machine-reading task of biomedical texts about the Alzheimer disease we have used a Question-Answering approach by adapting functionalities of Question-Answering (Q-A) engine EAGLi. We didn’t involve any other Natural Language Processing method. As a knowledge store we used the biggest resource of biomedical literature MEDLINE. Our final results showed that the best run was without using the filter of “stop words” in queries. Run 1 and Run 2 provided answers to all 40 Question, while Run 3 and 4 provided answers to 5 questions; Run 5 answered to 6 questions. These results can be tentatively explained by the limits of the Boolean search we chose in the Q-A engine.', 'externalIds': {'MAG': 1019611430.0, 'DBLP': 'conf/clef/VishnyakovaGR13', 'CorpusId': 18827264.0}, 'label': 1}\n",
      "{'paperId': '9c8aaa039d63e151fa89da82f16c5532e0a6dd26', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/9c8aaa039d63e151fa89da82f16c5532e0a6dd26', 'title': 'PrEVIEw: Clustering and Visualising PubMed using Visual Interface', 'abstract': '. The life sciences domain has been one of the early adopters of Open Data Initiative and a considerable portion of the Linked Open Data cloud is comprised of datasets from Life Sciences Linked Open Data (LSLOD). This deluge of biomedical data and active research over the past decade resulted in the ﬂux of scientiﬁc publications in this domain. PubMed resource provides access to MEDLINE, NLM’s database of citations and abstracts in the biomedical domain. PubMed Central provides links to full-text articles along with publisher web sites, and other related resources. In this paper we present PubMed Visual Interface (PrEVIEw)- a web based application to access information related to publication, research topic, author and institute through a visual interface. PrEVIEw not only provides useful information e.g. research topic of interest, research collaboration at personal or institute level etc, for the biomedical research community but also helpful for the working Data Scientist. We also evaluate the usability of our system by using the standard system usability scale as well as a custom questionnaire, particularly designed to test the usability of the interface. Our overall usability score of 83.69 suggests that web based interface is easy to learn, consistent, and adequate for frequent use.', 'externalIds': {'MAG': 2575442781.0, 'DBLP': 'conf/semweb/ZainabMZRH16', 'CorpusId': 12272925.0}, 'label': 0}\n",
      "{'paperId': 'd7020ce28b26767e12f414b3ebfd695be8a93422', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/d7020ce28b26767e12f414b3ebfd695be8a93422', 'title': 'Using Metacard: A Hypercard Browser for Biomedical Knowledge Sources*.', 'abstract': 'Abstract', 'externalIds': {'MAG': 1033481773.0, 'CorpusId': 60591014.0}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'As part of the Unified Medical Language System (UMLS) project, a large metathesaurus (Meta-1) was built. We have adapted a Hypercard browser of Meta-1 (MetaCard) to enable a user to continue the browsing process, extending from the Metathesaurus to a variety of different knowledge sources. These knowledge sources include Current Disease Descriptions (CDD), Physicians Data Query (PDQ), and Mendelian Inheritance in Man (MIM). Metacard can also be linked to Grateful Med, the NLM program which is used to search MEDLINE. A user can, with minimal training, use MetaCard to access these four different knowledge sources. The links (how one goes from one knowledge source to another) have been built on the basis of disease names. In organizing these links, it was helpful to use CDD as an additional source of knowledge about how diseases are named in various sources. Further plans are to expand the use of the Metathesaurus in building links to the knowledge sources. The question with each method of linking used will be to what extent the method provides a robust linkage whose utility can be anticipated. While future refinements or developments of links may give additional functionality, the current linkages are sufficient to provide a useful browsing tool. We believe that this is so because much of the knowledge in each of these sources is organized around diseases. Navigation is easy because of the similarities of the Hypercard interfaces to each of the knowledge sources; a common set of conventions (e.g., point and click) helps make it work.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': 'cee7e97af18b48c96a5d7178b8edbdb51f1da28d', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/cee7e97af18b48c96a5d7178b8edbdb51f1da28d', 'title': 'TCM-SAS: A Semantic Annotation System and Knowledgebase of Traditional Chinese Medicine', 'abstract': \"Objective: To construct a natural language processing (NLP) system focused on named entity recognition (NER) and semantic relation extraction (RE) of ancient Chinese medical books, it supports annotated corpora management and semantic knowledge retrieval. Methods: We integrate the 47 ontologies and terminologies as the terminology database. After that, we trained a preprocessing NER model using spaCy and used a hybrid approach combining automated annotation and manual review to annotate corpora of ancient Chinese medical books. Results: The semantic annotation system of Chinese ancient texts named traditional Chinese medicine - semantic annotation system (TCM-SAS), was constructed based on ontologies and terminologies. Annotations and knowledge retrieval of TCM's ancient texts were realized. Conclusion: TCM-SAS is a user-friendly semantic annotation system for ancient Chinese medical books that includes a large-scale manual annotation of TCM literature and semantic knowledge of TCM. TCM-SAS could provide users with two modes of automatic and manual NER and RE for ancient Chinese texts, as well as annotated entity and corpora management. Support the discovery of new knowledge from ancient Chinese medical texts in the future.\", 'externalIds': {'DBLP': 'conf/bibm/WangLYWZ22', 'DOI': '10.1109/BIBM55620.2022.9994940', 'CorpusId': 255418797.0}, 'label': 1}\n",
      "{'paperId': 'f566cea653aa57484c8aafbfb2e5d2e410a816fc', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/f566cea653aa57484c8aafbfb2e5d2e410a816fc', 'title': 'Open domain real-time question answering based on asynchronous multiperspective context-driven retrieval and neural paraphrasing', 'abstract': 'The live-QA task involves real user questions, extracted from the stream of most recent questions submitted to the Yahoo Answers (YA) site that has not yet been answered. There are two tracks in the live-QA task, general domain, and medical domain. In general domain, unanswered questions are taken from six categories of real-time yahoo question answering feed, and for the medical domain, they are taken from the consumer health questions asked in NLM forums. The answers given by the system for both general and medical tasks are evaluated by human experts looking into accuracy, readability, and preciseness. The features of our open-domain question answering include question decomposition, question focus iden-tiﬁcation, context identiﬁcation, answer retrieval and summarization. The current system builds an asynchronous sys-tem which has a multi-perspective view of the question being asked by decomposing the question into multiple smaller questions and identifying answers to sub-questions and summarizing the answers. Our system performed close to the median in the live-QA task and ranked second in the medical sub-task.', 'externalIds': {'MAG': 2886773635.0, 'DBLP': 'conf/trec/DatlaALAHLQLPF17', 'CorpusId': 3895143.0}, 'label': 0}\n",
      "{'paperId': 'd7104dab8e5379f9566108857e3bd9dc832286df', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/d7104dab8e5379f9566108857e3bd9dc832286df', 'title': 'Developing a general-purpose clinical language inference model from a large corpus of clinical notes', 'abstract': 'Several biomedical language models have already been developed for clinical language inference. However, these models typically utilize general vocabularies and are trained on relatively small clinical corpora. We sought to evaluate the impact of using a domain-specific vocabulary and a large clinical training corpus on the performance of these language models in clinical language inference. We trained a Bidirectional Encoder Decoder from Transformers (BERT) model using a diverse, deidentified corpus of 75 million deidentified clinical notes authored at the University of California, San Francisco (UCSF). We evaluated this model on several clinical language inference benchmark tasks: clinical and temporal concept recognition, relation extraction and medical language inference. We also evaluated our model on two tasks using discharge summaries from UCSF: diagnostic code assignment and therapeutic class inference. Our model performs at par with the best publicly available biomedical language models of comparable sizes on the public benchmark tasks, and is significantly better than these models in a within-system evaluation on the two tasks using UCSF data. The use of in-domain vocabulary appears to improve the encoding of longer documents. The use of large clinical corpora appears to enhance document encoding and inferential accuracy. However, further research is needed to improve abbreviation resolution, and numerical, temporal, and implicitly causal inference.', 'externalIds': {'DBLP': 'journals/corr/abs-2210-06566', 'DOI': '10.48550/arXiv.2210.06566', 'CorpusId': 252872970.0, 'ArXiv': 2210.06566}, 'label': 1}\n",
      "{'paperId': 'd14e52b23cf8fe070be00dd7a1284710f21c77c8', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/d14e52b23cf8fe070be00dd7a1284710f21c77c8', 'title': 'An Overview of the Active Gene Annotation Corpus and the BioNLP OST 2019 AGAC Track Tasks', 'abstract': 'The active gene annotation corpus (AGAC) was developed to support knowledge discovery for drug repurposing. Based on the corpus, the AGAC track of the BioNLP Open Shared Tasks 2019 was organized, to facilitate cross-disciplinary collaboration across BioNLP and Pharmacoinformatics communities, for drug repurposing. The AGAC track consists of three subtasks: 1) named entity recognition, 2) thematic relation extraction, and 3) loss of function (LOF) / gain of function (GOF) topic classification. The AGAC track was participated by five teams, of which the performance are compared and analyzed. The the results revealed a substantial room for improvement in the design of the task, which we analyzed in terms of “imbalanced data”, “selective annotation” and “latent topic annotation”.', 'externalIds': {'MAG': 2987875462.0, 'DBLP': 'conf/bionlp/WangZGX19', 'DOI': '10.18653/v1/D19-5710', 'CorpusId': 208332107.0, 'ACL': 'D19-5710'}, 'label': 1}\n",
      "{'paperId': '8e7220d3830ccf4b44a7b77a8d64f351315d6859', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/8e7220d3830ccf4b44a7b77a8d64f351315d6859', 'title': 'Using a text engineering framework to build an extendable and portable IE-based summarisation system', 'abstract': 'In this paper we describe how information extraction technology has been used to build a summarisation system in the domain of occupational health and safety. The core of the application is based on named entity recognition using pattern-action semantic grammar rules. Co-occurrence of the named entities is used as a criteria to identify the sentences to be included in the summary. The system is developed and automatically evaluated within the GATE framework, and can easily be extended or ported to new domains.', 'externalIds': {'MAG': 2157901004.0, 'DOI': '10.3115/1118162.1118165', 'CorpusId': 2970935.0, 'ACL': 'W02-0403'}, 'label': 1}\n",
      "{'paperId': 'ef3d9cbd094083336770e39c35bb28ea26c0f41a', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/ef3d9cbd094083336770e39c35bb28ea26c0f41a', 'title': 'Cross-lingual semantic annotation of biomedical literature: experiments in Spanish and English', 'abstract': 'MOTIVATION', 'externalIds': {'MAG': 2986423875.0, 'DBLP': 'journals/bioinformatics/PerezABCMSR20', 'DOI': '10.1093/bioinformatics/btz853', 'CorpusId': 208039303.0, 'PubMed': 31730202.0}, 'label': 1}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Biomedical literature is one of the most relevant sources of information for knowledge mining in the field of Bioinformatics. In spite of English being the most widely addressed language in the field, in recent years there has been a growing interest from the natural language processing community in dealing with languages other than English. However, the availability of language resources and tools for appropriate treatment of non-English texts is lacking behind. Our research is concerned with the semantic annotation of biomedical texts in the Spanish language, which can be considered an under-resourced language where biomedical text processing is concerned.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'RESULTS', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'We have carried out experiments to assess the effectiveness of several methods for the automatic annotation of biomedical texts in Spanish. One approach is based on the linguistic analysis of Spanish texts and their annotation using an information retrieval and concept disambiguation approach. A second method takes advantage of a Spanish-English machine translation process to annotate English documents and transfer annotations back to Spanish. A third method takes advantage of the combination of both procedures. Our evaluation shows that a combined system has competitive advantages over the two individual procedures.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'AVAILABILITY', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'UMLSmapper (https://snlt.vicomtech.org/umlsmapper) and the annotation transfer tool (http://scientmin.taln.upf.edu/anntransfer) are freely available for research purposes as web services and/or demos.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'SUPPLEMENTARY INFORMATION', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Supplementary data are available at Bioinformatics online.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': 'f656b3f6b4c1f883b6e3bb1fc5cb2e2a9f0bf0e9', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/f656b3f6b4c1f883b6e3bb1fc5cb2e2a9f0bf0e9', 'title': 'Bridging the Knowledge Gap: Improving BERT models for answering MCQs by using Ontology-generated synthetic MCQA Dataset', 'abstract': nan, 'externalIds': {'DOI': '10.32473/flairs.37.1.135608', 'CorpusId': 271006437.0}, 'label': 1}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' ', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' ', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'BERT-based models possess impressive language understanding capabilities but often lack domain-specific knowledge, limiting their performance on specialised tasks such as medical multiple-choice question answering (MCQA). In this paper, we study how biomedical ontologies, rich repositories of medical knowledge, can be harnessed to enhance BERT-based models for medical MCQA task. Our contributions include OntoMCQA-Gen, a system which leverages different biomedical ontologies to construct BioOntoMCQA, a large synthetic MCQA dataset. OntoMCQA-Gen exploits the subclass-class relationships, definitions of concepts, and also synonym relationships from the ontologies to create this dataset of MCQs automatically. We then use this synthetic dataset to fine-tune various BERT-based models to answer medical MCQs. We evaluated these fine-tuned BERT models on the challenging MedMCQA and MedQA datasets of questions from admission examinations for medical degrees in India and USA, respectively. Our evaluation study on these datasets shows that fine-tuning the BERT-based models on BioOntoMCQA results in significantly improved accuracy scores. BioBERT and PubMedBERT, pretrained on the large medical corpus, have also shown significant improvements with our technique of fine-tuning ontology-generated synthetic data. This finding highlights the effectiveness of incorporating biomedi- cal ontologies to enhance the BERT-based model in the medical domain. Moreover, our results underscore the importance of using ontology-generated data along with model adaptation for specialised domains, contributing to a novel advancement in natural language processing.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' ', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': ' ', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': '5bef8ecdeec3a11da86251e2cdbff1350135a7ad', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/5bef8ecdeec3a11da86251e2cdbff1350135a7ad', 'title': 'One Size Does Not Fit All: An Ensemble Approach Towards Information Extraction from Adverse Drug Event Narratives', 'abstract': 'Recognizing named entities in Adverse Drug Reactions narratives is a fundamental step towards extracting valuable patient information from unstructured text into a structured thus actionable format. This then unlocks advanced data analytics towards intelligent pharmacovigilance. Yet existing biomedical named entity recognition (NER) tools are limited in their ability to identify certain entity types from these domain-specific narratives and result in significant performance differences in terms of accuracy. To address these challenges, we propose an ensemble approach that integrates a rich variety of named entity recognizers to procure the final result. First, one critical problem faced by NER in the biomedical context is that the data is highly skewed. That is, only 1% of words belong to a certain medical entity type, such as, the reason for medication usage compared to all other non-reason words. We propose a balanced, under-sampled bagging strategy that is dependent on the imbalance level to overcome the class imbalance problem. Second, we present an ensemble of heterogeneous recognizers approach that leverages a novel ensemble combiner. Our experimental results show that for biomedical text datasets: (i) a balanced learning environment along with an Ensemble of Heterogeneous Classifiers constantly improves the performance over individual base learners and, (ii) stacking-based ensemble combiner methods outperform simple Majority Voting by 0.30 F-measure.', 'externalIds': {'MAG': 2792178553.0, 'DBLP': 'conf/biostec/Wunnava0KKRSD18', 'DOI': '10.5220/0006600201760188', 'CorpusId': 4357809.0}, 'label': 1}\n",
      "{'paperId': '7eaf95d4861c365b07b1ddb2bcaf20cbb045e5e9', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/7eaf95d4861c365b07b1ddb2bcaf20cbb045e5e9', 'title': 'Kalya Research: Complementary and Alternative Medicine (CAM) Virtual Research Assistant from Biomedical Literature', 'abstract': 'Complementary and alternative medicines (CAM) become an emerging subject of interest both for users and health professionals. Rigorous studies identify efficient and safe methods for human health, frequently called by researchers, non-pharmacological interventions. The challenge is to determine relevant articles in a large and increasing volume of publications and journals. To meet this challenge, we created Kalya Research (KR), a medical assistant tool based on artificial intelligence that selects and characterizes CAM literature and bring support to medical researchers. Based on rule models and ontologies, KR can suggest relevant and recent CAM publications. It presents key indicators through analytical visualizations. KR was evaluated at several points (effectiveness, relevance, usability) in 2 ways, by means of a bibliographic search comparison with MedLine and by questioning more than 40 biomedical researchers who used KR for their research. When compared with Medline, KR highlighted most of the relevant CAM publications. The evaluation by the researchers showed that the majority of them found the tool to be relevant and time saver and feature-rich. Our future objectives are therefore to constantly develop the application to improve our models for detecting CAM publications and named entities (diseases, CAMs, outcomes), and to extend it to new health topics.', 'externalIds': {'DOI': '10.32388/iw54x7.2', 'CorpusId': 266257343.0}, 'label': 1}\n",
      "{'paperId': 'c64a0909edab376dcc087cb40b632ba475076cf4', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/c64a0909edab376dcc087cb40b632ba475076cf4', 'title': 'Knowledge Discovery from Biomedical Ontologies in Cross Domains', 'abstract': 'In recent years, there is an increasing demand for sharing and integration of medical data in biomedical research. In order to improve a health care system, it is required to support the integration of data by facilitating semantic interoperability systems and practices. Semantic interoperability is difficult to achieve in these systems as the conceptual models underlying datasets are not fully exploited. In this paper, we propose a semantic framework, called Medical Knowledge Discovery and Data Mining (MedKDD), that aims to build a topic hierarchy and serve the semantic interoperability between different ontologies. For the purpose, we fully focus on the discovery of semantic patterns about the association of relations in the heterogeneous information network representing different types of objects and relationships in multiple biological ontologies and the creation of a topic hierarchy through the analysis of the discovered patterns. These patterns are used to cluster heterogeneous information networks into a set of smaller topic graphs in a hierarchical manner and then to conduct cross domain knowledge discovery from the multiple biological ontologies. Thus, patterns made a greater contribution in the knowledge discovery across multiple ontologies. We have demonstrated the cross domain knowledge discovery in the MedKDD framework using a case study with 9 primary biological ontologies from Bio2RDF and compared it with the cross domain query processing approach, namely SLAP. We have confirmed the effectiveness of the MedKDD framework in knowledge discovery from multiple medical ontologies.', 'externalIds': {'MAG': 2517617411.0, 'PubMedCentral': 4993478.0, 'DOI': '10.1371/journal.pone.0160005', 'CorpusId': 16068842.0, 'PubMed': 27548262.0}, 'label': 0}\n",
      "{'paperId': 'b851f51311a23eb35910d1e323f9652aeddade18', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/b851f51311a23eb35910d1e323f9652aeddade18', 'title': 'Biomedical Relation Extraction Using Distant Supervision', 'abstract': 'With the accelerating growth of big data, especially in the healthcare area, information extraction is more needed currently than ever, for it can convey unstructured information into an easily interpretable structured data. Relation extraction is the second of the two important tasks of relation extraction. This study presents an overview of relation extraction using distant supervision, providing a generalized architecture of this task based on the state-of-the-art work that proposed this method. Besides, it surveys the methods used in the literature targeting this topic with a description of different knowledge bases used in the process along with the corpora, which can be helpful for beginner practitioners seeking knowledge on this subject. Moreover, the limitations of the proposed approaches and future challenges were highlighted, and possible solutions were proposed.', 'externalIds': {'MAG': 3036783970.0, 'DBLP': 'journals/sp/BoudjellalZKA20', 'DOI': '10.1155/2020/8893749', 'CorpusId': 219965358.0}, 'label': 1}\n",
      "{'paperId': '332a1b5c5f16912b2dcab5f827bd1d468435b682', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/332a1b5c5f16912b2dcab5f827bd1d468435b682', 'title': 'Biomedical Named Entity Recognition with less Supervision', 'abstract': 'Summary form only given: Annotating clinical notes manually is very labor-intensive and needs expertise in the area of annotation. Thus annotation is a highly expensive task not only in human resource but also in financial aspects. Moreover mistakes, missed tags, and inconsistency are the common problems with manual annotations. The purpose of this research is to reduce humans as annotation effort for clinical notes, to improve consistency, and to decrease cost of annotation. The aim of this research is to annotate clinical texts to extract biomedical names and terms. In our research Unified Medical Language System (UMLS) is the reference meta thesaurus of names and terms used in biomedical and clinical domains. In this research we have done unsupervised and semi-supervised Named Entity Recognition (NER) through exact matching in UMLS. The data sets that have been used were provided by SemEval 2015 (task 14) natural language processing competition, including 199 clinical notes in training set and 133 notes in test set. The analysis that has been done so far can be divided into two steps: mapping and learning. The first step is to map all terms into UMLS that includes not only unigrams but also n-grams, usually n is 5. To achieve the best results of exact matching, we extracted UMLS terms of diseases and disorders based on semantic groups and mapped each n-gram to that part of UMLS. If there is a match, that is assumed to be a disease or disorder. When there is no match for n-grams (n>=2), to avoid low precisions, we supposed that unigrams must be noun phrases to be nominated as a disease/disorder. With this method we got 60% of f-score, and training files for next process (training CRFs) were generated. The second step involves using Conditional Random Fields (CRFs). The results generated in the first step were used to train the CRF. CRFs learn from training data the general contexts in which named entities occur. Also because of different levels of correctness in training files, we decided to modify training files before using them to train CRFs and to test on test data. Level of correctness means different accuracies of tagging in the data set. Because exact matching is not very accurate, the accuracy in different notes is variable. In some data it is very high and in some of them it is low. This results in an inconsistency in training files. To solve this problem we divided training files into ten groups. The CRF used only one group to be trained and to tag other groups, and results of exact matches and CRFs were combined (logic OR between results of CRF and exact match) together to get the final results. This was done for all other groups as well, and finally applied on test data. These two steps together are known as unsupervised disease named entity recognition, and the results show a difference of 10.3 percent between unsupervised and supervised approaches. By supervised learning we got 73% F-score while we got 62.7% by the proposed unsupervised approach. Another approach that was developed is semi supervised disease named entity recognition that used annotated files generated by unsupervised method and annotated files by human or gold standards. By this method we could improve 73% of F-score, that we got in supervised approach, to 74.2%. In the future some other refinements and extra tasks are going to be done. To improve the results, we are planning to use approximate matching by the process that is called normalization. Normalization means mapping a term in clinical notes to a preferred term in UMLS. These kinds of terms do not have exact matches, thus the way to find exact matches is to use normalization. Moreover we are going to do exact/approximate matching over discontinuous mentions in clinical texts. In these texts there are mentions including disconnected words in a sentence that together form a named entity. This essential step will extract those mentions that could not be extracted by exact match and normalization approaches. The last thing in our plan is to expand our developed system to a less supervised \"Biomedical Named Entity Recognition (BNER)\" to extract all biomedical and clinical terms. We will do this for other semantic groups in UMLS such as Activities and Behaviors, Anatomy, Devices, Phenomena, etc. Thus developing a less supervised annotating system for clinical notes could generate annotated notes with less cost of manual tagging, more consistent, and accurate enough. By using this approach it is feasible to extract tags of other semantic groups in UMLS, and finally it could be an advanced system to tag all the biomedical and clinical mentions based on semantic groups in UMLS.', 'externalIds': {'MAG': 2295141588.0, 'DBLP': 'conf/ichi/GhiasvandK15', 'DOI': '10.1109/ICHI.2015.85', 'CorpusId': 16955736.0}, 'label': 1}\n",
      "{'paperId': '337955822223bae5e6eaea81adfcd280413a1d1c', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/337955822223bae5e6eaea81adfcd280413a1d1c', 'title': 'VSP at MEDDOCAN 2019 De-Identification of Medical Documents in Spanish with Recurrent Neural Networks', 'abstract': 'This work presents the participation in the MEDDOCAN Task of the VSP team with a neural model for the Named Entity Recognition of medical documents in Spanish. The Neural Network consists of a two-layer model that creates a feature vector for each word of the sentences. The first layer uses the character information of each word and the output is aggregated to the second layer together with its word embedding in order to create the feature vector of the word. Both layers are implemented with a bidirectional Recurrent Neural Network with LSTM cells. Moreover, a Conditional Random Field layer classifies the word vectors in one of the 29 types of Protected Health Information (PHI). The system obtains a performance of 86.01%, 87.03%, and 89,12% in F1 for the classification of the entity types, the sensitive span detection, and both tasks merged, respectively. The model shows very high and promising results being a basic approach without using pretrained word embeddings or any hand-crafted feature.', 'externalIds': {'MAG': 2971088040.0, 'DBLP': 'conf/sepln/Suarez-Paniagua19a', 'CorpusId': 199448300.0}, 'label': 1}\n",
      "{'paperId': 'e3b31ab11bbcc8c9003604292471529a34804400', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/e3b31ab11bbcc8c9003604292471529a34804400', 'title': 'Named Entity Recognition for Novel Types by Transfer Learning', 'abstract': \"In named entity recognition, we often don't have a large in-domain training corpus or a knowledge base with adequate coverage to train a model directly. In this paper, we propose a method where, given training data in a related domain with similar (but not identical) named entity (NE) types and a small amount of in-domain training data, we use transfer learning to learn a domain-specific NE model. That is, the novelty in the task setup is that we assume not just domain mismatch, but also label mismatch.\", 'externalIds': {'MAG': 2547450774.0, 'DBLP': 'conf/emnlp/QuFZHB16', 'DOI': '10.18653/v1/D16-1087', 'CorpusId': 11406047.0, 'ACL': 'D16-1087', 'ArXiv': 1610.09914}, 'label': 0}\n",
      "{'paperId': '1e15de9245be9bf8f11c1270f46fb0195caf240d', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/1e15de9245be9bf8f11c1270f46fb0195caf240d', 'title': 'Document-Level Relation Extraction with Reconstruction', 'abstract': 'In document-level relation extraction (DocRE), graph structure is generally used to encode relation information in the input document to classify the relation category between each entity pair, and has greatly advanced the DocRE task over the past several years. However, the learned graph representation universally models relation information between all entity pairs regardless of whether there are relationships between these entity pairs. Thus, those entity pairs without relationships disperse the attention of the encoder-classifier DocRE for ones with relationships, which may further hind the improvement of DocRE. To alleviate this issue, we propose a novel encoder-classifier-reconstructor model for DocRE. The reconstructor manages to reconstruct the ground-truth path dependencies from the graph representation, to ensure that the proposed DocRE model pays more attention to encode entity pairs with relationships in the training. Furthermore, the reconstructor is regarded as a relationship indicator to assist relation classification in the inference, which can further improve the performance of DocRE model. Experimental results on a large-scale DocRE dataset show that the proposed model can significantly improve the accuracy of relation extraction on a strong heterogeneous graph-based baseline. The code is publicly available at https://github.com/xwjim/DocRE-Rec.', 'externalIds': {'DBLP': 'journals/corr/abs-2012-11384', 'DOI': '10.1609/aaai.v35i16.17667', 'CorpusId': 229339602.0, 'ArXiv': 2012.11384}, 'label': 0}\n",
      "{'paperId': '0b494dd537f3991b0525db0227ed5a43081ea51a', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/0b494dd537f3991b0525db0227ed5a43081ea51a', 'title': 'Data integration in the life sciences : second International Workshop, DILS 2005, San Diego, CA, USA, July 20-22, 2005 ; proceedings', 'abstract': 'Keynotes.- Challenges in Biological Data Integration in the Post-genome Sequence Era.- Curated Databases.- User Applications.- A User-Centric Framework for Accessing Biological Sources and Tools.- BioLog: A Browser Based Collaboration and Resource Navigation Assistant for BioMedical Researchers.- Learning Layouts of Biological Datasets Semi-automatically.- Ontologies.- Factors Affecting Ontology Development in Ecology.- Querying Ontologies in Relational Database Systems.- Scientific Names Are Ambiguous as Identifiers for Biological Taxa: Their Context and Definition Are Required for Accurate Data Integration.- The Multiple Roles of Ontologies in the BioMediator Data Integration System.- Data Integration I-IV.- Integrating Heterogeneous Microarray Data Sources Using Correlation Signatures.- Knowledge-Based Integrative Framework for Hypothesis Formation in Biochemical Networks.- Semantic Correspondence in Federated Life Science Data Integration Systems.- Assigning Unique Keys to Chemical Compounds for Data Integration: Some Interesting Counter Examples.- Integrating and Warehousing Liver Gene Expression Data and Related Biomedical Resources in GEDAW.- Information Integration and Knowledge Acquisition from Semantically Heterogeneous Biological Data Sources.- Cluster Based Integration of Heterogeneous Biological Databases Using the AutoMed Toolkit.- Hybrid Integration of Molecular-Biological Annotation Data.- Setup and Annotation of Metabolomic Experiments by Integrating Biological and Mass Spectrometric Metadata.- Performance-Oriented Privacy-Preserving Data Integration.- Potpourri.- Building a Generic Platform for Medical Screening Applications Based on Domain Specific Modeling and Process Orientation.- Automatic Generation of Data Types for Classification of Deep Web Sources.- BioNavigation: Selecting Optimum Paths Through Biological Resources to Evaluate Ontological Navigational Queries.- Posters and Demonstrations.- Support for BioIndexing in BLASTgres.- An Environment to Define and Execute In-Silico Workflows Using Web Services.- Web Service Mining for Biological Pathway Discovery.- SemanticBio: Building Conceptual Scientific Workflows over Web Services.- PLATCOM: Current Status and Plan for the Next Stages.- SOAP API for Integrating Biological Interaction Databases.- Collaborative Curation of Data from Bio-medical Texts and Abstracts and Its integration.- Towards an Ontology Based Visual Query System.- Invited Briefings.- Data Integration in the Biomedical Informatics Research Network (BIRN).- Data Integration and Workflow Solutions for Ecology.- Eco-Informatics for Decision Makers Advancing a Research Agenda.- An Architecture and Application for Integrating Curation Data at the Residue Level for Proteins.- The Biozon System for Complex Analysis of Heterogeneous Interrelated Biological Data and Discovery of Emergent Structures.', 'externalIds': {'MAG': 1537750021.0, 'CorpusId': 264685021.0}, 'label': 0}\n",
      "{'paperId': '249c8aa90414f95979d4dfc4342da8bc7e4af7b5', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/249c8aa90414f95979d4dfc4342da8bc7e4af7b5', 'title': 'Combining Sample Selection and Error-Driven Pruning for Machine Learning of Coreference Rules', 'abstract': 'Most machine learning solutions to noun phrase coreference resolution recast the problem as a classification task. We examine three potential problems with this reformulation, namely, skewed class distributions, the inclusion of \"hard\" training instances, and the loss of transitivity inherent in the original coreference relation. We show how these problems can be handled via intelligent sample selection and error-driven pruning of classification rule-sets. The resulting system achieves an F-measure of 69.5 and 63.4 on the MUC-6 and MUC-7 coreference resolution data sets, respectively, surpassing the performance of the best MUC-6 and MUC-7 coreference systems. In particular, the system outperforms the best-performing learning-based coreference system to date.', 'externalIds': {'MAG': 2047885427.0, 'DBLP': 'conf/emnlp/NgC02', 'DOI': '10.3115/1118693.1118701', 'CorpusId': 8950181.0, 'ACL': 'W02-1008'}, 'label': 0}\n",
      "{'paperId': '02ce087d5bd696cf1d6a480d889c4ed1f5f0f9b4', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/02ce087d5bd696cf1d6a480d889c4ed1f5f0f9b4', 'title': 'Recognition of chemical entities in patents using LeadMine', 'abstract': 'LeadMine is a dictionary/grammar based approach to entity recognition. For chemical entities, hand-written grammars are used to recognize systematic chemical names and formulae. Trivial names are found using dictionaries, some derived from public sources and some hand curated. A rule-based method is used to detect abbreviations of identified entities. To improve the system’s performance on patents, improvements were made to the grammars for families of chemical compounds, and for chemical formulae, especially those containing R groups. Additionally a step was added where short ambiguous formulae, frequently used in Markush descriptions, are recognized e.g. C, N, O. Post-recognition certain terms are trimmed from entities for better agreement with the annotation guidelines e.g. \"heterocyclic\" instead of \"heterocyclic ring\". For genes/proteins, a dictionary-based recognizer was developed, using terms from Uniprot, EntrezGene and HGNC. Our system achieved F1-scores of 85.2% for chemicals and 75.2% for genes/proteins on the test set.', 'externalIds': {'CorpusId': 12533862.0}, 'label': 1}\n",
      "{'paperId': '782876a0eb86ea73808bb9e1423a34fa4dca28ef', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/782876a0eb86ea73808bb9e1423a34fa4dca28ef', 'title': 'Extractive Search for Analysis of Biomedical Texts', 'abstract': 'Extractive search has been used to create datasets matching queries and syntactic patterns, but less attention has been paid on what to do with those datasets. We present a two-stage system targeted towards biomedical texts. First, it creates custom datasets using a powerful mix of keyword and syntactic matching. We then return lists of related words, provide semantic search, train a large language model, a synthetic data based QA model, a summarization model over those results, and so on. These are then used in downstream biomedical work.', 'externalIds': {'DBLP': 'conf/sigir/ClothiauxS22', 'DOI': '10.1145/3477495.3536328', 'CorpusId': 250340161.0}, 'label': 1}\n",
      "{'paperId': '919536061245d3456a85b0439fcc2d9a87dce4f7', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/919536061245d3456a85b0439fcc2d9a87dce4f7', 'title': 'PuReD-MCL: a graph-based PubMed document clustering methodology', 'abstract': 'MOTIVATION', 'externalIds': {'MAG': 2106987717.0, 'DBLP': 'journals/bioinformatics/TheodosiouDAO08', 'DOI': '10.1093/bioinformatics/btn318', 'CorpusId': 15450296.0, 'PubMed': 18593717.0}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Biomedical literature is the principal repository of biomedical knowledge, with PubMed being the most complete database collecting, organizing and analyzing such textual knowledge. There are numerous efforts that attempt to exploit this information by using text mining and machine learning techniques. We developed a novel approach, called PuReD-MCL (Pubmed Related Documents-MCL), which is based on the graph clustering algorithm MCL and relevant resources from PubMed.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'METHODS', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'PuReD-MCL avoids using natural language processing (NLP) techniques directly; instead, it takes advantage of existing resources, available from PubMed. PuReD-MCL then clusters documents efficiently using the MCL graph clustering algorithm, which is based on graph flow simulation. This process allows users to analyse the results by highlighting important clues, and finally to visualize the clusters and all relevant information using an interactive graph layout algorithm, for instance BioLayout Express 3D.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'RESULTS', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'The methodology was applied to two different datasets, previously used for the validation of the document clustering tool TextQuest. The first dataset involves the organisms Escherichia coli and yeast, whereas the second is related to Drosophila development. PuReD-MCL successfully reproduces the annotated results obtained from TextQuest, while at the same time provides additional insights into the clusters and the corresponding documents.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'AVAILABILITY', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Source code in perl and R are available from http://tartara.csd.auth.gr/~theodos/', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': '6f15499af1c15fb723355c4c76a3f79a3afe5d41', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/6f15499af1c15fb723355c4c76a3f79a3afe5d41', 'title': 'A HMM Text Classification Model with Learning Capacity', 'abstract': 'Hidden Markov Model, Text classification, BioInformatics, Adaptive models In this paper a method of classifying biomedical text documents based on Hidden Markov Model is proposed and evaluated. The method is integrated into a framework named BioClass. Bioclass is composed of intelligent text classification tools and facilitates the comparison between them because it has several views of the results. The main goal is to propose a more effective based-on content classifier than current methods in this environment To test the effectiveness of the classifier presented, a set of experiments performed on the OSHUMED corpus are preseted. Our model is tested adding it learning capacity and without it, and it is compared with other classification techniques. The results suggest that the adaptive HMM model is indeed more suitable for document classification.', 'externalIds': {'CorpusId': 56445423.0}, 'label': 1}\n",
      "{'paperId': '759f29666748ed854400c16807f7cfc59578eed5', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/759f29666748ed854400c16807f7cfc59578eed5', 'title': 'Clinical XLNet-based End-to-End Knowledge Discovery on Clinical Text Data using Natural Language Processing', 'abstract': 'A modern framework for assessing patient histories and conducting clinical research has been developed as the number of clinical narratives evolves. To discover the knowledge from such clinical narratives, clinical entity recognition and relation extraction tasks were performed subsequently in existing approaches, which resulted in error propagation. Therefore, a novel end-to-end clinical knowledge discovery strategy has been proposed in this paper. The clinical XLNet was used as a base model for handling the discrepancy issue. To predict the dependent clinical relation association, the multinomial Naïve Bayes probability function has been incorporated. In order to improve the performance of the proposed strategy, it takes into account entity pairs presented consecutively through the multi-head attention layer. Tests have been conducted using the N2C2 corpus, and the proposed methodology achieves a greater than 20% improvement in accuracy over existing neural network-based and transformer-based methods.', 'externalIds': {'CorpusId': 263327064.0}, 'label': 1}\n",
      "{'paperId': '560c353b5145497747b81d6e064f5949eaad1401', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/560c353b5145497747b81d6e064f5949eaad1401', 'title': 'Co-decision matrix framework for name entity recognition in biomedical text', 'abstract': 'As a new branch of data mining and knowledge discovery, the research of biomedical text mining has a rapid progress currently. Biomedical named entity (BNE) recognition is a basic technique in the biomedical knowledge discovery and its performance has direct effects on further discovery and processing in biomedical texts. In this paper, we present an improved method based on co-decision matrix framework for Biomedical Named Entity Recognition (BNER). The relativity between classifiers is utilised by using co-decision matrix to exchange decision information among classifiers. The experiments are carried on GENIA corpus with the best result of 75.9% F-score. Experimental results show that the proposed method, co-decision matrix framework, can yield promising performances.', 'externalIds': {'MAG': 2165436705.0, 'DBLP': 'journals/ijdmb/WangL15', 'DOI': '10.1504/IJDMB.2015.067956', 'CorpusId': 207409676.0, 'PubMed': 26336667.0}, 'label': 1}\n",
      "{'paperId': '9e1d00a0ebde19ccbdc10edf18f99a130c5af2e1', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/9e1d00a0ebde19ccbdc10edf18f99a130c5af2e1', 'title': 'Coreference analysis in clinical notes: a multi-pass sieve with alternate anaphora resolution modules', 'abstract': 'OBJECTIVE', 'externalIds': {'MAG': 1497603085.0, 'DBLP': 'journals/jamia/JonnalagaddaLSWWTL12', 'DOI': '10.1136/amiajnl-2011-000766', 'CorpusId': 15902587.0, 'PubMed': 22707745.0}, 'label': 1}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'This paper describes the coreference resolution system submitted by Mayo Clinic for the 2011 i2b2/VA/Cincinnati shared task Track 1C. The goal of the task was to construct a system that links the markables corresponding to the same entity.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'MATERIALS AND METHODS', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'The task organizers provided progress notes and discharge summaries that were annotated with the markables of treatment, problem, test, person, and pronoun. We used a multi-pass sieve algorithm that applies deterministic rules in the order of preciseness and simultaneously gathers information about the entities in the documents. Our system, MedCoref, also uses a state-of-the-art machine learning framework as an alternative to the final, rule-based pronoun resolution sieve.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'RESULTS', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'The best system that uses a multi-pass sieve has an overall score of 0.836 (average of B(3), MUC, Blanc, and CEAF F score) for the training set and 0.843 for the test set.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'DISCUSSION', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'A supervised machine learning system that typically uses a single function to find coreferents cannot accommodate irregularities encountered in data especially given the insufficient number of examples. On the other hand, a completely deterministic system could lead to a decrease in recall (sensitivity) when the rules are not exhaustive. The sieve-based framework allows one to combine reliable machine learning components with rules designed by experts.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': nan, 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'CONCLUSION', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Using relatively simple rules, part-of-speech information, and semantic type properties, an effective coreference resolution system could be designed. The source code of the system described is available at https://sourceforge.net/projects/ohnlp/files/MedCoref.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': '8aa043e5e7f3c47c9732456b56da0c205cc16eb5', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/8aa043e5e7f3c47c9732456b56da0c205cc16eb5', 'title': 'Chemical binding of pyrrolidinyl peptide nucleic acid (acpcPNA‐T9) probe with AuNPs toward label‐free monitoring of miRNA‐21: A novel biosensing platform for biomedical analysis and POC diagnostics', 'abstract': 'miRNAs are attractive factors in cancer research studies due to their important roles for regulating of gene expression. Because of miRNA‐21 expression surplus in many types of cancers, so accurate identification is important. Increasing efforts have caused different methods to improve the sensitivity and specificity of detection. Present study is an attempt to report a new electrochemical label‐free PNA‐based bioassay for detection of miRNA‐21. In this study, gold electrode was modified by gold nanoparticles to improve a functional PNA‐based biosensor. The EDS and field emission scanning electron microscope (FE‐SEM) were used to detect fabrication of biosensor. The electrochemical behavior of sensor was evaluated after inserting of acpcPNA probes and miRNA‐21 on the stucture of electrode and analyzed essential parameters such as various concentration of target miRNA, hybridization time, reproducibility, stability, and applicability. The results of study demonstrated that engineered biosensor was successfully fabricated. The findings showed the highest amount of current in 5\\u2009minutes hybridization time, with suitable reproducibility and stability. This innovative miRNA‐based biosensor presents a sensitive and specific method in fast and may be lab‐on chip assay in future.', 'externalIds': {'DOI': '10.1002/jmr.2893', 'CorpusId': 233035040.0, 'PubMed': 33822429.0}, 'label': 0}\n",
      "{'paperId': '10a4db59e81d26b2e0e896d3186ef81b4458b93f', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/10a4db59e81d26b2e0e896d3186ef81b4458b93f', 'title': 'Named Entity Recognition with Bidirectional LSTM-CNNs', 'abstract': 'Named entity recognition is a challenging task that has traditionally required large amounts of knowledge in the form of feature engineering and lexicons to achieve high performance. In this paper, we present a novel neural network architecture that automatically detects word- and character-level features using a hybrid bidirectional LSTM and CNN architecture, eliminating the need for most feature engineering. We also propose a novel method of encoding partial lexicon matches in neural networks and compare it to existing approaches. Extensive evaluation shows that, given only tokenized text and publicly available word embeddings, our system is competitive on the CoNLL-2003 dataset and surpasses the previously reported state of the art performance on the OntoNotes 5.0 dataset by 2.13 F1 points. By using two lexicons constructed from publicly-available sources, we establish new state of the art performance with an F1 score of 91.62 on CoNLL-2003 and 86.28 on OntoNotes, surpassing systems that employ heavy feature engineering, proprietary lexicons, and rich entity linking information.', 'externalIds': {'MAG': 2951460488.0, 'DBLP': 'journals/corr/ChiuN15', 'DOI': '10.1162/tacl_a_00104', 'CorpusId': 6300165.0, 'ACL': 'Q16-1026', 'ArXiv': 1511.08308}, 'label': 0}\n",
      "{'paperId': '678357329b4a8e16fc76ac145e3139e97b876a62', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/678357329b4a8e16fc76ac145e3139e97b876a62', 'title': 'Enhancing Pressure Injury Surveillance Using Natural Language Processing', 'abstract': 'Objective This study assessed the feasibility of nursing handoff notes to identify underreported hospital-acquired pressure injury (HAPI) events. Methods We have established a natural language processing–assisted manual review process and workflow for data extraction from a corpus of nursing notes across all medical inpatient and intensive care units in a tertiary care pediatric center. This system is trained by 2 domain experts. Our workflow started with keywords around HAPI and treatments, then regular expressions, distributive semantics, and finally a document classifier. We generated 3 models: a tri-gram classifier, binary logistic regression model using the regular expressions as predictors, and a random forest model using both models together. Our final output presented to the event screener was generated using a random forest model validated using derivation and validation sets. Results Our initial corpus involved 70,981 notes during a 1-year period from 5484 unique admissions for 4220 patients. Our interrater human reviewer agreement on identifying HAPI was high (κ = 0.67; 95% confidence interval [CI], 0.58–0.75). Our random forest model had 95% sensitivity (95% CI, 90.6%–99.3%), 71.2% specificity (95% CI, 65.1%–77.2%), and 78.7% accuracy (95% CI, 74.1%–83.2%). A total of 264 notes from 148 unique admissions (2.7% of all admissions) were identified describing likely HAPI. Sixty-one described new injuries, and 64 describe known yet possibly evolving injuries. Relative to the total patient population during our study period, HAPI incidence was 11.9 per 1000 discharges, and incidence rate was 1.2 per 1000 bed-days. Conclusions Natural language processing–based surveillance is proven to be feasible and high yield using nursing handoff notes.', 'externalIds': {'DOI': '10.1097/PTS.0000000000001193', 'CorpusId': 266549709.0, 'PubMed': 38147064.0}, 'label': 1}\n",
      "{'paperId': '4695c82884b5d6ca8a4273a44f60d345e2cf456a', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/4695c82884b5d6ca8a4273a44f60d345e2cf456a', 'title': 'ALBERT-Based Self-Ensemble Model With Semisupervised Learning and Data Augmentation for Clinical Semantic Textual Similarity Calculation: Algorithm Validation Study', 'abstract': 'Background In recent years, with increases in the amount of information available and the importance of information screening, increased attention has been paid to the calculation of textual semantic similarity. In the field of medicine, electronic medical records and medical research documents have become important data resources for clinical research. Medical textual semantic similarity calculation has become an urgent problem to be solved. Objective This research aims to solve 2 problems—(1) when the size of medical data sets is small, leading to insufficient learning with understanding of the models and (2) when information is lost in the process of long-distance propagation, causing the models to be unable to grasp key information. Methods This paper combines a text data augmentation method and a self-ensemble ALBERT model under semisupervised learning to perform clinical textual semantic similarity calculations. Results Compared with the methods in the 2019 National Natural Language Processing Clinical Challenges Open Health Natural Language Processing shared task Track on Clinical Semantic Textual Similarity, our method surpasses the best result by 2 percentage points and achieves a Pearson correlation coefficient of 0.92. Conclusions When the size of medical data set is small, data augmentation can increase the size of the data set and improved semisupervised learning can boost the learning efficiency of the model. Additionally, self-ensemble methods improve the model performance. Our method had excellent performance and has great potential to improve related medical problems.', 'externalIds': {'MAG': 3111991384.0, 'PubMedCentral': 7864778.0, 'DOI': '10.2196/23086', 'CorpusId': 230674855.0, 'PubMed': 33480858.0}, 'label': 1}\n",
      "{'paperId': '42d5bebd50c5c3a6bb47e862e996257bd5940b21', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/42d5bebd50c5c3a6bb47e862e996257bd5940b21', 'title': 'Theme 02 - Genetics and Genomics', 'abstract': 'Background: Amyotrophic Lateral Sclerosis (ALS) is a fatal neurodegenerative disorder involving upper and lower motor neurons. It is mostly sporadic, tough pathogenic mutations are sometime detectable, mainly in those patients with a positive familiar track record for neurodegenerative disorders. More than 50 genes have been put in relation with ALS so far, among which SOD1, C9Orf72, FUS, ATXN2 and TARDBP are the most frequent. SOD1, encoding for the antioxidant enzyme Cu/ Zn superoxide dismutase and described for the first time in 1993, is the first gene that had been put in rela- tion with ALS. To date, over 180 different SOD1 mutations have been described throughout the five exons of the SOD1 gene. However, the exact pathogenic effect of this gene mutations are still unclear. Recently, a gene therapy targeting SOD1 has been approved for ALS patients carrying any SOD1 mutation. This new therapeutic approach has boosted the number of genetic tests performed, sometimes revealing unexpected positivity and sometimes underlying new genes ’ mutations. Here we describe a case of a woman with a new SOD1 mutation, not described in literature before and con- sidered as pathogenetic in VarSome. Case report: diseases, gait complete neurological dis-closing severe bulbar with anarthria, tongue hyposthenia and oral apraxia. presented mild upper hyposthenia, limbs Hereditary spastic paraplegia (HSP) is a heterogeneous group of genetic neurodegenerative disorders characterized by progressive weakness and spasticity of lower limbs. SPG15 is a rare form of autosomal recessive HSP due to mutations in ZFYVE26 gene, which encodes for spastizin, involved in autophagy and endocytosis (1). Here we describe the case of a 56 years old man who presented to our clinic in November 2020 referring a progressive motor clumsiness of both legs and walking instability during the last five years. No motor impairment at upper limb, no bulbar nor respiratory symptoms. These symptoms had a progressive evolution. In anamnesis only high blood pressure. No familiar history of neurodegenerative diseases. Neurological examination showed a spastic gait, a light hypo-trophy and hyposthenia of the left leg, brisk reflexes at lower limb, no Hoffmann nor Babinski signs, no urinary nor intes- tinal problems. He underwent: blood examination (resulted normal, no HIV, HTLV infections), electroneurography/electro- myography study (signs of chronic neurogenic muscle with apparently sporadic disease have a lower than expected testing yield. Increasing availability of wider genetic panels may confound our results and yield of testing with contemporary approaches may increase. Our data supports testing of individuals with early-onset disease but does not provide strong evidence for testing those without a family history. Interval re-evaluation of this cohort may be of benefit to appreciate the utility of an extended panel (26 genes plus C9orf72 established in 2021). Systematic questioning regarding family history of dementia, other neurological and psychiatric diseases may also help to identify at risk individuals with early-onset disease. Background: Neuronal nicotinic acetylcholine receptors (nAChRs) are ligand-gated ion channels encoded by different nicotinic cholinergic receptor (CHRN) genes and expressed in both bulbar and spinal motor neurons. They are involved in neuroprotection and in control of the release of many neuro-transmitters, including glutamate. It has been previously postulated that rare variants in the subunits of nAChRs might represent one of several genetic risk factors for Amyotrophic Lateral Sclerosis (ALS) (1). Objective: The aim of this study was to elucidate the contribution of genetic variation of CHRN genes to disease risk in ALS. Methods: We analyzed 935 sporadic ALS patients of Italian origin from the Piemonte and Aosta Register for ALS and 775 ethnically and geographically matched controls. We tested for associations of variants in the CHRN genes cluster using linear regression for common variants and burden analysis for rare (minor allele frequency, MAF, < 1%) variants. Results: No significant association between CHRN genes mutations and ALS was found after appropriate correction for multiple testing. We did not observe a significant excess of rare nonsynonymous variants or an aggregate contribution of rare and common coding variants to the risk for ALS. No effect was detected when applying the combined test at the gene cluster level. Conclusion: Our results indicate that common and rare genetic variations in the CHRN gene cluster do not contribute to ALS pathogenesis. However, further studies are needed to understand the possible effect of genetic variability in nAChRs to motor neuron degeneration. ERLIN1 and UNC13A genes in two different PLS patients. We also investigated the role of pathogenic expansions in PLS. In our PLS cohort no pathogenic expansions were found in the ATXN2 & C9orf72. Finally, we observed that the mean age of onset was 58.4 years and 60.05 years for our PLS and ALS cohort, respectively. This contrasts with the previously reported mean age of onset of 50 years and 60 years between the PLS and ALS patients, respectively. Introduction: Until the emergence of specific drugs for cer- tain genetic pathologies, the request for a genetic study was basically focused on the possibility of being able to carry out adequate genetic counselling. Now that it seems that the antisense oligonucleotide tofersen will soon be available for forms of ALS due to mutations in the copper-zinc superoxide dismutase (SOD1) gene, many scientific societies recommend carrying out a genetic study, at least of this SOD1 gene, in patients with ALS. Materials and methods: We collected transversally the results of the genetic studies carried out on our patients, in June 2022, and compared them with the results in 2019. Results: Of the 36 patients who are being followed up in our ALS unit, only two (5.56%) are positive for some type of genetic mutation (alterations in SOD 1 and in compound het-erozygosity for TANK binding kinase (TBK1) and angiogenin (ANG)), after sequencing in 25 (69.44%) of them, a wide ALS panel, as well as copy number determination for the C9orf72 gene. In absolute values, these are the same patients who had genetic alterations in the past, when compared with the results of 2019. In that moment, only those with a family history underwent a genetic study (in this case, two patients had alterations in C9orf72 and another in SOD1). In addition, patients with genetic alterations in our current cohort also have relevant family history. Conclusions: It seems that despite carrying out more genetic studies, no more patients with ALS due to genetic causes are discovered. However, despite this, it seems reasonable to continue with this behavior, since although the probability is very low (and this must be correctly informed to the patient), the detection of mutations in SOD1, at the present time, can determine a very relevant change in the prognosis of the disease. Background: Amyotrophic lateral sclerosis (ALS) is a rare and fatal neurodegenerative disease. Patients experience progressive motor neuron degeneration, leading to paralysis and death, often from respiratory failure within 3 – 5 years of diagnosis (1). While approximately 10% of ALS cases are familial, the genetic architecture of ALS is still largely unknown, par- ticularly in conjunction with local environmental risk factors that may increase susceptibility to disease. Methods: To address this gap in understanding, we conducted a genome-wide association study to understand the genetic risk factors using a regional cohort of 435 ALS cases and 279 controls primarily based in New England and Ohio. We performed SNP genotyping of 714 subjects using the NeuroChip array, which focuses on curated variants impli- cated in neurological diseases (Illumina Inc.). To minimize the effects of population stratification, we excluded subjects of non-European descent from the analysis. Standard quality control procedures on the genomic data left 242,090 SNPs included in the analysis. We used covariate adjusted logistic regression to screen all the SNPs ’ associations with ALS case-control status. Wald test was used to obtain the p- values followed by Bonferroni correction for multiple comparisons. Covariates included sex, age at symptom onset and the first 10 principal components. The genomic inflation factor was 1.02 after adjusting for covariates. Results: We found a marginally significant (Bonferroni adjusted p -value < 0.1) SNP in the ALS-linked gene, TARDBP : Rs367543041. This SNP was previously reported in association with ALS and was found to share a close affinity with the Sardinian haplotype. Discussion: Our results support future evaluation of genetic risk factors in regional cohorts to better understand potential genetic contributors to ALS risk as well Background: While classic ALS is characterized by varying degrees of upper motor neuron (UMN) and/or lower motor neuron (LMN) dysfunction, primary lateral sclerosis (PLS) and progressive muscular atrophy (PMA) represent extreme phenotypes characterized respectively by pure upper motor neu- ron (UMN) and lower motor neuron (LMN) pathology. Theorizing defects contribute to phenotypic heterogeneity in motor neuron long- read RNA sequencing to accurately capture the full-length transcriptome. Objectives: obtain of versus LMN pathology. Methods: Blood samples from age- and sex-matched individuals with clinical diagnoses of PLS (N (cid:3) 20), classic ALS (N (cid:3) 20) or PMA (N (cid:3) 20) were obtained from the PGB (Phenotype-Genotype-Biomarker, NCT02327845) study of the CReATe (Clinical Research in ALS and Related Disorders for Therapeutic Development) Consortium. RNA was extracted using the PAXgene Blood RNA extraction kit (Qiagen). Only samples with an RNA integrity number (RIN) above 7 were included. Long- read RNA sequencing was', 'externalIds': {'DOI': '10.1080/21678421.2022.2120678', 'CorpusId': 253629070.0, 'PubMed': 36394236.0}, 'label': 0}\n",
      "{'paperId': '5852ac104d29b364c72d6a8f6d3e764830664247', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/5852ac104d29b364c72d6a8f6d3e764830664247', 'title': 'Sentence Simplification Aids Protein-Protein Interaction Extraction', 'abstract': 'Accurate systems for extracting ProteinProtein Inter actions (PPIs) automatically from biomedical articles can help accelerate biomedical research. Biomedical Informatics researchers are collaborating to provide metaservices and advance the state-of-art in PPI extraction. One problem often neglected by current Natural Language Processing systems is the characteristic complexity of the sentences in biomedical literature. In this paper, we report on the impact that automatic simplification of sentences has on the performance of a state-of-art PPI extraction system, showing a substantial improvement in recall (8%) when the sentence simplification method is applied, without significant impact to precision.', 'externalIds': {'MAG': 1538616452.0, 'DBLP': 'journals/corr/abs-1001-4273', 'CorpusId': 14059790.0, 'ArXiv': 1001.4273}, 'label': 1}\n",
      "{'paperId': '4ca2be18b65a7f0b8ef09b85d3ac0b67ab94ad0d', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/4ca2be18b65a7f0b8ef09b85d3ac0b67ab94ad0d', 'title': 'Concept Extraction in EMR based on Stacking Method', 'abstract': \"With governments increasing investments in health information systems,information extraction in EMR( electronic medical record) has drawn more and more scholars' attention. Compared with the traditional text,EMR has its own characteristics. In 2010 i2b2 / VA challenge,F value of the best system in concept extraction task reaches 0. 8523. There's a wedge between concept extraction in EMR and traditional name entity recognitions. In order to extract relevant concepts in EMR more precisely,this article uses CRF,maximum entropy to establish baseline systems. The integrated classifier predictions with the stacking strategy are very remarkable,making the system F value reached 91. 1%.\", 'externalIds': {'MAG': 2353756928.0, 'CorpusId': 63288874.0}, 'label': 1}\n",
      "{'paperId': 'f4f5867d8b713cf66fe71f19c51033062976ac13', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/f4f5867d8b713cf66fe71f19c51033062976ac13', 'title': 'DDRE-27. IDH MUTATED GLIOMAS PROMOTE EPILEPTOGENESIS VIA D-2-HYDROXYGLUTARATE DEPENDENT MTOR HYPERACTIVATION', 'abstract': 'i12 NEURO-ONCOLOGY ADVANCES • MARCH 2021 selectivity and so we are interested in identifying which transporters are particularly important in the metabolic adaptation to hypoxia. Using CRISPR and siRNA technologies we have identified transporters that are functionally required to maintain cell proliferation of glioma cell lines and patient tumour cells. Furthermore, using stable isotope-enriched nutrients, we have identified novel means by which glioma cell metabolism can be perturbed by inhibition of these transporters. Characterising which SLC25A transporters are important for hypoxic tumour metabolism could therefore expose a way to exploit these hypoxic areas subsequently making them more vulnerable to treatment and thus impacting patient survival. DDRE-26. THE IMMUNO-METABOLIC ENZYME FASN PREVENTS CANCER-CELL INTRINSIC TYPE I INTERFERON RESPONSES IN GLIOBLASTOMA Mara De Martino1, Camille Daviaud1, Claire Vanpouille-Box1,2; 1Department of Radiation Oncology, Weill Cornell Medicine, New York, NY, USA, 2Sandra and Edward Meyer Cancer Center, New York, NY, USA Glioblastoma (GBM) is a devastating primary brain cancer with a median survival of 11–15 months. Radiation therapy (RT), the standard of care for GBM, can generate type I interferon responses (IFN-I) to jumpstart antitumor immunity. However, these effects are sometimes mitigated by inhibitory mechanisms that are exacerbated by RT. RT can modify GBM metabolism to promote de novo lipogenesis via the fatty acid synthase (FASN). Because FASN was found to impair IFN-I in antiviral immunity, we hypothesize that FASN is preventing RT-induced IFN-I responses to promote GBM survival and evade immune recognition. We first defined RT-induced metabolic changes in the GL261 murine GBM model. We observed an increase in mitochondrial respiration, glycolysis and in lipid metabolism-related pathways in 10 gray (Gy) irradiated GL261 cells. Additionally, we found upregulation of FASN by western blot and lipid accumulation by BODIPY staining in 10 Gy-GL261 cells. RT-induced lipid accumulation was reverted when GL261 cells were incubated with a FASN inhibitor. Next, to ask whether FASN was impairing IFN-I, GL261 cells were engineered to express an inducible shRNA silencing FASN (GL261shFASN) or its non-silencing control (GL261shNS). As expected, irradiation of GL261shNS cells enhanced the secretion of IFNbeta and CXCL10. This effect was more pronounced when FASN was abrogated in GL261 independently from the presence of RT. Finally, GL261shNS and GL261shFASN cells were orthotopically implanted in mice and IFN-I signaling was blocked by anti-IFN-I receptor antibody (a-IFNAR). Mice bearing GL261shFASN tumors presented a median survival of 51 days vs. 35 days for GL261shNS tumors, a significant prolongation of mice survival that was completely abrogated with a-IFNAR treatment. Overall, our findings suggest that FASN-mediated lipogenesis prevents RT-induced cancer cell intrinsic IFN-I to promote GBM survival. Consequently, it is possible that FASN acts as an immuno-metabolic checkpoint capable to regulate the immune system upon metabolic cues generated by RT. DDRE-27. IDH MUTATED GLIOMAS PROMOTE EPILEPTOGENESIS VIA D-2-HYDROXYGLUTARATE DEPENDENT MTOR HYPERACTIVATION Armin Mortazavi1, Islam Fayed1,2, Muzna Bachani1, Tyrone Dowdy1, Joseph Steiner3, Dragan Maric1, Chun Zhang Yang1, Mioara Larion1, Alexander Ksendzovsky4, Kareem Zaghloul1; 1National Institute of Health, Bethesda, MD, USA, 2Medstar Georgetown University Hospital, Washington, DC, USA, 3National Institute of Health, Bethesda, MD, USA, USA, 4University of Maryland School of Medicine, Baltimore, MD, USA INTRODUCTION: Epileptic seizures in patients with low-grade, isocitrate dehydrogenase (IDH) mutated gliomas reach 90%, a major source of morbidity for these patients. Albeit there are multiple features that contribute to tumor related epileptogenesis, IDH mutations are determined to be an independent factor, although the pathogenesis remains poorly understood. We demonstrate IDH-mutated tumors promote epileptogenesis through D-2hydroxyglutarate (D-2-HG) dependent mTOR hyperactivation and metabolic reprogramming. METHODS: Human epileptic and nonepileptic cortex were identified via subdural electrodes in patients with IDH-mutated gliomas (n=5). An in vitro rat cortical neuronal model on microelectrode arrays were utilized to investigate the role of D-2-HG on neuronal excitability. mTOR and lysine demethylase (KDM) modulators were applied to elucidate the epileptogenic mechanism. Tetrodotoxin was utilized to evaluate the contribution of neuronal activity to mTOR signaling and metabolism. mTOR signaling was evaluated through western blot analysis and multiplex immunofluorescence. Metabolic function were analyzed via Seahorse assays and metabolomic analysis. RESULTS: D-2-HG increased normalized bursting rate in the neuronal cultures (p<0.0001). Inhibition of mTOR with rapamycin corrected bursting levels to control levels. Furthermore, D-2-HG induced mTOR hyperactivation, independent of bursting activity, which correlated with upregulation of mTOR signaling in human epileptic tissue. KDM inhibition resulted in mTOR hyperactivation and neuronal hyperexcitability, which we demonstrated with D-2-HG, succinate, and PFI-90, a small molecule KDM inhibitor. Epileptic cortex and D-2-HG-treated neurons, have distinct metabolisms independent of neuronal activity compared to peritumoral nonepileptic cortex and control, respectively. CONCLUSION: We demonstrate IDHmutated gliomas promote epileptogenesis through a D-2-HG dependent mTOR hyperactivation via KDM inhibition, a putative mechanism and potential therapeutic targets. Furthermore, we argue mTOR hyperactivation results in metabolic reprogramming, independent of neuronal firing, which may contribute to epileptogenesis, a heretofore unrecognized aspect of pathologic mTOR signaling in neurological diseases. DDRE-28. MECHANISTIC AND THERAPEUTIC LINKS BETWEEN PURINE BIOSYNTHESIS AND DNA DAMAGE IN GLIOBLASTOMA Andrew Scott, Weihua Zhou, Kari Wilder-Romans, Jiane Feng, Zhe Wu, Anthony Andren, Li Zhang, Peter Sajjakulnukit, Maureen Kachman, Yoshie Umemura, Melanie Schmitt, Nathan Qi, Theodore Lawrence, Costas Lyssiotis, Daniel Wahl; University of Michigan, Ann Arbor, MI, USA Glioblastoma (GBM) is the most common and aggressive adult brain cancer. Radiation therapy (RT) is a critical treatment modality, and development of RT resistance is the predominant cause of recurrence and mortality in GBM patients. Using cell line models as well as patient-derived xenografts and neurospheres in orthotopic brain tumor models, we have identified increased rates and dependence upon de novo purine biosynthesis as a hallmark of GBM RT resistance. More recently, we have discovered that radiation treatment acutely stimulates flux through de novo purine synthesis in cell line and neurosphere models of GBM. This RT-induced increase in de novo purine synthesis is dependent on signaling through the DNA damage response and thus appears to be an adaptive mechanism to supply purines to repair radiation-induced DNA damage. To determine whether this regulatory mechanism also exists in vivo, we have used advanced metabolomic and metabolic tracing techniques with 13C-labeled glucose and 15N-labeled glutamine in mice bearing RT-resistant GBM patient-derived orthotopic brain tumors. We found that that orthotopic GBM PDXs had elevated activity of de novo purine synthesis that increased further after RT, while normal cortex had little activity even after RT. These observations have therapeutic relevance, as targeting this metabolic pathway with the FDA-approved purine biosynthesis inhibitor mycophenolate mofetil (MMF) overcomes GBM radiation resistance in mouse models in vivo. The lack of de novo purine synthesis in normal cortex suggests that targeting this pathway may be tumor specific. Collectively our data suggest that de novo synthesis of purines mediates RT resistance in GBM and that treatment of brain tumors with MMF in combination with RT may be a promising therapeutic strategy in patients. DDRE-29. DE NOVO PYRIMIDINE SYNTHESIS IS A TARGETABLE VULNERABILITY IN IDH-MUTANT GLIOMA Diana D. Shi1,2, Adam C. Wang1, Michael M. Levitt3, Jennifer E. Endress4,5, Min Xu3, Wenhua Gao1, Januka Khanal1, Dennis Bonal6, Harley I. Kornblum7,8, Quang-De Nguyen6, Stefan Gradl9, Andreas Sutter9, Michael Jeffers10, Andreas Janzer9, Daniel P. Cahill11, Keith L. Ligon12,13, Kalil G. Abdullah14, Isaac S. Harris15, William G. Kaelin1,16, Samuel K. McBrayer3; 1Department of Medical Oncology, Dana-Farber Cancer Institute and Harvard Medical School, Boston, MA, USA, 2Harvard Radiation Oncology Program, Boston, MA, USA, 3Children’s Medical Center Research Institute, University of Texas Southwestern Medical Center, Dallas, TX, USA, 4Ludwig Cancer Center, Boston, MA, USA, 5Harvard Medical School, Boston, MA, USA, 6Lurie Family Imaging Center, Center for Biomedical Imaging in Oncology, Dana-Farber Cancer Institute, Boston, MA, USA, 7Department of Molecular and Medical Pharmacology, University of California Los Angeles, Los Angeles, CA, USA, 8Department of Psychiatry and Behavioral Sciences, and Semel Institute for Neuroscience and Human Behavior, University of California Los Angeles, Los Angeles, CA, USA, 9Bayer AG, Berlin, Germany, 10Bayer HealthCare Pharmaceuticals, Whippany, NJ, USA, 11Department of Neurosurgery, Translational Neuro-Oncology Laboratory, Massachusetts General Hospital, Harvard Medical School, Boston, MA, USA, 12Department of Pathology, Brigham and Women’s Hospital, Boston, MA, USA, 13Department of Oncologic Pathology, Dana-Farber Cancer Institute, Boston, MA, USA, 14Department of Neurological Surgery, University of Texas Southwestern Medical Center, Dallas, TX, USA, 15Wilmot Cancer Institute, University of Rochester Medical Center, Rochester, NY, USA, 16Howard Hughes Medical Institute, Chevy Chase, MD, USA 70–90% of lower-grade g', 'externalIds': {'CorpusId': 232481438.0}, 'label': 0}\n",
      "{'paperId': '8e38b0e0e087ec09ba9ee3673c240dbbe4269777', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/8e38b0e0e087ec09ba9ee3673c240dbbe4269777', 'title': 'Identifying Abbreviation Definitions Machine Learning with Naturally Labeled Data', 'abstract': 'The rapid growth of biomedical literature requires accurate text analysis and text processing tools. Detecting abbreviations and identifying their definitions is an important component of such tools. In this work, we develop a machine learning algorithm for abbreviation definition identification in text. Most existing approaches for abbreviation definition identification employ rule-based methods. While achieving high precision, rule-based methods are limited to the rules defined and fail to capture many uncommon definition patterns. Supervised learning techniques, which offer more flexibility in detecting abbreviation definitions, have also been applied to the problem. However, they require manually labeled training data. In this study, we make use of what we term naturally labeled data. Positive training examples are extracted from text, which provides naturally occurring potential abbreviation-definition pairs. Negative training examples are generated randomly by mixing potential abbreviations with unrelated potential definitions. The machine learner is trained to distinguish between these two sets of examples. Then, the learned feature weights are used to identify the abbreviation full form. This approach does not require manually labeled training data. We evaluate the performance of our algorithm on the Ab3P, BIOADI and Meds tract corpora. We achieve an F-score that is comparable to the earlier existing systems yet with a higher recall.', 'externalIds': {'MAG': 2169821936.0, 'DBLP': 'conf/icmla/YeganovaCW10', 'DOI': '10.1109/ICMLA.2010.166', 'CorpusId': 1933089.0}, 'label': 1}\n",
      "{'paperId': '6a0defd2a6044cbad94911bee4e45f85bb673ccd', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/6a0defd2a6044cbad94911bee4e45f85bb673ccd', 'title': 'Bio-molecular event extraction using Support Vector Machine', 'abstract': 'The main goal of Biomedical Natural Language Processing (BioNLP) is to capture biomedical phenomena from textual data by extracting relevant entities, information and relations between biomedical entities (i.e. proteins and genes). In general, in most of the published papers, only binary relations were extracted. In a recent past, the focus is shifted towards extracting more complex relations in the form of bio-molecular events that may include several entities or other relations. In this paper we propose an approach that enables event extraction (detection and classification) of relatively complex bio-molecular events. We approach this problem as a supervised classificat ion problem and use the well-known algorithm, namely Support Vector Machine (SVM) that makes use of statistical and linguistic features that represent various morphological, syntactic and contextual information of the candidate bio-molecular trigger words. Firstly, we consider the problem of event detection and classification as a two-step process, first step of which deals with the event detection task and the second step classifies these identified events to one of the nine predefined classes. Later on we tr eat this problem as one-step process, and perform event detection and classification together. Three-fold cross validation expe riments on the BioNLP 2009 shared task datasets yield the overall average recall, precision and F-measure values of 62.95%, 74.53%, and 68.25%, respectively, for the event detection. We observed the overall classification accuracy of 72.50%. Evaluation resu lts of the proposed approach when detection and classification are performed together showed the overall recall, precision and F-measure values of 57.66%, 55.87%, and 56.75%, respectively.', 'externalIds': {'MAG': 2539274330.0, 'DOI': '10.1109/ICOAC.2011.6165192', 'CorpusId': 6056369.0}, 'label': 1}\n",
      "{'paperId': '86b4ec29b55a8f07401a3f5229bf403f0f6d5be5', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/86b4ec29b55a8f07401a3f5229bf403f0f6d5be5', 'title': 'Semantic Processing for Enhanced Access to Biomedical Knowledge', 'abstract': 'The Semantic Knowledge Representation (SKR) project at the National Library of Medicine (NLM) develops programs that extract usable semantic information from biomedical text by building on resources currently available at NLM. Two programs in particular, MetaMap and SemRep, are being applied to a variety of problems in biomedical informatics. Both programs depend on the biomedical domain knowledge available in the Unified Medical Language System® (UMLS®). In representing concepts and relationships extracted from text, the semantic predications produced by these programs support a variety of applications in biomedical information management, including automatic indexing of MEDLINE® citations, concept-based query expansion, accurate identification of anatomical terminology and relationships in clinical records, and the mining of biomedical text for drug-disease relations and molecular biology information.', 'externalIds': {'MAG': 81415018.0, 'CorpusId': 8827544.0}, 'label': 0}\n",
      "{'paperId': 'd93f919f4cf71792b2426d351a0cb5d643718542', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/d93f919f4cf71792b2426d351a0cb5d643718542', 'title': 'Using computable knowledge mined from the literature to elucidate confounders for EHR-based pharmacovigilance', 'abstract': 'Introduction: Confounding bias threatens the reliability of observational studies and poses a significant scientific challenge. This paper introduces a framework for identifying confounding factors by exploiting literature-derived computable knowledge. In previous work, we have shown that semantic constraint search over computable knowledge extracted from the literature can be useful for reducing confounding bias in statistical models of EHR-derived observational clinical data. We hypothesize that adjustment sets of literature-derived confounders could also improve causal inference. Methods: We introduce two methods (semantic vectors and string-based confounder search) that query the literature for potential confounders and use this information to build models from EHR-derived data to more accurately estimate causal effects. These methods search SemMedDB for indications TREATED BY the drug that is also known to CAUSE the adverse event. For evaluation, we attempt to rediscover associations in a publicly available reference dataset containing expected pairwise relationships between drugs and adverse events from empirical data derived from a corpus of 2.2M EHR-derived clinical notes. For our knowledge-base, we use SemMedDB, a database of computable knowledge mined from the biomedical literature. Using standard adjustment and causal inference procedures on dichotomous drug exposures, confounders, and adverse event outcomes, varying numbers of literature-derived confounders are combined with EHR data to predict and estimate causal effects in light of the literature-derived confounders. We then compare the performance of the new methods with naive ($chi^2$, reporting odds ratio) measures of association. Results and Conclusions: Logistic regression with ten vector space-derived confounders achieved the most improvement with AUROC of 0.628 (95% CI: [0.556,0.720]), compared with baseline $chi^2$ 0.507 (95% CI: [0.431,0.583]). Bias reduction was improved more often in modeling methods using more rather than less information, and using semantic vector rather than string-based search. We found computable knowledge useful for improving automated causal inference, and identified opportunities for further improvement, including a role for adjudicating literature-derived confounders by subject matter experts.', 'externalIds': {'MAG': 3041350182.0, 'DBLP': 'journals/jbi/MalecWBBC21', 'DOI': '10.1101/2020.07.08.20113035', 'CorpusId': 220443990.0, 'PubMed': 33716168.0}, 'label': 1}\n",
      "{'paperId': 'e24da2027f880d3cf71fbb4139aa5cef468619d3', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/e24da2027f880d3cf71fbb4139aa5cef468619d3', 'title': 'Arabic Biomedical Community Question Answering Based on Contextualized Embeddings', 'abstract': \"Community question answering has become increasingly important as they are practical for seeking and sharing information. Applying deep learning models often leads to good performance, but it requires an extensive amount of annotated data, a problem exacerbated for languages suffering a scarcity of resources. Contextualized language representation models have gained success due to promising results obtained on a wide array of downstream natural language processing tasks such as text classification, textual entailment, and paraphrase identification. This paper presents a novel approach by fine-tuning contextualized embeddings for a medical domain community question answering task. The authors propose an architecture combining two neural models powered by pre-trained contextual embeddings to learn a sentence representation and thereafter fine-tuned on the task to compute a score used for both ranking and classification. The experimental results on SemEval Task 3 CQA show that the model significantly outperforms the state-of-the-art models by almost 2% for the '16 edition and 1% for the '17 edition.\", 'externalIds': {'DBLP': 'journals/ijiit/AdlouniEAMRA21', 'DOI': '10.4018/IJIIT.2021070102', 'CorpusId': 237474675.0}, 'label': 0}\n",
      "{'paperId': 'baca8ad98441bd80938e55cf5191894baf88116c', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/baca8ad98441bd80938e55cf5191894baf88116c', 'title': 'Cost-sensitive structured perceptron incorporating category hierarchy for named entity recognition', 'abstract': 'Named Entity Recognition (NER) is a fundamental natural language processing task for the identification and classification of expressions into predefined categories, such as person and organization.Existing NER systems usually target about 10 categories and do not incorporate analysis of category relations.However, categories often belong naturally to some predefined hierarchy.In such cases, the distance between categories in the hierarchy becomes a rich source of information that can be exploited.This is intuitively useful particularly when the categories are numerous.On that account, this paper proposes an NER approach that can leverage category hierarchy information by introducing, in the structured perceptron framework, a cost function more strongly penalizing category predictions that are more distant from the correct category in the hierarchy.Experimental results on the GENIA biomedical text corpus indicate the effectiveness of the proposed approach as compared with the case where no cost function is utilized. In addition, the proposed approach demonstrates the superior performance over a representative work using multi-class support vector machines on the same corpus.A possible direction to further improve the proposed approach is to investigate more elaborate cost functions than a simple additive cost adopted in this work.', 'externalIds': {'MAG': 2809076213.0, 'DOI': '10.32890/JICT.14.2015.8153', 'CorpusId': 227025740.0}, 'label': 0}\n",
      "{'paperId': '603fd1648d28dce2eca1b8b8a9258f29068df66f', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/603fd1648d28dce2eca1b8b8a9258f29068df66f', 'title': 'Domain Ontology Health Informatics Service from Text Medical Data Classification', 'abstract': 'Domain Ontology can represent the particular meanings of terms as they apply to that domain from medical data. Terms of meaning and use help provide information and knowledge for a better health informatics service. In this paper, the proposed framework and method for building ontology from text medical data is called Domain Ontology Health Informatics Classification (DOHIC). This method uses data mining techniques and applies ontology categories to explore the creation of a practicable health informatics service system, including information extraction, text medical data classification and ontological terminology concepts. The text mining concept has enabled the discovery of derivational and remarkable health information, uncovered amongst assorted collections of textual medical data, for the diagnosis of diseases. Furthermore, it acts as a means of control for the vocabulary based system according to UMLS of methatherasus to support the application of a viable database, which also aided in finding key words and phrases from the health information text. A disease is identified using the IDC-10 diagnosis and disease classification system. Then, the C4.5 algorithm, a workable classification methodology, was exploited through a decision tree. The classification will then be converted and mapped into ontological techniques in XML/OWL in order to build the main structure of the health informatics domain ontology in the concept hierarchy or terminology. The retrieval mechanism is employed to show meaningful relationships among the symptoms. These relationships are useful for a health informatics service as they help discover and provide new knowledge.', 'externalIds': {'MAG': 2100173694.0, 'DOI': '10.1109/SRII.2011.48', 'CorpusId': 402469.0}, 'label': 1}\n",
      "{'paperId': '41c65a257abef987c2a8ba35829b47cae21c27b6', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/41c65a257abef987c2a8ba35829b47cae21c27b6', 'title': 'Language and Domain-Independent Named Entity Recognition : Experiment using SVM and High-Dimensional Features', 'abstract': 'This paper presents the results of experiments aiming to explore a baseline solution for the named entity recognition problem using a language-independent, domainindependent approach. The first domain chosen for this experiment is the biomedical publications domain, especially selected due to its importance and inherent challenges. A supervised learning approach using Support Vector Machines (SVM) and high-dimensional features is used. Single-class and multi-class classification performance and results are examined. The approach used eliminates prior language knowledge such as part-of-speech or noun phrase tagging thereby allowing for its applicability across languages. No domain-specific knowledge is included. The initial results are comparable to those obtained using more complex approaches despite problems faced due to memory and computational power limitations. The multi-class F!=1 score for the right boundary identification is 79.3%, for the left boundary identification is 69.9%, and the score for the semantic composite classification is 63.5%.', 'externalIds': {'CorpusId': 17724111.0}, 'label': 0}\n",
      "{'paperId': 'd639030f7191a0b9e8f07849fc7162b6bdf81cf8', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/d639030f7191a0b9e8f07849fc7162b6bdf81cf8', 'title': 'Semantic resources in pharmacovigilance: a corpus and an ontology for drug-drug interactions', 'abstract': 'Nowadays, with the increasing use of several drugs for the treatment of one or more different diseases (polytherapy) in large populations, the risk for drugs combinations that have not been studied in pre-authorization clinical trials has increased. This provides a favourable setting for the occurrence of drug-drug interactions (DDIs), a common adverse drug reaction (ADR) representing an important risk to patients safety, and an increase in healthcare costs. Their early detection is, therefore, a main concern in the clinical setting. Although there are different databases supporting healthcare professionals in the detection of DDIs, the quality of these databases is very uneven, and the consistency of their content is limited. Furthermore, these databases do not scale well to the large and growing number of pharmacovigilance literature in recent years. In addition, large amounts of current and valuable information are hidden in published articles, scientific journals, books, and technical reports. Thus, the large number of DDI information sources has overwhelmed most healthcare professionals because it is not possible to remain up to date on everything published about DDIs. Computational methods can play a key role in the identification, explanation, and prediction of DDIs on a large scale, since they can be used to collect, analyze and manipulate large amounts of biological and pharmacological data. Natural language processing (NLP) techniques can be used to retrieve and extract DDI information from pharmacological texts, supporting researchers and healthcare professionals on the challenging task of searching DDI information among different and heterogeneous sources. However, these methods rely on the availability of specific resources providing the domain knowledge, such as databases, terminological vocabularies, corpora, ontologies, and so forth, which are necessary to address the Information Extraction (IE) tasks. In this thesis, we have developed two semantic resources for the DDI domain that make an important contribution to the research and development of IE systems for DDIs. We have reviewed and analyzed the existing corpora and ontologies relevant to this domain, based on their strengths and weaknesses, we have developed the DDI corpus and the ontology for drug-drug interactions (named DINTO). The DDI corpus has proven to fulfil the characteristics of a high-quality gold-standard, and has demonstrated its usefulness as a benchmark for the training and testing of different IE systems in the SemEval-2013 DDIExtraction shared task. Meanwhile, DINTO has been used and evaluated in two different applications. Firstly, it has been proven that the knowledge represented in the ontology can be used to infer DDIs and their different mechanisms. Secondly, we have provided a proof-of-concept of the contribution of DINTO to NLP, by providing the domain knowledge to be exploited by an IE pilot prototype. From these results, we believe that these two semantic resources will encourage further research into the application of computational methods to the early detection of DDIs. This work has been partially supported by the Regional Government of Madrid under the Research Network MA2VICMR [S2009/TIC-1542], by the Spanish Ministry of Education under the project MULTIMEDICA [TIN2010-20644-C03-01] and by the European Commission Seventh Framework Programme under TrendMiner project [FP7-ICT287863].', 'externalIds': {'MAG': 2613946917.0, 'CorpusId': 114475396.0}, 'label': 1}\n",
      "{'paperId': '5b0a0aff06999e36d0908dcd1375530d4e0ab6ea', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/5b0a0aff06999e36d0908dcd1375530d4e0ab6ea', 'title': 'Bootstrapping a Romanian Corpus for Medical Named Entity Recognition', 'abstract': 'Named Entity Recognition (NER) is an important component of natural language processing (NLP), with applicability in biomedical domain, enabling knowledge-discovery from medical texts. Due to the fact that for the Romanian language there are only a few linguistic resources specific to the biomedical domain, it was created a sub-corpus specific to this domain. In this paper we present a newly developed Romanian sub-corpus for medical-domain NER, which is a valuable asset for the field of biomedical text processing. We provide a description of the sub-corpus, informative statistics about data-composition and we evaluate an automatic NER tool on the newly created resource.', 'externalIds': {'MAG': 2775451169.0, 'DBLP': 'conf/ranlp/Mitrofan17', 'DOI': '10.26615/978-954-452-049-6_066', 'CorpusId': 13132097.0, 'ACL': 'R17-1066'}, 'label': 1}\n",
      "{'paperId': 'e1162e8705fee5cd9e483d2245b713ca4f8db5b2', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/e1162e8705fee5cd9e483d2245b713ca4f8db5b2', 'title': 'Biomedical Named Entity Recognition based on Long and Short Term Memory Model', 'abstract': 'In view of the problem of biological entity recognition, this paper proposes an improved Long Short-Term Memory (LSTM) recognition method based on the improved bidirectional long and short term memory model. First of all, based on the improvement of re constructed corpus is used to solve the imbalance problem in the distribution of biological entities data sampling algorithm; then, by coupling the forgotten and the input threshold combination to improve the LSTM memory unit, update method to choose the reasonable use of forgotten door control unit state in memory left information improve the biological entity recognition effect. Finally, the test was carried out on the JNLPBA 2004 corpus, and the accuracy rate of 79.7% and the value of 74.1% of the F were obtained. Experimental results show that the proposed recognition method not only has better generalization ability without external assistance, but also effectively improves the recognition effect of biological entities.', 'externalIds': {'MAG': 2783390047.0, 'DOI': '10.2991/MCEI-17.2017.113', 'CorpusId': 116118249.0}, 'label': 1}\n",
      "{'paperId': '73c43c7bbf9336228fe2cb1fcb53db5eaa561958', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/73c43c7bbf9336228fe2cb1fcb53db5eaa561958', 'title': 'A Refer-and-Ground Multimodal Large Language Model for Biomedicine', 'abstract': 'With the rapid development of multimodal large language models (MLLMs), especially their capabilities in visual chat through refer and ground functionalities, their significance is increasingly recognized. However, the biomedical field currently exhibits a substantial gap in this area, primarily due to the absence of a dedicated refer and ground dataset for biomedical images. To address this challenge, we devised the Med-GRIT-270k dataset. It comprises 270k question-and-answer pairs and spans eight distinct medical imaging modalities. Most importantly, it is the first dedicated to the biomedical domain and integrating refer and ground conversations. The key idea is to sample large-scale biomedical image-mask pairs from medical segmentation datasets and generate instruction datasets from text using chatGPT. Additionally, we introduce a Refer-and-Ground Multimodal Large Language Model for Biomedicine (BiRD) by using this dataset and multi-task instruction learning. Extensive experiments have corroborated the efficacy of the Med-GRIT-270k dataset and the multi-modal, fine-grained interactive capabilities of the BiRD model. This holds significant reference value for the exploration and development of intelligent biomedical assistants.', 'externalIds': {'CorpusId': 270737584.0, 'ArXiv': 2406.18146}, 'label': 1}\n",
      "{'paperId': 'd1012b2c4a9455adb0e3b90d291187b1ff0b0d05', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/d1012b2c4a9455adb0e3b90d291187b1ff0b0d05', 'title': 'Automatic Extraction of Social Determinants of Health from Medical Notes of Chronic Lower Back Pain Patients', 'abstract': 'Background. Adverse social determinants of health (SDoH), or social risk factors, such as food insecurity and housing instability, are known to contribute to poor health outcomes and inequities. Our ability to study these linkages is limited because SDoH information is more frequently documented in free-text clinical notes than structured data fields. To overcome this challenge, there is a growing push to develop techniques for automated extraction of SDoH. In this study, we explored natural language processing (NLP) and inference (NLI) methods to extract SDoH information from clinical notes of patients with chronic low back pain (cLBP), to enhance future analyses of the associations between SDoH and low back pain outcomes and disparities. Methods. Clinical notes (n=1,576) for patients with cLBP (n=386) were annotated for seven SDoH domains: housing, food, transportation, finances, insurance coverage, marital and partnership status, and other social support, resulting in 626 notes with at least one annotated entity for 364 patients. We additionally labelled pain scores, depression, and anxiety. We used a two-tier taxonomy with these 10 first-level ontological classes and 68 second-level ontological classes. We developed and validated extraction systems based on both rule-based and machine learning approaches. As a rule-based approach, we iteratively configured a clinical Text Analysis and Knowledge Extraction System (cTAKES) system. We trained two machine learning models (based on convolutional neural network (CNN) and RoBERTa transformer), and a hybrid system combining pattern matching and bag-of-words models. Additionally, we evaluated a RoBERTa based entailment model as an alternative technique of SDoH detection in clinical texts. We used a model previously trained on general domain data without additional training on our dataset. Results. Four annotators achieved high agreement (average kappa=95%, F1=91.20%). Annotation frequency varied significantly dependent on note type. By tuning cTAKES, we achieved a performance of F1=47.11% for first-level classes. For most classes, the machine learning RoBERTa-based NER model performed better (first-level F1=84.35%) than other models within the internal test dataset. The hybrid system on average performed slightly worse than the RoBERTa NER model (first-level F1=80.27%), matching or outperforming the former in terms of recall. Using an out-of-the-box entailment model, we detected many but not all challenging wordings missed by other models, reaching an average F1 of 76.04%, while matching and outperforming the tested NER models in several classes. Still, the entailment model may be sensitive to hypothesis wording and may require further fine tuning. Conclusion. This study developed a corpus of annotated clinical notes covering a broad spectrum of SDoH classes. This corpus provides a basis for training machine learning models and serves as a benchmark for predictive models for named entity recognition for SDoH and knowledge extraction from clinical texts.', 'externalIds': {'DBLP': 'journals/jamia/LituievLPAMP23', 'DOI': '10.1101/2022.03.04.22271541', 'CorpusId': 247291428.0, 'PubMed': 37080559.0}, 'label': 1}\n",
      "{'paperId': '576518a9b2d8ec6397179ef7e2c269f7c194a09b', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/576518a9b2d8ec6397179ef7e2c269f7c194a09b', 'title': 'Medical Name Entity Recognition Based on Lexical Enhancement and Global Pointer', 'abstract': \"—Named entity recognition (NER) in biological sources, also called medical named entity recognition (MNER), attempts to identify and categorize medical terminology in electronic records. Deep neural networks have recently demonstrated substantial effectiveness in MNER. However, Chinese MNER has issues that cannot use lexical information and involve nested entities. To address these problems, we propose a model which can handle both nested and non-nested entities. The model uses a simple lexical enhancement method for merging lexical information into each character's vector representation, and then uses the Global Pointer approach for entity recognition. Furthermore, we retrain a pre-trained model with a Chinese medical corpus to incorporate medical knowledge, resulting in F1 score of 68.13% on the nested dataset CMeEE, 95.56% on the non-nested dataset CCKS2017, 85.89% on CCKS2019, and 92.08% on CCKS2020. These data demonstrate the efficacy of our proposed model.\", 'externalIds': {'DOI': '10.14569/ijacsa.2023.0140369', 'CorpusId': 257976121.0}, 'label': 1}\n",
      "{'paperId': '9ffff04ca3f8d6f3e2a12d70ca524578c8e4bde7', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/9ffff04ca3f8d6f3e2a12d70ca524578c8e4bde7', 'title': 'Biomedical event trigger detection based on convolutional neural network', 'abstract': 'Event trigger detection, which plays a key role in biomedical event extraction, has attracted significant attention recently. However, most approaches are based on statistical models, much relying on complex hand-designed features. In this paper, we utilise the ability of Convolutional Neural Network CNN for addressing higher-level features automatically to explore correlations between a trigger and an event type. We only keep one candidate trigger along with N-words around it and entity mention features as a raw input, giving up complex input with hand-designed features that derived from currently existed Natural Language Processing NLP tools. Our experiments on Multi-Level Event Extraction MLEE corpus showed that the method achieved a higher F-score of 78.67% compared to the state-of-the-art approaches. The results demonstrate that the proposed method is effective for event trigger detection.', 'externalIds': {'MAG': 2469171125.0, 'DBLP': 'journals/ijdmb/WangLALY16', 'DOI': '10.1504/IJDMB.2016.077067', 'CorpusId': 3600343.0}, 'label': 1}\n",
      "{'paperId': 'c82c76bb8ad855b032d3479bf0492d3753493307', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/c82c76bb8ad855b032d3479bf0492d3753493307', 'title': 'CRF based Bio-Medical Named Entity Recognition', 'abstract': \"Named entity recognizer's main task is Information Extraction (IE) from non-structured text, such as newspaper articles, magazines, online data, social media etc. It recognizes information units like name of the person, organization and location and numeric expressions including time, date. As the biomedical knowledge base is expanding at an increasing rate, there is a rising need for effective natural language processing tools to manage this huge biomedical data. In recent years, much attention has been focused on the problem of recognizing gene, protein and other biomedical entities mentions in biomedical abstracts. Thus, we propose to create a Bio-medical named entity recognizer which is trained for the terms we want to recognize. The main approach is to find the terms such as DNA, RNA, cell type, cell line, protein and other bio medical terms. In this paper we propose a system for predicting these terms from a bio medical running text using Machine learning algorithm. After training the data on huge annotated corpus, the algorithm is trained enough to predict terms from a plain running test. Machine Learning algorithm used in this paper, Conditional Random Fields is a class of statistical modeling used for pattern recognition and for structured prediction\", 'externalIds': {'MAG': 2901060953.0, 'CorpusId': 70165694.0}, 'label': 1}\n",
      "{'paperId': '2d8b8e023d2b2dbb42671de91501c5e78f62081c', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/2d8b8e023d2b2dbb42671de91501c5e78f62081c', 'title': 'COEXPEDIA: exploring biomedical hypotheses via co-expressions associated with medical subject headings (MeSH)', 'abstract': 'The use of high-throughput array and sequencing technologies has produced unprecedented amounts of gene expression data in central public depositories, including the Gene Expression Omnibus (GEO). The immense amount of expression data in GEO provides both vast research opportunities and data analysis challenges. Co-expression analysis of high-dimensional expression data has proven effective for the study of gene functions, and several co-expression databases have been developed. Here, we present a new co-expression database, COEXPEDIA (www.coexpedia.org), which is distinctive from other co-expression databases in three aspects: (i) it contains only co-functional co-expressions that passed a rigorous statistical assessment for functional association, (ii) the co-expressions were inferred from individual studies, each of which was designed to investigate gene functions with respect to a particular biomedical context such as a disease and (iii) the co-expressions are associated with medical subject headings (MeSH) that provide biomedical information for anatomical, disease, and chemical relevance. COEXPEDIA currently contains approximately eight million co-expressions inferred from 384 and 248 GEO series for humans and mice, respectively. We describe how these MeSH-associated co-expressions enable the identification of diseases and drugs previously unknown to be related to a gene or a gene group of interest.', 'externalIds': {'MAG': 2526346366.0, 'DBLP': 'journals/nar/YangKHKKSL17', 'PubMedCentral': 5210615.0, 'DOI': '10.1093/nar/gkw868', 'CorpusId': 17826978.0, 'PubMed': 27679477.0}, 'label': 0}\n",
      "{'paperId': '9b18fbe281496ad72bdd18e0a5883d235ebdfd87', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/9b18fbe281496ad72bdd18e0a5883d235ebdfd87', 'title': 'Biolink Model: A universal schema for knowledge graphs in clinical, biomedical, and translational science', 'abstract': 'Within clinical, biomedical, and translational science, an increasing number of projects are adopting graphs for knowledge representation. Graph‐based data models elucidate the interconnectedness among core biomedical concepts, enable data structures to be easily updated, and support intuitive queries, visualizations, and inference algorithms. However, knowledge discovery across these “knowledge graphs” (KGs) has remained difficult. Data set heterogeneity and complexity; the proliferation of ad hoc data formats; poor compliance with guidelines on findability, accessibility, interoperability, and reusability; and, in particular, the lack of a universally accepted, open‐access model for standardization across biomedical KGs has left the task of reconciling data sources to downstream consumers. Biolink Model is an open‐source data model that can be used to formalize the relationships between data structures in translational science. It incorporates object‐oriented classification and graph‐oriented features. The core of the model is a set of hierarchical, interconnected classes (or categories) and relationships between them (or predicates) representing biomedical entities such as gene, disease, chemical, anatomic structure, and phenotype. The model provides class and edge attributes and associations that guide how entities should relate to one another. Here, we highlight the need for a standardized data model for KGs, describe Biolink Model, and compare it with other models. We demonstrate the utility of Biolink Model in various initiatives, including the Biomedical Data Translator Consortium and the Monarch Initiative, and show how it has supported easier integration and interoperability of biomedical KGs, bringing together knowledge from multiple sources and helping to realize the goals of translational science.', 'externalIds': {'DBLP': 'journals/corr/abs-2203-13906', 'PubMedCentral': 9372416.0, 'DOI': '10.1111/cts.13302', 'CorpusId': 247762142.0, 'PubMed': 36125173.0, 'ArXiv': 2203.13906}, 'label': 1}\n",
      "{'paperId': 'dfeb612917936eaf1aaf80e04a38a54cb78af6fd', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/dfeb612917936eaf1aaf80e04a38a54cb78af6fd', 'title': 'NEMO: Extraction and normalization of organization names from PubMed affiliation strings', 'abstract': 'Background. We are witnessing an exponential increase in biomedical research citations in PubMed. However, translating biomedical discoveries into practical treatments is estimated to take around 17 years, according to the 2000 Yearbook of Medical Informatics, and much information is lost during this transition. Pharmaceutical companies spend huge sums to identify opinion leaders and centers of excellence. Conventional methods such as literature search, survey, observation, self-identification, expert opinion, and sociometry not only need much human effort, but are also noncomprehensive. Such huge delays and costs can be reduced by “connecting those who produce the knowledge with those who apply it”. A humble step in this direction is large scale discovery of persons and organizations involved in specific areas of research. This can be achieved by automatically extracting and disambiguating author names and affiliation strings retrieved through Medical Subject Heading (MeSH) terms and other keywords associated with articles in PubMed. In this study, we propose NEMO (Normalization Engine for Matching Organizations), a system for extracting organization names from the affiliation strings provided in PubMed abstracts, building a thesaurus (list of synonyms) of organization names, and subsequently normalizing them to a canonical organization name using the thesaurus. Results: We used a parsing process that involves multi-layered rule matching with multiple dictionaries. The normalization process involves clustering based on weighted local sequence alignment metrics to address synonymy at word level, and local learning based on finding connected components to address synonymy. The graphical user interface and java client library of NEMO are available at http://lnxnemo.sourceforge.net . Conclusion: NEMO is developed to associate each biomedical paper and its authors with a unique organization name and the geopolitical location of that organization. This system provides more accurate information about organizations than the raw affiliation strings provided in PubMed abstracts. It can be used for : a) bimodal social network analysis that evaluates the research relationships between individual researchers and their institutions; b) improving author name disambiguation; c) augmenting National Library of Medicine (NLM)’s Medical Articles Record System (MARS) system for correcting errors due to OCR on affiliation strings that are in small fonts; and d) improving PubMed citation indexing strategies (authority control) based on normalized organization name and country.', 'externalIds': {'MAG': 2099846738.0, 'PubMedCentral': 2990275.0, 'DOI': '10.5210/DISCO.V5I0.3047', 'CorpusId': 62744816.0, 'PubMed': 20922666.0, 'ArXiv': 1107.5743}, 'label': 1}\n",
      "{'paperId': '9daa039d74cc7d4fdaf140852bef235b74767512', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/9daa039d74cc7d4fdaf140852bef235b74767512', 'title': 'Clinical Flair: A Pre-Trained Language Model for Spanish Clinical Natural Language Processing', 'abstract': 'Word embeddings have been widely used in Natural Language Processing (NLP) tasks. Although these representations can capture the semantic information of words, they cannot learn the sequence-level semantics. This problem can be handled using contextual word embeddings derived from pre-trained language models, which have contributed to significant improvements in several NLP tasks. Further improvements are achieved when pre-training these models on domain-specific corpora. In this paper, we introduce Clinical Flair, a domain-specific language model trained on Spanish clinical narratives. To validate the quality of the contextual representations retrieved from our model, we tested them on four named entity recognition datasets belonging to the clinical and biomedical domains. Our experiments confirm that incorporating domain-specific embeddings into classical sequence labeling architectures improves model performance dramatically compared to general-domain embeddings, demonstrating the importance of having these resources available.', 'externalIds': {'DOI': '10.18653/v1/2022.clinicalnlp-1.9', 'CorpusId': 250390953.0, 'ACL': '2022.clinicalnlp-1.9'}, 'label': 1}\n",
      "{'paperId': 'abd3dbbcea0ba63e8e326835a60853e2ea63bb5c', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/abd3dbbcea0ba63e8e326835a60853e2ea63bb5c', 'title': 'Towards the Construction of a Gold Standard Biomedical Corpus for the Romanian Language', 'abstract': 'Gold standard corpora (GSCs) are essential for the supervised training and evaluation of systems that perform natural language processing (NLP) tasks. Currently, most of the resources used in biomedical NLP tasks are mainly in English. Little effort has been reported for other languages including Romanian and, thus, access to such language resources is poor. In this paper, we present the construction of the first morphologically and terminologically annotated biomedical corpus of the Romanian language (MoNERo), meant to serve as a gold standard for biomedical part-of-speech (POS) tagging and biomedical named entity recognition (bioNER). It contains 14,012 tokens distributed in three medical subdomains: cardiology, diabetes and endocrinology, extracted from books, journals and blogposts. In order to automatically annotate the corpus with POS tags, we used a Romanian tag set which has 715 labels, while diseases, anatomy, procedures and chemicals and drugs labels were manually annotated for bioNER with a Cohen Kappa coefficient of 92.8% and revealed the occurrence of 1877 medical named entities. The automatic annotation of the corpus has been manually checked. The corpus is publicly available and can be used to facilitate the development of NLP algorithms for the Romanian language.', 'externalIds': {'MAG': 2900954802.0, 'DBLP': 'journals/data/MitrofanMM18', 'DOI': '10.3390/DATA3040053', 'CorpusId': 70349172.0}, 'label': 1}\n",
      "{'paperId': '9cb7d559837cac8596a12881aab8bf507e105294', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/9cb7d559837cac8596a12881aab8bf507e105294', 'title': 'Analysis of a machine learning algorithm and corpus as a tool for managing the ambiguity problem of search engines', 'abstract': 'The increasing number of scientific literature on the Internet and the absence of efficient tools used for its classification, structuring and setting the relationships among the articles influence the speed of the search and the quality of the result. The usage of ontologies hierarchical structured controlled vocabularies makes it possible to process information at the semantic level, which greatly improves the search for the relevant information. However, an imprecise query statement does not eliminate the possibility of ambiguity appearance in the search results. The master thesis explores one of the possible ways to handle the ambiguity problem of search engines. The application is the concept-recognition to identify ontology concepts from text. The goal is to analyze the performance of the machine learning algorithm approach. The first step is to examine the PubMed corpus with the given training data in from of MeSH hand-annotations. By now, PubMed database contains over 20 million biomedical abstracts. Moreover, the MeSH vocabulary contains more than 25,000 biological terms. Based on the obtained results, experiments are conducted to provide input for the classification of concepts and textual labels as non-ambiguous or ambiguous. The concept recognition approach, developed by Doms (2008), annotates the PubMed articles with the Medical Subject Headings (MeSH) concept labels. The approach uses maximum entropy models to identify the ambiguous biomedical terms and distinguish their meanings. The evaluation of the algorithm performance showed high results, namely 91% f-score (precision 90%, recall 92%) with accuracy threshold value of 0.6. The evaluation was done on the training data with the optimal size of 5000 documents, which is sufficient for the good prediction ability of the classifier. The term features title, abstract and year turned out to be important for the classification process, while feature journal brings insufficient improvement to the algorithm’s performance. The negative training data – random selected articles with literal occurrence of the explored term – decreases the risk of overfitting and overestimation of the model. The share of ambiguous terms is 6.4% based on WordNet and Wikipedia results. The additional biomedical thesauri UMLS should be applied together with the used lexica to determine the ambiguity level of the biomedical terms and to correlate it with the algorithm’s performance.', 'externalIds': {'CorpusId': 15984442.0}, 'label': 0}\n",
      "{'paperId': 'f609cec915f1abf77d769817d6cd996e437ed33f', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/f609cec915f1abf77d769817d6cd996e437ed33f', 'title': 'Multi-Task Transfer Learning with Data Augmentation for Recognizing Question Entailment in the Medical Domain', 'abstract': 'Recognizing Question Entailment (RQE) is an important task for Question Answering (QA) as it infers the logical relation between two questions. Existing research efforts on this topic using multi-task transfer learning models have proven to be successful. However, the relative scarcity of labeled data has impeded the exploitation of this family of high-capacity approaches. In this paper, we propose a multi-task transfer learning-based method with data augmentation for RQE in medical QA. The proposed method first generates new training data from existing RQE examples based on contextual word embeddings and QA data. It then uses multi-task transfer learning that combines multi-task learning and language-model pre-training. Experimental evaluations performed on the RQE test set of the 2019 MEDIQA challenge show that our data augmentation method led to a substantial increase of an average of 18.5% and that the proposed RQE approach is more effective than the state-of-the-art systems.', 'externalIds': {'DBLP': 'conf/ichi/SarroutiAD21', 'DOI': '10.1109/ICHI52183.2021.00058', 'CorpusId': 238993451.0}, 'label': 1}\n",
      "{'paperId': '552ae71fb8ee3f31442cb092e0e6f23e3d56fd31', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/552ae71fb8ee3f31442cb092e0e6f23e3d56fd31', 'title': 'Deep Learning and transfer learning in Biomedical relation extraction', 'abstract': 'Biomedical literature is growing exponentially every year, making it harder for researchers to find relevant literature for their research. With this huge growth in biomedical information, the challenge of keeping up to date with new discoveries is getting extremely hard. Databases consisting of structured biomedical knowledge are manually curated and they are often unable to keep pace with the rich amount of information available in fast growing biomedical texts. To cope with this huge amount of literature, text mining and knowledge extraction methods can be very useful. Biomedical relation extraction is the task of extraction biomedical relations from biomedical text. Existing methods mostly rely on hand-crafted features, and by the lack of annotated data, the methods have inadequate performance. The existing methods are mainly applied to a single application in Healthcare, for instance focusing on Drug-Drug Interactions. In this thesis a method is proposed to extract different types of biomedical relations by joining data from existing knowledge bases to unstructured text from PubMed. By using this method, a large dataset was created that contained information about drugs and diseases and different types of relations like Treats, Causes and Interacts. Recently, Neural networks have shown to achieve better or similar performance as models that depend on hand-crafted features. With the current trend of transfer learning in NLP (BERT), neural networks can also be used without the requirement of a large annotated dataset. In this thesis, we propose several methods that are all based on embedding features and do not require any explicit feature engineering. Our experimental results show that especially the transfer learning models have very promising performance on this task. The performance of this model outperforms all of the Deep learning models that before achieved state-of-the-art performance on many biomedical NLP tasks.', 'externalIds': {'CorpusId': 221670171.0}, 'label': 1}\n",
      "{'paperId': 'e77078d5ddcaf5c76fe1c291c2b7cbc7518afc23', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/e77078d5ddcaf5c76fe1c291c2b7cbc7518afc23', 'title': 'Improving Biomedical Question Answering by Data Augmentation and Model Weighting', 'abstract': \"Biomedical Question Answering aims to extract an answer to the given question from a biomedical context. Due to the strong professionalism of specific domain, it's more difficult to build large-scale datasets for specific domain question answering. Existing methods are limited by the lack of training data, and the performance is not as good as in open-domain settings, especially degrading when facing to the adversarial sample. We try to resolve the above issues. First, effective data augmentation strategies are adopted to improve the model training, including slide window, summarization and round-trip translation. Second, we propose a model weighting strategy for the final answer prediction in biomedical domain, which combines the advantage of two models, open-domain model QANet and BioBERT pre-trained in biomedical domain data. Finally, we give adversarial training to reinforce the robustness of the model. The public biomedical dataset collected from PubMed provided by BioASQ challenge is used to evaluate our approach. The results show that the model performance has been improved significantly compared to the single model and other models participated in BioASQ challenge. It can learn richer semantic expression from data augmentation and adversarial samples, which is beneficial to solve more complex question answering problems in biomedical domain.\", 'externalIds': {'DBLP': 'journals/tcbb/DuYLZJ23', 'DOI': '10.1109/TCBB.2022.3171388', 'CorpusId': 248432501.0, 'PubMed': 35486563.0}, 'label': 1}\n",
      "{'paperId': 'c29a44e108d17c3b5097703bb41518e4ac0d71ad', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/c29a44e108d17c3b5097703bb41518e4ac0d71ad', 'title': 'Gamification for Arabic Natural Language Processing: Ideas into Practice', 'abstract': 'Gamification is a novel IT development that focuses on how to address the use of games and apply game design techniques in a non-gaming context. Recently, it has significantly attracted several researchers’ attention concerned with different fields such as education, business, and information retrieval, among other fields. Most Natural Language Processing (NLP) applications use large accurately labelled data sets to achieve good performance, but these data sets are hard to obtain. The standard method to produce labelled data has been through manual labour that demands a strong engagement and a heavy financial participation. For these reasons, gamification may offer smooth possibilities for wide improvements in this field. However, gamification by itself may not yield the widely-expected results if the incentives are not strong motivators. Further, based on a previous experience, we strongly believe that even financial incentives are not enough for the participants to increase their contributions. Therefore, we could incentivise the participants, through gamification, and through their need for language acquisition. Thus, language-based games are adopted in this project as a direct incentive and a stronger engagement to ensure the benefits for both NLP practitioners and the language learners. In this paper, we present the first Arabic project that targets all the means to promote and explore the possibilities for research and practical applications of using games and gamification for Arabic NLP. Here, we shed light over the advantages of using a gamified approach in corpus annotation, named entity recognition, and word sense disambiguation.', 'externalIds': {'MAG': 2758732737.0, 'DOI': '10.14738/TMLAI.54.3323', 'CorpusId': 64565480.0}, 'label': 0}\n",
      "{'paperId': '7dd5764a988de7f4be1fa6a6ebff85b2c8dce7b7', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/7dd5764a988de7f4be1fa6a6ebff85b2c8dce7b7', 'title': 'Insights into Analogy Completion from the Biomedical Domain', 'abstract': 'Analogy completion has been a popular task in recent years for evaluating the semantic properties of word embeddings, but the standard methodology makes a number of assumptions about analogies that do not always hold, either in recent benchmark datasets or when expanding into other domains. Through an analysis of analogies in the biomedical domain, we identify three assumptions: that of a Single Answer for any given analogy, that the pairs involved describe the Same Relationship, and that each pair is Informative with respect to the other. We propose modifying the standard methodology to relax these assumptions by allowing for multiple correct answers, reporting MAP and MRR in addition to accuracy, and using multiple example pairs. We further present BMASS, a novel dataset for evaluating linguistic regularities in biomedical embeddings, and demonstrate that the relationships described in the dataset pose significant semantic challenges to current word embedding methods.', 'externalIds': {'MAG': 2963491049.0, 'DBLP': 'conf/bionlp/Newman-GriffisL17', 'DOI': '10.18653/v1/W17-2303', 'CorpusId': 6219679.0, 'ACL': 'W17-2303', 'ArXiv': 1706.02241}, 'label': 1}\n",
      "{'paperId': 'fb0deac784854a3d1db57dbe0134911042c2b6bb', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/fb0deac784854a3d1db57dbe0134911042c2b6bb', 'title': 'Optimizing clinical interpretability of functional evidence in epilepsy-related ion channel variants', 'abstract': 'Variants in genes encoding the voltage-gated ion channels are among the most common monogenic causes of epilepsy and neurodevelopmental disorders. Functional effects of a variant are increasingly important for diagnosis and therapeutic decisions. To incorporate knowledge regarding functional consequences in formal clinical variant interpretation, we developed an approach for evaluating multiple functional measurements within the Bayesian framework of the modified ACMG/AMP guidelines. We analyzed 216 functional assessments of 191 variants in SCN1A (n=74), SCN2A (n=66), SCN3A (n=18), and SCN8A (n=33). Of 20 commonly measured biophysical parameters, the most frequent drivers of overall functional consequence were persistent current (f=0.54), voltage dependence of activation (f=0.51), and voltage dependence of fast inactivation (f=0.40) for gain-of-function and peak current (f=0.87) for loss-of-function. By comparing measurements of 23 benign variants, we determined thresholds by which published data on these four parameters confer Strong evidence of variant pathogenicity (likelihood ratio > 18.7) under the ACMG/AMP rubric. Similarly, we delineated evidence weights for the most common epilepsy-related potassium channel gene, KCNQ2, through reports of 80 pathogenic and 24 benign variants, accounting for heterozygous and homozygous experimental conditions. We collected the resulting categorization of functional data into FENICS, a biomedical ontology of 152 standardized terms for coherent annotation of electrophysiological results. Across 271 variants in SCN1A/2A/3A/8A and KCNQ2, 1,731 annotations are available in ClinVar, facilitating use of this evidence in variant classification. In summary, we introduce and apply an ACMG/AMP-calibrated framework for electrophysiological studies in epilepsy-related channelopathies to delineate the impact of functional evidence on clinical variant interpretation.', 'externalIds': {'DOI': '10.1101/2024.05.09.593343', 'CorpusId': 269791589.0}, 'label': 0}\n",
      "{'paperId': '475062da8b8e518056d0752c6a0aff2aaac3f83a', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/475062da8b8e518056d0752c6a0aff2aaac3f83a', 'title': 'Combining rule-based and embedding-based approaches to normalize textual entities with an ontology', 'abstract': 'In this paper, we propose a two-step method to normalize multi-word terms with concepts from a domain-specific ontology. Normalization is a critical step of information extraction. The method uses vector representations of terms computed with word embedding information and hierarchical information among ontology concepts. A training dataset and a first result dataset with high precision and low recall are generated by using the ToMap unsupervised normalization method. It is based on the similarities between the form of the term to normalize and the form of concept labels. Then, a projection of the space of terms towards the space of concepts is learned by globally minimizing the distances between vectors of terms and vectors of concepts. It applies multivariate linear regression using the previously generated training dataset. Finally, a distance calculation is carried out between the projections of term vectors and the concept vectors, providing a prediction of normalization by a concept for each term. This method was evaluated through the categorization task of bacterial habitats of BioNLP Shared Task 2016. Our results largely outperform all existing systems on this task, opening up very encouraging prospects.', 'externalIds': {'MAG': 2805776676.0, 'DBLP': 'conf/lrec/FerreDZN18', 'CorpusId': 21712705.0, 'ACL': 'L18-1543'}, 'label': 1}\n",
      "{'paperId': '392d50643c4dee8ffa25af9bc7f347a4df8fb580', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/392d50643c4dee8ffa25af9bc7f347a4df8fb580', 'title': 'Modeling acute lesion volume and topography for genetic analysis ( MRI-GENIE study )', 'abstract': 'The CHARGE consortium is an investigator-initiated collaboration to facilitate meta-analyses of genome-wide association studies (GWAS) and genomic analyses based on next generation sequencing (NGS), among multiple large and well-phenotyped population-based cohort studies around the world (http://www.chargeconsortium.com). Within the neuro-CHARGE working group, we are presenting an update of ongoing genomic studies on MRI-markers of cerebrovascular disease. Large population-based studies have shown that the burden of cerebrovascular disease extends far beyond that of clinical stroke. MRI-markers of cerebral small vessel disease, such as white matter hyperintensities (WMH), small subcortical brain infarcts, microbleeds, or dilated perivascular spaces, are particularly frequent in older community persons. These markers portend an increased risk of stroke, dementia, and premature death, and were shown to have a high heritability, especially WMH burden. Interestingly recent work has revealed genetic risk variants between WMH burden and stroke. To account for the major role of high blood pressure in the occurrence of WMH, we are performing a GWAS of WMH burden stratified on hypertension status, as well as a joint meta-analysis to account for gene-environment interaction with hypertension. Moreover, based on prior epidemiologic and histologic data suggesting that the pathogenesis of WMH may differ according to their location, we are running separate GWAS for periventricular and deep WMH burden. A GWAS of cerebral microbleeds is being finalized. We are also exploring the role of vascular risk factors in the occurrence of dementia by examining the relation of genetic risk scores for these factors with MRI-markers of brain aging and cerebrovascular disease. Finally, several NGS projects are being conducted to identify rare variants associated with WMH burden and lacunar brain infarcts. Additional projects are also currently being designed, including GWAS of novel MRI phenotypes, such as composite measures of cerebral small vessel disease, as well as lifetime, and epigenomic approaches. 2016.002 Modeling acute lesion volume and topography for genetic analysis (MRI-GENIE study) Ona Wu, PhD; Stefan Winzeck, MS; Steven J.T. Mocking, MS; Markus D. Schirmer, PhD; Mark J.R.J. Bouts, PhD; Elissa C. McIntosh, MA; Anne-Katrin Giese, MD; Joseph P. Broderick, MD; Jordi Jimenez-Conde, MD, PhD; Christina Jern, MD, PhD; Brett M. Kissela, MD, MS, Steven J. Kittner, MD, MPH; Dawn O. Kleindorfer, MD; Robin Lemmens, MD, PhD; Arne Lindgren, MD, PhD; James F. Meschia, MD; Braxton D. Mitchell, PhD, MPH; Jonathan Rosand, MD, MSc; Tatjana Rundek, MD, PhD; Ralph L. Sacco, MD, MS; Reinhold Schmidt, MD; Pankaj Sharma, MD, PhD; Agnieszka Slowik, MD, PhD, Vincent N.S. Thijs, MD, PhD; Daniel Woo, MD, MS, Bradford B. Worrall, MD, MSc; Natalia S. Rost, MD, MPH Athinoula A Martinos Center for Biomedical Imaging, Department of Radiology, Massachusetts General Hospital, Harvard Medical School, Charlestown; University Division of Anaesthesia, Department of Medicine, Cambridge University, UK; Department of Neurology, Massachusetts General Hospital, Harvard Medical School, Boston; Program in Medical and Population Genetics, Broad Institute of MIT and Harvard, Cambridge, MA; Department of Neurology and Rehabilitation Medicine, University of Cincinnati College of Medicine, OH; Department of Neurology, Neurovascular Research Group (NEUVAS), IMIM-Hospital del Mar (Institut Hospital del Mar d’Investigacions Mèdiques), Universitat Autonoma de Barcelona, Spain; Institute of Biomedicine, the Sahlgrenska Academy at University of Gothenburg, Sweden; Department of Neurology, University of Maryland School of Medicine and Veterans Affairs Maryland Health Care System, Baltimore; KU Leuven—University of Leuven, Department of Neurosciences, Experimental Neurology and Leuven Research Institute for Neuroscience and Disease (LIND), Leuven, Belgium; VIB, Vesalius Research Center, Laboratory of Neurobiology, University Hospitals Leuven, Department of Neurology, Belgium; Department of Clinical Sciences Lund, Neurology, Lund University; Department of Neurology and Rehabilitation Medicine, Neurology, Skåne University Hospital, Lund, Sweden; Department of Neurology, Mayo Clinic, Jacksonville, FL; Department of Medicine, University of Maryland School of Medicine, Baltimore; Geriatric Research and Education Clinical Center, Veterans Administration Medical Center, Baltimore, MD; Department of Neurology, Miller School of Medicine, University of Miami, FL; Department of Neurology, Clinical Division of Neurogeriatrics, Medical University Graz, Austria; Institute of Cardiovascular Research, Royal Holloway University of London (ICR2UL), Egham, Ashford and St Peter’s Hospitals, UK; Department of Neurology, Jagiellonian University Medical College, Krakow, Poland; Department of Neurology Austin Health, Melbourne Brain Center, Florey Institute of Neuroscience and Mental Health, Heidelberg, Australia; and Departments of Neurology and Public Health Sciences, University of Virginia, Charlottesville, VA. OBJECTIVE: To investigate the relationship between acute ischemic lesion location and volumes and genetics with admission stroke severity and long-term outcome, an automated lesion segmentation algorithm was developed. BACKGROUND: One of the primary goals of the MRI-Genetics Interface Exploration study (MRI-GENIE) is to develop clinical MRI scan analysis tools that will advance genetic discovery in stroke. To incorporate lesion volumes and topology into stroke genetic analysis studies, thousands of datasets from multiple centers will need to be analyzed. We therefore developed an automated lesion segmentation algorithm. DESIGN/METHODS: Lesion segmentation was performed by randomized classification forests (RF) on a voxel-wise basis. 9 3 9 3 1 patches of the input, consisting of the apparent diffusion coefficient map, isotropic diffusionweighted image, and non-diffusion-weighted image, resulted in 243 features. Optimal patch size was determined in a 5-fold cross-validation with 50 patients. The final segmentation model was trained on 67 patients and applied to 1,197 independent datasets from the Stroke Genetics Network (SiGN) Repository. The RF outputs were thresholded then further processed using post-hoc regional analyses. All images were spatially normalized to the MNI 1 mm atlas using non-linear co-registration (MNI Autoreg). RESULTS: Median (IQR) acute DWI volumes were 4.3 (0–22.0) cm. The figure shows the incidence map of lesions for all 1,197 subjects (maximum incidence was 138). The frequency of stroke lesions was comparable for both left and right hemispheres and consistent with previously published studies involving single centers. CONCLUSIONS: Automatic acute DWI lesion segmentation is feasible. Studies investigating the association between lesion topography and lesion volumes with genetics, admission stroke severity scores and long term functional outcomes in large multi-center datasets are therefore realistic. Study Supported By: NIH-Neurological Disorders and Stroke (MRI-GENIE study: R01NS086905—PI N.S. Rost; K23NS064052, R01NS082285—N.S. Rost; SiGN: U01 NS069208—J. Rosand, S.J. Kittner; R01NS063925, R01NS086905, R01NS059775, R01NS082285, P50NS051343, U01NS069208—O. Wu). Disclosure: The authors declare no conflict of interest. 2016.003 Genome-wide association studies of disease severity in neurocritical care: Interim analysis of spontaneous intracerebral hemorrhage volume Guido J. Falcone; Daniel Woo; Miriam R. Raffeld; Alessandro Biffi; Chia-Ling Phuah; Joshua N. Goldstein; David L. Tirschwell; Magdy Selim; Scott L. Silliman; Bradford B. Worrall; James F. Meschia; Jordi Jimenez-Conde; Arne Lindgren; Christopher D. Anderson; Jonathan Rosand Center for Human Genetic Research, Massachusetts General Hospital, Boston; Department of Neurology, University of Cincinnati College of Medicine, OH; Department of Emergency Medicine, Massachusetts General Hospital, Boston; Stroke Center, Harborview Medical Center, University of Washington, Seattle; Department of Neurology, Stroke Division, Beth Israel Deaconess Medical Center, Boston, MA; Department of Neurology, University of Florida College of Medicine, Jacksonville; 2016.002: Modeling acute lesion volume and topography for genetic analysis (MRI-GENIE study) 2016.003: Genome-wide association studies of disease severity in neurocritical care: Interim analysis of spontaneous intracerebral hemorrhage volume S2 Neurology: Genetics ISGC 2016 Abstracts a 2017 American Academy of Neurology. Unauthorized reproduction of this article is prohibited. Department of Neurology and Public Health Sciences, University of Virginia Health System, Charlottesville, Department of Neurology, Mayo Clinic, Jacksonville, FL; Neurovascular Research Unit, Department of Neurology, IMIM (Institut Hospital del Mar d’Investigacions Mèdiques), Universitat Autonoma de Barcelona, Spain; Department of Neurology, Skåne University Hospital, Lund, Sweden. OBJECTIVE: We report an interim analysis of the first GWAS of ICH volume undertaken by the International Stroke Genetics Consortium. BACKGROUND: Spontaneous intracerebral hemorrhage (ICH) carries a grim prognosis and has limited treatment options. ICH volume remains the most potent predictor of outcome. Genome-wide association studies (GWAS) constitute a powerful technique for identifying novel biological pathways and drug targets for human disease. DESIGN/METHODS: Two-stage (discovery and replication) cohort study that included subjects from a multicenter US study (discovery) and 2 European studies (replication). We utilized admission head CT to calculate hematoma volume and classify ICH cases as lobar or non-lobar. After genotyping (Illumina 610 platform) and imputation, 7 million genetic variants were available for testing. Association testing was carried out using linear regression. Signals with p , 5 3 10 were pursued in repli', 'externalIds': {'CorpusId': 207790941.0}, 'label': 0}\n",
      "{'paperId': 'b631c7fa8cd3fd1939c43b01065fff924c2aa57c', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/b631c7fa8cd3fd1939c43b01065fff924c2aa57c', 'title': 'Learning paraphrases from text', 'abstract': 'Paraphrases are textual expressions that convey the same meaning using different surface forms. Capturing the variability of language, they play an important role in many natural language applications including question answering, machine translation, and multi-document summarization. In linguistics, paraphrases are characterized by approximate conceptual equivalence. Since no automated semantic interpretation systems available today can identify conceptual equivalence, paraphrases are difficult to acquire without human effort. The aim of this thesis is to develop methods for automatically acquiring and filtering phrase-level paraphrases using a monolingual corpus.', 'externalIds': {'MAG': 118736248.0, 'CorpusId': 54151930.0}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Noting that the real world uses far more quasi-paraphrases than the logically equivalent ones, we first present a general typology of quasi-paraphrases together with their relative frequencies. To our knowledge the first one ever. We then present a method for automatically learning the contexts in which quasi-paraphrases obtained from a corpus are mutually replaceable. For this purpose, we use Relational Selectional Preferences (RSPs) that specify the selectional preferences of the syntactic arguments of phrases (usually verbs or verb phrases). From the RSPs of individual phrases, we learn Inferential Selectional Preferences (ISPs), which specify the selectional preferences of a pair of quasi-paraphrases. We then apply the learned ISPs to the task of filtering incorrect inferences. We achieve an accuracy of 59% for this task, which is a statistically significant improvement over several baselines.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Knowing that quasi-paraphrases are often inexact because they contain semantic implications which can be directional, we present an algorithm called LEDIR to learn the directionality of quasi-paraphrases using the (syntactic argument based) RSPs for phrases. Learning directionality allows us to differentiate the strong (bidirectional) from the weak (unidirectional) paraphrases. We show that the directionality of the quasi-paraphrases can be learned with 48% accuracy. This is again a significant improvement over several baselines.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'In learning the context and directionality of quasi-paraphrases, we have encountered the need for semantic concepts: Both RSPs and ISPs are defined in terms of semantic concepts. For learning these semantic concepts from text, we use a semi-supervised clustering algorithm HMRF-KMeans. We show that compared to the commonly used unsupervised clustering approach, this algorithm performs much better. Applying the semi-supervised clustering algorithm to the task of discovering verb classes, we obtain precision scores of 54% and 37% and corresponding recall scores of 53% and 38% for our two test sets. These are large improvements over the baseline.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'We next investigate the task of learning surface paraphrases, i.e., paraphrases that do not require the use of a syntactic interpretation. Since one would need a very large corpus to find enough surface variations, we start with a really large but unprocessed corpus of 150GB (25 billion words) obtained from Google News. We rely only on distributional similarity to learn paraphrases from this corpus. To scale paraphrase acquisition to this large corpus, we apply only simple POS tagging and randomized algorithms. We build a paraphrase resource containing more than 2.5 million phrases. In the resource, 71% of the quasi-paraphrases are correct.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Having learned the surface paraphrases, we investigate their utility for the task of relation extraction. We show that these paraphrases can be used to learn surface patterns for relation extraction. The extraction patterns obtained by using the paraphrases are not only more precise (more than 80% precision for both our test relations), but also have higher relative recall compared to a state-of-the-art baseline. This method also delivers more extraction patterns than the baseline. Applying the learned extraction patterns to the task of extracting relation instances from a test corpus, our system takes a hit in relative recall as compared to the baseline, but results in a much higher precision (more than 85% precision for both our test relations).', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Finally, we use paraphrases to learn patterns for domain-specific information extraction (IE). Since the paraphrases are learned from a large broad-coverage corpus, our patterns are domain-independent, making the task of moving to new domains very easy. We empirically show that patterns learned using (broad-coverage corpus based) paraphrases are comparable in performance to several state-of-the-art domain-specific IE engines.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Thus, in this thesis we define quasi-paraphrases, present methods to learn them from a corpus, and show that quasi-paraphrases are useful for information extraction.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': '462d21da3094062ad80972aa40cc8388789cf309', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/462d21da3094062ad80972aa40cc8388789cf309', 'title': 'VTCC-NLP at NL4Opt competition subtask 1: An Ensemble Pre-trained language models for Named Entity Recognition', 'abstract': 'We propose a combined three pre-trained language models (XLM-R, BART, and DeBERTa-V3) as an empower of contextualized embedding for named entity recognition. Our model achieves a 92.9% F1 score on the test set and ranks 5th on the leaderboard at NL4Opt competition subtask 1.', 'externalIds': {'DBLP': 'journals/corr/abs-2212-07219', 'DOI': '10.48550/arXiv.2212.07219', 'CorpusId': 254636238.0, 'ArXiv': 2212.07219}, 'label': 0}\n",
      "{'paperId': '18ae13b6982a332c335d98766347fa3b9fe7aa37', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/18ae13b6982a332c335d98766347fa3b9fe7aa37', 'title': \"Wanting what we don't want to want: Representing addiction in interoperable bio-ontologies\", 'abstract': 'Ontologies are being developed throughout the biomedical sciences to address standardization, integration, classification and reasoning needs against the background of an increasingly data-driven research paradigm. In particular, ontologies facilitate the translation of basic research into benefits for the patient by making research results more discoverable and by facilitating knowledge transfer across disciplinary boundaries. Addressing and adequately treating mental illness is one of our most pressing public health challenges. Primary research across multiple disciplines such as psychology, psychiatry, biology, neuroscience and pharmacology needs to be integrated in order to promote a more comprehensive understanding of underlying processes and mechanisms, and this need for integration only becomes more pressing with our increase in understanding of differences among individuals and populations at the molecular level concerning susceptibility to specific illnesses. Substance addiction is a particularly relevant public health challenge in the developed world, affecting a substantial percentage of the population, often co-morbid with other illnesses such as mood disorders. Currently, however, there is no straightforward automated method to combine data of relevance to the study of substance addiction across multiple disciplines and populations. In this contribution, we describe a framework of interlinked, interoperable bio-ontologies for the annotation of primary research data relating to substance addiction, and discuss how this framework enables easy integration of results across disciplinary boundaries. We describe entities and relationships relevant for the description of addiction within the Mental Functioning Ontology, Chemical Entities of Biological Interest Ontology, Protein Ontology, Gene Ontology and the Neuroscience Information Framework ontologies.', 'externalIds': {'MAG': 2221993090.0, 'DBLP': 'conf/icbo/HastingsNCMS12', 'CorpusId': 1535210.0}, 'label': 0}\n",
      "{'paperId': 'ac1869e5648e4e6d68dd2b7632079107b49d316b', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/ac1869e5648e4e6d68dd2b7632079107b49d316b', 'title': 'Learning to Infer Entities, Properties and their Relations from Clinical Conversations', 'abstract': 'Recently we proposed the Span Attribute Tagging (SAT) Model to infer clinical entities (e.g., symptoms) and their properties (e.g., duration). It tackles the challenge of large label space and limited training data using a hierarchical two-stage approach that identifies the span of interest in a tagging step and assigns labels to the span in a classification step. We extend the SAT model to jointly infer not only entities and their properties but also relations between them. Most relation extraction models restrict inferring relations between tokens within a few neighboring sentences, mainly to avoid high computational complexity. In contrast, our proposed Relation-SAT (R-SAT) model is computationally efficient and can infer relations over the entire conversation, spanning an average duration of 10 minutes. We evaluate our model on a corpus of clinical conversations. When the entities are given, the R-SAT outperforms baselines in identifying relations between symptoms and their properties by about 32% (0.82 vs 0.62 F-score) and by about 50% (0.60 vs 0.41 F-score) on medications and their properties. On the more difficult task of jointly inferring entities and relations, the R-SAT model achieves a performance of 0.34 and 0.45 for symptoms and medications respectively, which is significantly better than 0.18 and 0.35 for the baseline model. The contributions of different components of the model are quantified using ablation analysis.', 'externalIds': {'MAG': 2970315338.0, 'DBLP': 'journals/corr/abs-1908-11536', 'DOI': '10.18653/v1/D19-1503', 'CorpusId': 201698393.0, 'ACL': 'D19-1503', 'ArXiv': 1908.11536}, 'label': 1}\n",
      "{'paperId': '969ae2aef666cafb1c4eed2707d6206caacfd88e', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/969ae2aef666cafb1c4eed2707d6206caacfd88e', 'title': 'Supporting Medical Relation Extraction via Causality-Pruned Semantic Dependency Forest', 'abstract': 'Medical Relation Extraction (MRE) task aims to extract relations between entities in medical texts. Traditional relation extraction methods achieve impressive success by exploring the syntactic information, e.g., dependency tree. However, the quality of the 1-best dependency tree for medical texts produced by an out-of-domain parser is relatively limited so that the performance of medical relation extraction method may degenerate. To this end, we propose a method to jointly model semantic and syntactic information from medical texts based on causal explanation theory. We generate dependency forests consisting of the semantic-embedded 1-best dependency tree. Then, a task-specific causal explainer is adopted to prune the dependency forests, which are further fed into a designed graph convolutional network to learn the corresponding representation for downstream task. Empirically, the various comparisons on benchmark medical datasets demonstrate the effectiveness of our model.', 'externalIds': {'DBLP': 'journals/corr/abs-2208-13472', 'DOI': '10.48550/arXiv.2208.13472', 'CorpusId': 251903055.0, 'ACL': '2022.coling-1.216', 'ArXiv': 2208.13472}, 'label': 1}\n",
      "{'paperId': '6dd3a440883d9e719ecaacf33c8f2833e8be3298', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/6dd3a440883d9e719ecaacf33c8f2833e8be3298', 'title': 'Sentence Similarity Measures Revisited: Ranking Sentences in PubMed Documents', 'abstract': 'While various measures are available for computing sentence similarity, few studies have examined their performance in the biomedical domain. Motivated by BIOSSES, an earlier study for biomedical sentence similarity, we here explore the effectiveness of multiple similarity measures via sentence ranking in PubMed abstracts. Ranking sentences is a crucial component for text summarization and biocuration evidence attribution. Applied to the \"natural language processing\" and \"computational biology\" datasets, our experimental results show that the off-the-shelf measures for sentence similarity may not be effective for ranking sentences. Neither lexical nor semantic measures provided more than 0.60 NDCG scores at the top 1 ranked document. It necessitates the development of a large-scale benchmark set and more effective measures.', 'externalIds': {'MAG': 2888557427.0, 'DBLP': 'conf/bcb/ChenKWL18', 'DOI': '10.1145/3233547.3233640', 'CorpusId': 52098134.0}, 'label': 1}\n",
      "{'paperId': '0e4bae65c81c278108c259f2e242ac14826cdfac', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/0e4bae65c81c278108c259f2e242ac14826cdfac', 'title': 'Chronic Myeloid Leukemia and BCR/ABL Signal Pathway Are Not Associated with AKT1 Pleckstrin Homology Domain(E17K) Mutations.', 'abstract': 'Abstract 4262 AKT1 E17K mutation was recently found in several human cancers. PI3K/AKT is one of major downstream signal pathways of BCR-ABL oncogene and essential for CML leukemogenesis and IM resistance. More recently, it has been shown that increased PI3K/AKT activity in CML contributes to the development of drug resistance of malignant cells and combination of PI3K/AKT pathway inhibitor and rapamycin can efficiently kill imatinib-resistant BCR-ABL -expressing cells, highlighting the potential of PI3K/AKT as the new targets for CML therapy. Considering the central role of AKT in CML, we performed a screening study to investigate the possible role of AKT1 E17K mutation in CML in the Chinese population. To study the frequency of AKT1 E17K mutation in CML patients in Chinese population as well as its possible relation to IM sensitivity, we recruited 86 patients with CML revealed the presence of Philadelphia chromosome at diagnosis. At molecular level, B2a2, B3a2, B2a3 and B3a3 were identified by RT-PCR in 41,43,1 and 1 cases, respectively. Molecular response to IM was evaluated by real-time PCR at 6 months and 12 months after IM administration. The CCR, MMR and CMR were achieved in 74, 39 and 27 cases, respectively. No AKT1 E17K mutation was found in all patients. We also studied the AKT1 E17K genotype in 7 CML patients at blast stage. The additional genetic abnormalities were summarized. For these patients, CD34+ leukemic cells were purified by FACS from PBMNCs before DNA extraction. Again, we failed to detect any AKT1 E17K mutant in this group of patients. Conclusion No mutation was found in all patients with different phases, genotypes and IM responses. The results indicated that the acquisition of AKT1 E17K mutation should not be the major event in IM resistance or CML blasts. Disclosures: No relevant conflicts of interest to declare.', 'externalIds': {'MAG': 2571404772.0, 'DOI': '10.1182/BLOOD.V114.22.4262.4262', 'CorpusId': 208327555.0}, 'label': 0}\n",
      "{'paperId': '69e74cd2e97a5dd4c1d48fca79aed9a770f72acd', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/69e74cd2e97a5dd4c1d48fca79aed9a770f72acd', 'title': 'Relation extraction from biomedical text', 'abstract': 'In this thesis, we study the extraction of biomedical relations specifically, the extraction of bacterial protein subcellular localizations (BPLs), from abstracts of biomedical scientific articles. A BPL indicates where the protein is located in the bacterium. The extraction of BPLs provides a valuable clue to the biological function of the protein and helps to identify suitable drug, vaccine and diagnostic targets. The work is motivated by our collaboration with researchers in molecular biology, with the goal of automatically extracting BPLs from text to expand their BPL database.', 'externalIds': {'MAG': 26197850.0, 'CorpusId': 59780293.0}, 'label': 1}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'We first introduce a Biomedical Information Retrieval (IR) system, which expands synonyms from a set of biomedical ontology sources and applies a boosting algorithm that captures natural language sub-structures embedded in the text to re-rank retrieved documents. Experiments show that the boosting algorithm works well in cases where the conventional IR system performs poorly.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Our research on the BPL extraction focuses on two learning perspectives: generative and discriminative learning. We propose a three-tier system that integrates a generative model, a discriminative model and a graph-based model to extract BPLs from MEDLINE abstracts. The generative model integrates syntactic features and domain-specific semantic features on the parse tree for a sentence. The model is capable of identifying biomedical named-entities and relations simultaneously from a large set of noisy data and exhibits a significant improvement on the overall performance against a supervised alternative.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'We also introduce a discriminative model that applies rich syntactic features from parse trees to extract relations from single sentences. A hybrid pipelined system that integrates generative and discriminative models shows a further improvement against the generative model alone.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'Finally we implement a graph model to identify global and hidden relations from multiple sentences and to detect inconsistent predictions.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': nan, 'semanticScholarUrl': nan, 'title': nan, 'abstract': 'The study is new to the biomedical natural language processing community in terms of the specific molecular biology task and the capture of the ternary relation among bacterium, protein and location. Our key contributions also lie in learning from noisy data, integrating syntactic and semantic features to extract named-entities and relations simultaneously and establishing an annotated BPL corpus that will benefit relation extraction research.', 'externalIds': {}, 'label': 0}\n",
      "{'paperId': '8defeaf6592ad1c241fe34de368db20efafde974', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/8defeaf6592ad1c241fe34de368db20efafde974', 'title': 'Inferring Gene Regulatory Mechanisms from Microarray Data Using Latent Semantic Indexing of MEDLINE Abstracts: The role of Rel in type‐I interferon signaling', 'abstract': 'Integration of promoter sequence analysis with gene expression data has been described recently for identification of gene regulatory mechanisms. However, high throughput methods are needed to further refine the promoter elements responsible for specific regulation gene expression. Here we describe a novel integrative approach that combines gene expression profiling, promoter sequence analysis and latent semantic indexing (LSI), a variant of the vector space model of information retrieval, to infer from the biomedical literature candidate regulatory factors. Application of this method to our previous data on IFN stimulated genes (ISGs) identified Rel (also known as c‐Rel) as a candidate regulatory factor for a subset of ISGs. Chromatin immunoprecipitation (ChIP) assays confirmed that Rel directly binds to the promoter of one ISG, guanylate binding protein 2. Our results indicate that LSI‐based methods provide a unique and powerful tool to identify potentially new regulatory factors from microarray data by automatically extracting implicit information from the literature.', 'externalIds': {'MAG': 48391191.0, 'DOI': '10.1096/fasebj.20.5.A929-a', 'CorpusId': 80669351.0}, 'label': 0}\n",
      "{'paperId': '485c4f573b9f706b905948698611200687a86e4a', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/485c4f573b9f706b905948698611200687a86e4a', 'title': 'Data Representation for Learning and Information Fusion in Bioinformatics', 'abstract': 'Title of dissertation: Data Representation for Learning and Information Fusion in Bioinformatics Vinodh N. Rajapakse, Doctor of Philosophy, 2013 Dissertation directed by: Professor Wojciech Czaja Department of Mathematics This thesis deals with the rigorous application of nonlinear dimension reduction and data organization techniques to biomedical data analysis. The Laplacian Eigenmaps algorithm is representative of these methods and has been widely applied in manifold learning and related areas. While their asymptotic manifold recovery behavior has been well-characterized, the clustering properties of Laplacian embeddings with finite data are largely motivated by heuristic arguments. We develop a precise bound, characterizing cluster structure preservation under Laplacian embeddings. From this foundation, we introduce flexible and mathematically well-founded approaches for information fusion and feature representation. These methods are applied to three substantial case studies in bioinformatics, illustrating their capacity to extract scientifically valuable information from complex data. DATA REPRESENTATION FOR LEARNING AND INFORMATION FUSION IN BIOINFORMATICS', 'externalIds': {'MAG': 379127822.0, 'DBLP': 'phd/basesearch/Rajapakse13', 'CorpusId': 7061929.0}, 'label': 0}\n",
      "{'paperId': '3cf5cfd00e041b73e55dbb7329ae039d5b0ff19e', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/3cf5cfd00e041b73e55dbb7329ae039d5b0ff19e', 'title': 'Special Issue on Ontology and Innovation: Part 2 Guest Editorial Preface', 'abstract': 'Ontology organises the things that was used to consist of corpus for the real world. Ontology constructs the model of information systems in term of taxonomy in a wide range of subject areas from social science and natural science. Ontology defines a large number of objects for a wide range of applications, such as education , healthcare, medicine, engineering and manufacturing. Ontology is underpinned by the theories of formal language, classification and automata languages, and can be implemented by the natural language process, particularly involving the tools and technologies in artificial intelligence. Ontology made significant contribution to the computational science, especially in information retrieval/extraction and visualisation from the theory to practice. The challenge ahead for ontology is to prove even more useful and effective in an even broader range of application domains. It follows that ontology made this issue special. Lee and Wu developed a model and method for extracting key entities from the online social messages regarding emergent events for enhancing ontology engineering, enabling a sensible solution for prevention of similar disasters. The preliminary experimental results demonstrate that the developed system is workable, allowing for prediction of possible evolution and early warning of critical incidents with a support of dynamic entity extraction. Herrero-Zazo et al applied the drug-drug interactions ontology (DINTO) to named entity recognition and relation extraction from pharmacological texts. We use the DDI corpus , a gold-standard for the development and evaluation of IE systems in this domain, and evaluate our results in the framework of the last SemEval-2013 DDIExtraction task. Ruben Costa 1 , Celson Lima introduces a novel conceptual framework to support the creation of knowledge representations based on enriched Semantic Vectors, using the classical vector space model approach extended with ontological support. One of the primary research challenges addressed here relates to the process of formalization and representation of document contents, where most existing approaches are', 'externalIds': {'CorpusId': 18595310.0}, 'label': 0}\n",
      "{'paperId': 'fd74cacaa2a80428f352ab10af24576f56082f50', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/fd74cacaa2a80428f352ab10af24576f56082f50', 'title': 'Information Retrieval Systems Adapted to the Biomedical Domain', 'abstract': 'The terminology used in Biomedicine shows lexical peculiarities that have required the elaboration of terminological resources and information retrieval systems with specific functionalities. The main characteristics are the high rates of synonymy and homonymy, due to phenomena such as the proliferation of polysemic acronyms and their interaction with common language. Information retrieval systems in the biomedical domain use techniques oriented to the treatment of these lexical peculiarities. In this paper we review some of the techniques used in this domain, such as the application of Natural Language Processing (BioNLP), the incorporation of lexical-semantic resources, and the application of Named Entity Recognition (BioNER). Finally, we present the evaluation methods adopted to assess the suitability of these techniques for retrieving biomedical resources.', 'externalIds': {'DBLP': 'journals/corr/abs-1203-6845', 'DOI': '10.3145/epi.2010.may.04', 'CorpusId': 15688333.0, 'ArXiv': 1203.6845}, 'label': 1}\n",
      "{'paperId': '418cd8e078ed9b91b08e7915ac6753ed811053e4', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/418cd8e078ed9b91b08e7915ac6753ed811053e4', 'title': 'Cross-type Biomedical Named Entity Recognition with Deep Multi-Task Learning', 'abstract': 'Motivation State-of-the-art biomedical named entity recognition (BioNER) systems often require handcrafted features specific to each entity type, such as genes, chemicals and diseases. Although recent studies explored using neural network models for BioNER to free experts from manual feature engineering, the performance remains limited by the available training data for each entity type. Results We propose a multi-task learning framework for BioNER to collectively use the training data of different types of entities and improve the performance on each of them. In experiments on 15 benchmark BioNER datasets, our multi-task model achieves substantially better performance compared with state-of-the-art BioNER systems and baseline neural sequence labeling models. Further analysis shows that the large performance gains come from sharing character- and word-level information among relevant biomedical entities across differently labeled corpora. Availability Our source code is available at https://github.com/yuzhimanhua/lm-lstm-crf. Contact xwang174@illinois.edu, xiangren@usc.edu.', 'externalIds': {'MAG': 2963339489.0, 'DBLP': 'journals/bioinformatics/WangZRZZSLH19', 'DOI': '10.1101/256453', 'CorpusId': 4587640.0, 'PubMed': 30307536.0, 'ArXiv': 1801.09851}, 'label': 1}\n",
      "{'paperId': 'b1900a47e140b884e0a946ab2bc697b3ef229d8c', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/b1900a47e140b884e0a946ab2bc697b3ef229d8c', 'title': 'Findings of the WMT 2018 Biomedical Translation Shared Task: Evaluation on Medline test sets', 'abstract': 'Machine translation enables the automatic translation of textual documents between languages and can facilitate access to information only available in a given language for non-speakers of this language, e.g. research results presented in scientific publications. In this paper, we provide an overview of the Biomedical Translation shared task in the Workshop on Machine Translation (WMT) 2018, which specifically examined the performance of machine translation systems for biomedical texts. This year, we provided test sets of scientific publications from two sources (EDP and Medline) and for six language pairs (English with each of Chinese, French, German, Portuguese, Romanian and Spanish). We describe the development of the various test sets, the submissions that we received and the evaluations that we carried out. We obtained a total of 39 runs from six teams and some of this year’s BLEU scores were somewhat higher that last year’s, especially for teams that made use of biomedical resources or state-of-the-art MT algorithms (e.g. Transformer). Finally, our manual evaluation scored automatic translations higher than the reference translations for German and Spanish.', 'externalIds': {'MAG': 2903366149.0, 'DBLP': 'conf/wmt/NevesJNGSKV18', 'DOI': '10.18653/v1/W18-6403', 'CorpusId': 53234891.0, 'ACL': 'W18-6403'}, 'label': 1}\n",
      "{'paperId': '5e44ff0788a4e8461a15290ff68318d3502ffd50', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/5e44ff0788a4e8461a15290ff68318d3502ffd50', 'title': 'Supervised Classification for Extracting Biomedical Events', 'abstract': \"We introduce a supervised approach for extracting bio-molecular events by using linguistic features that represent the contexts of the candidate event triggers and participants. We use Support Vector Machines as our learning algorithm and train separate models for event types that are described with a single theme participant, multiple theme participants, or a theme and a cause participant. We perform experiments with linear kernel and edit-distance based kernel and report our results on the BioNLP'09 Shared Task test data set.\", 'externalIds': {'MAG': 2124283281.0, 'DBLP': 'conf/bionlp/OzgurR09', 'DOI': '10.3115/1572340.1572358', 'CorpusId': 424313.0, 'ACL': 'W09-1416'}, 'label': 1}\n",
      "{'paperId': 'dd3c5e6363d015b5fea88c969d1623e7233a325d', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/dd3c5e6363d015b5fea88c969d1623e7233a325d', 'title': 'Adversarial learning for distant supervised relation extraction', 'abstract': 'Recently, many researchers have concentrated on using neural networks to learn features for Distant Supervised Relation Extraction (DSRE). These approaches generally use a softmax classifier with cross-entropy loss, which inevitably brings the noise of artificial class NA into classification process. To address the shortcoming, the classifier with ranking loss is employed to DSRE. Uniformly randomly selecting a relation or heuristically selecting the highest score among all incorrect relations are two common methods for generating a negative class in the ranking loss function. However, the majority of the generated negative class can be easily discriminated from positive class and will contribute little towards the training. Inspired by Generative Adversarial Networks (GANs), we use a neural network as the negative class generator to assist the training of our desired model, which acts as the discriminator in GANs. Through the alternating optimization of generator and discriminator, the generator is learning to produce more and more discriminable negative classes and the discriminator has to become better as well. This framework is independent of the concrete form of generator and discriminator. In this paper, we use a two layers fully-connected neural network as the generator and the Piecewise Convolutional Neural Networks (PCNNs) as the discriminator. Experiment results show that our proposed GAN-based method is effective and performs better than state-of-the-art methods.', 'externalIds': {'MAG': 2801521191.0, 'DOI': '10.3970/CMC.2018.055.121', 'CorpusId': 54947588.0}, 'label': 0}\n",
      "{'paperId': '1d40887754d34eb93af978e411508367ef3de4ab', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/1d40887754d34eb93af978e411508367ef3de4ab', 'title': 'A Machine Learning Approach for Phenotype Name Recognition', 'abstract': 'Extracting biomedical named entities is one of the major challenges in automatic processing of biomedical literature. This paper proposes a machine learning approach for finding phenotype names in text. Features are included in a machine learning infrastructure to implement the rules found in our previously developed rule-based system. The system also uses two available resources: MetaMap and HPO. As we are not aware of any available corpus for phenotype names, a corpus has been constructed. Since manual tagging of the corpus was not possible for us, we started tagging only HPO phenotypes in the corpus and then using a semi-supervised learning method, the tagging process improved. The evaluation results (F-Score 92.25) suggest that the system achieved good performance and it outperforms the rule-based system.', 'externalIds': {'MAG': 2250670243.0, 'DBLP': 'conf/coling/KhordadMR12', 'CorpusId': 5660361.0, 'ACL': 'C12-1087'}, 'label': 0}\n",
      "{'paperId': '9c254edd38722dcedc04c1a7cdad15af25edf340', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/9c254edd38722dcedc04c1a7cdad15af25edf340', 'title': 'Calculating Prevalence of Comorbidity and Comorbidity Combinations with Diabetes in Hospital Care in Sweden Using a Health Care Record Database', 'abstract': 'Access to reliable data from electronic health records is of high importance in several key areas in patient care, biomedical research, and education. However, many of the clinical entities are negated in the patient record text. Detecting what is a negation and what is not is therefore a key to high quality text mining. In this study we used the NegEx system adapted for Swedish to investigate negated clinical entities. We applied the system to a subset of free-text entries under a heading containing the word \\x91assessment\\x92 from the Stockholm EPR corpus, containing in total 23,171,559 tokens. Specifically, the explored entities were the SNOMED CT terms having the semantic categories \\x91finding\\x92 or \\x91disorder\\x92. The study showed that the proportion of negated clinical entities was around 9%. The results thus support that negations are abundant in clinical text and hence negation detection is vital for high quality text mining in the medical domain.', 'externalIds': {'MAG': 293190842.0, 'CorpusId': 14873224.0}, 'label': 1}\n",
      "{'paperId': '0e342eacd680ee9e301a9e467e2d24b25dbcb6f7', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/0e342eacd680ee9e301a9e467e2d24b25dbcb6f7', 'title': 'Multi-dimensional classification of biomedical text: Toward automated, practical provision of high-utility text to diverse users', 'abstract': 'Motivation: Much current research in biomedical text mining is concerned with serving biologists by extracting certain information from scientific text. We note that there is no ‘average biologist’ client; different users have distinct needs. For instance, as noted in past evaluation efforts (BioCreative, TREC, KDD) database curators are often interested in sentences showing experimental evidence and methods. Conversely, lab scientists searching for known information about a protein may seek facts, typically stated with high confidence. Text-mining systems can target specific end-users and become more effective, if the system can first identify text regions rich in the type of scientific content that is of interest to the user, retrieve documents that have many such regions, and focus on fact extraction from these regions. Here, we study the ability to characterize and classify such text automatically. We have recently introduced a multi-dimensional categorization and annotation scheme, developed to be applicable to a wide variety of biomedical documents and scientific statements, while intended to support specific biomedical retrieval and extraction tasks. Results: The annotation scheme was applied to a large corpus in a controlled effort by eight independent annotators, where three individual annotators independently tagged each sentence. We then trained and tested machine learning classifiers to automatically categorize sentence fragments based on the annotation. We discuss here the issues involved in this task, and present an overview of the results. The latter strongly suggest that automatic annotation along most of the dimensions is highly feasible, and that this new framework for scientific sentence categorization is applicable in practice. Contact: shatkay@cs.queensu.ca', 'externalIds': {'MAG': 2107141268.0, 'DBLP': 'journals/bioinformatics/ShatkayPRW08', 'PubMedCentral': 2530883.0, 'DOI': '10.1093/bioinformatics/btn381', 'CorpusId': 4068646.0, 'PubMed': 18718948.0}, 'label': 1}\n",
      "{'paperId': '2413ffd74b68a12a25d497de6823874c2ea0dd74', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/2413ffd74b68a12a25d497de6823874c2ea0dd74', 'title': 'Five new things', 'abstract': 'Purpose of review To review 5 new areas in primary headache disorders, especially migraine and cluster headache. Recent findings Calcitonin gene-related peptide (CGRP) receptor antagonists (gepants—rimegepant and ubrogepant) and serotonin 5-HT1F receptor agonists (ditans—lasmiditan) have completed phase 3 clinical trials and will soon offer novel, effective, well-tolerated nonvasoconstrictor options to treat acute migraine. CGRP preventive treatment is being revolutionized after the licensing of 3 monoclonal antibodies (MABs), erenumab, fremanezumab, and galcanezumab, with eptinezumab to follow, especially designed for migraine; they are effective and well tolerated. For patients seeking a nondrug therapy, neuromodulation approaches, single-pulse transcranial magnetic stimulation, noninvasive vagus nerve stimulation (nVNS), and external trigeminal nerve stimulation, represent licensed, well-tolerated approaches to migraine treatment. For the acute treatment of episodic cluster headache, nVNS is effective, well tolerated, and licensed; nVNS is effective and well tolerated in preventive treatment of cluster headache. The CGRP MAB galcanezumab was effective and well tolerated in a placebo-controlled trial in the preventive treatment of episodic cluster headache. Sphenopalatine ganglion stimulation has been shown to be effective and well tolerated in 2 randomized sham-controlled studies on chronic cluster headache. Understanding the premonitory (prodromal) phase of migraine during which patients experience symptoms such as yawning, tiredness, cognitive dysfunction, and food cravings may help explain apparent migraine triggers in some patients, thus offering better self-management. Summary Headache medicine has made remarkable strides, particularly in understanding migraine and cluster headache in the past 5 years. For the most common reason to visit a neurologist, therapeutic advances offer patients reduced disability and neurologists a rewarding, key role in improving the lives of those with migraine and cluster headache. Primary headache disorders, such as migraine and cluster headache, are the most common reasons, for which patients seek neurologic advice, and every year affect nearly 3 billion people; thus, any new therapy would be of broad interest. It was a challenge to adopt a marmoreal attitude to a single therapeutic advance, triptans, serotonin 5-HT1B/1D receptor agonists, when they came. Thirty years later, and certainly since the last of this series of NIHR-Wellcome Trust King’s Clinical Research Facility and SLaM Biomedical Research Centre, King’s College London, UK; and Department of Neurology, University of California, San Francisco. Funding information and disclosures are provided at the end of the article. Full disclosure form information provided by the author is available with the full text of this article at Neurology.org/cp. The Article Processing Charge was funded by the Author. This is an open access article distributed under the terms of the Creative Commons Attribution License 4.0 (CC BY), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. Copyright © 2019 The Author(s). Published by Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology. 233 articles in 2011, 4 new things have happened in therapeutics alone; exciting seems a trite description when thinking about headache medicine in 2019. Because new treatments are affecting, or will affect, neurologists in 2019, I will cover them in detail. An emerging area of clinical neuroscience is the study of nonheadache phases of migraine, notably the premonitory (prodromal) and postdromal phases. They provide insights into mechanisms that can be used in clinical practice. Many other areas in the primary headache disorders have advanced in the past decade, so readers interested in pathophysiology of migraine or cluster headache, headache classification, or the genetics of headache are referred to recent reviews wherein wallahs riff. New acute therapies for migraine attacks, gepants, calcitonin gene-related peptide (CGRP) receptor antagonists, and ditans, serotonin 5-HT1F receptor agonists, offer novel approaches to the treatment. Preventive therapy targeting the CGRP pathway using monoclonal antibodies (MABs) or small molecule CGRP receptor antagonists offers a remarkable clinical advance. Neuromodulation approaches to migraine, both acute and preventive, provide nondrug options for physicians to deploy and patients to take benefit from. Being important for patients and neurologists, therapeutic developments in medicines and neuromodulation are underway for cluster headache. The therapeutic developments are framed as comments from a patient, and replies that clinicians may now make. Citations for data concerning these developments are given in table. Reformulation of triptans is covered here; certainly, more efficient delivery systems, such as a permeation enhancer for nasal sumatriptan or an adhesive dermally applied microarray for zolmitriptan, offer new avenues for medicines that are widely used and well liked. Here, newer approaches that neurologists may be less familiar with have been chosen for a more detailed study. Understanding the premonitory phase ofmigraine affords the clinician expanded dimensions in the clinical history that aid diagnosis and offer an opportunity to demonstrate to patients a deeper understanding of their presentation and disability. What can you give me for my migraine? I cannot take triptans. Gepants or Ditans? Triptans were developed based on the hypothesis that the pain of migraine was due to dilation of extracerebral cranial vessels. Although undoubtedly useful and effective in suitable patients, triptans have 3 major limitations: not all patients respond, not all patients tolerate the medicines, and for some patients with cardiovascular or cerebrovascular disease they are contraindicated. Although the neural, nonvasoconstrictor effect of triptans has been postulated for 2 decades, the vasodilator hypothesis of migraine took some time to be shown as inadequate. Readers should not consider that just anything works for migraine; there is a long list of failed approaches, including substance P/neurokinin 1 receptor antagonists, plasma protein extravasation inhibitors, and TRPV1 receptor antagonists, which offer comfort to the positive outcomes. Gepants—CGRP receptor antagonists CGRP was shown to be important for migraine in translational studies in the late 1980s. CGRP can trigger migraine, and blockade of the canonical CGRP receptor is effective in the treatment of acute migraine (table). Gepants have no active vasoconstrictor effect. Six gepants have been tested, and each was effective in the acute treatment ofmigraine. Twowere terminated during development because of hepatic concerns, which now seem firmly based on metabolites not on the CGRPmechanism. Two CGRP receptor antagonists, rimegepant and ubrogepant, have completed phase III studies. They are both effective at the primary endpoints of being free of pain for 2 hours and most bothersome symptom (MBS), as currently recommended by the US FDA. The latter endpoint is new: patients are asked to nominate which of nausea, photophobia, or phonophobia bothers them the most during the migraine and which symptom is absent for 2 hours. Interestingly, photophobia has dominated in all phase III studies as the MBS. Gepants are remarkably well tolerated with only a few percentage points or less excess of nausea or somnolence reported above placebo. There have been no cardiovascular or cerebrovascular concerns, as would be expected from the mechanism, given peptide redundancy in the CGRP class, nor have liver enzyme issues emerged. Are gepants potentially disruptive therapies? Across the studies, there is remarkable consistency in the population effect: about 20% of migraineurs are pain free at 2 hours. The population effect is smaller than triptans, or ditans, where about one-third of migraineurs are pain free at 2 hours. From an intrapatient perspective, in pain-free patients, they are just as pain free as they would be on a triptan or a ditan; they may be better off given the tolerability is improved. Moreover, given the preventive data with the CGRP pathway, both from MABs and gepants used preventively, it seems highly likely thatmedication overuse will simply not be a problem since it would seem the more often a gepant is dosed, the less migraine the patient has. Studies on gepants suggest that the dichotomous view of acute therapies vs preventive therapies for migraine is artificial because the CGRP pathway can be engaged for either purpose. Perhaps the most disruptive aspect of this new class is that biologydriven developments can be targeted at the clinical need not constrained as either acute or preventive. Preventive therapy targeting the CGRP pathway using monoclonal antibodies or small molecule CGRP receptor antagonists offer a remarkable clinical advance. 234 Neurology: Clinical Practice | Volume 9, Number 3 | June 2019 Neurology.org/CP Table Licensed or phase III completed treatments Mechanism/indication Treatment Stage', 'externalIds': {'CorpusId': 215412159.0}, 'label': 0}\n",
      "{'paperId': 'da532e39fe5e7f21224eb5f4051939bc8b82abc3', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/da532e39fe5e7f21224eb5f4051939bc8b82abc3', 'title': 'DUVEL: an active-learning annotated biomedical corpus for the recognition of oligogenic combinations', 'abstract': 'Abstract While biomedical relation extraction (bioRE) datasets have been instrumental in the development of methods to support biocuration of single variants from texts, no datasets are currently available for the extraction of digenic or even oligogenic variant relations, despite the reports in literature that epistatic effects between combinations of variants in different loci (or genes) are important to understand disease etiologies. This work presents the creation of a unique dataset of oligogenic variant combinations, geared to train tools to help in the curation of scientific literature. To overcome the hurdles associated with the number of unlabelled instances and the cost of expertise, active learning (AL) was used to optimize the annotation, thus getting assistance in finding the most informative subset of samples to label. By pre-annotating 85 full-text articles containing the relevant relations from the Oligogenic Diseases Database (OLIDA) with PubTator, text fragments featuring potential digenic variant combinations, i.e. gene–variant–gene–variant, were extracted. The resulting fragments of texts were annotated with ALAMBIC, an AL-based annotation platform. The resulting dataset, called DUVEL, is used to fine-tune four state-of-the-art biomedical language models: BiomedBERT, BiomedBERT-large, BioLinkBERT and BioM-BERT. More than 500\\u2009000 text fragments were considered for annotation, finally resulting in a dataset with 8442 fragments, 794 of them being positive instances, covering 95% of the original annotated articles. When applied to gene–variant pair detection, BiomedBERT-large achieves the highest F1 score (0.84) after fine-tuning, demonstrating significant improvement compared to the non-fine-tuned model, underlining the relevance of the DUVEL dataset. This study shows how AL may play an important role in the creation of bioRE dataset relevant for biomedical curation applications. DUVEL provides a unique biomedical corpus focusing on 4-ary relations between two genes and two variants. It is made freely available for research on GitHub and Hugging Face. Database URL: https://huggingface.co/datasets/cnachteg/duvel or https://doi.org/10.57967/hf/1571', 'externalIds': {'DBLP': 'journals/biodb/NachtegaelSCL24', 'PubMedCentral': 11131422.0, 'DOI': '10.1093/database/baae039', 'CorpusId': 270091438.0, 'PubMed': 38805753.0}, 'label': 1}\n",
      "{'paperId': '92dbb6ac991020cbea25d8f4663c38ab0d0492f8', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/92dbb6ac991020cbea25d8f4663c38ab0d0492f8', 'title': 'Automated methods for the summarization of electronic health records', 'abstract': 'Objectives This review examines work on automated summarization of electronic health record (EHR) data and in particular, individual patient record summarization. We organize the published research and highlight methodological challenges in the area of EHR summarization implementation. Target audience The target audience for this review includes researchers, designers, and informaticians who are concerned about the problem of information overload in the clinical setting as well as both users and developers of clinical summarization systems. Scope Automated summarization has been a long-studied subject in the fields of natural language processing and human–computer interaction, but the translation of summarization and visualization methods to the complexity of the clinical workflow is slow moving. We assess work in aggregating and visualizing patient information with a particular focus on methods for detecting and removing redundancy, describing temporality, determining salience, accounting for missing data, and taking advantage of encoded clinical knowledge. We identify and discuss open challenges critical to the implementation and use of robust EHR summarization systems.', 'externalIds': {'MAG': 2143514833.0, 'DBLP': 'journals/jamia/PivovarovE15', 'PubMedCentral': 4986665.0, 'DOI': '10.1093/jamia/ocv032', 'CorpusId': 1452.0, 'PubMed': 25882031.0}, 'label': 1}\n",
      "{'paperId': '94c48a1fe7ef343481c3a82a9476e3d3b910948a', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/94c48a1fe7ef343481c3a82a9476e3d3b910948a', 'title': 'DISEASES: Text mining and data integration of disease–gene associations', 'abstract': 'Text mining is a flexible technology that can be applied to numerous different tasks in biology and medicine. We present a system for extracting disease–gene associations from biomedical abstracts. The system consists of a highly efficient dictionary-based tagger for named entity recognition of human genes and diseases, which we combine with a scoring scheme that takes into account co-occurrences both within and between sentences. We show that this approach is able to extract half of all manually curated associations with a false positive rate of only 0.16%. Nonetheless, text mining should not stand alone, but be combined with other types of evidence. For this reason, we have developed the DISEASES resource, which integrates the results from text mining with manually curated disease–gene associations, cancer mutation data, and genome-wide association studies from existing databases. The DISEASES resource is accessible through a user-friendly web interface at http://diseases.jensenlab.org/, where the text-mining software and all associations are also freely available for download.', 'externalIds': {'MAG': 2053039860.0, 'DOI': '10.1101/008425', 'CorpusId': 18828604.0, 'PubMed': 25484339.0}, 'label': 1}\n",
      "{'paperId': 'c5194427b6b37c5ec0795749cfd57ffaf9d49f80', 'semanticScholarUrl': 'https://www.semanticscholar.org/paper/c5194427b6b37c5ec0795749cfd57ffaf9d49f80', 'title': 'Zero-shot Hybrid Retrieval and Reranking Models for Biomedical Literature', 'abstract': 'We describe our participating system in the document retrieval sub-task (Task B Phase A) at the 10th BioASQ challenge. We designed and implemented a zero-shot hybrid model using only synthetic training data. The model consists of two stages: retrieval and reranking. The retrieval model is a hybrid of sparse and dense retrieval models, which is an extension of our participating system at 8th BioASQ challenge. We improved the dense retrieval model with a T5-based synthetic question generation model and an iterative training strategy involving techniques to filter low-quality synthetic data. In the second stage, we proposed a hybrid reranking model, which is trained using the candidates retrieved from the first stage. We further explored whether the knowledge from the hybrid reranking model can be transferred to the dense retrieval model through distillation. Our experiments show the proposed hybrid ranking model is effective even when applied to different first-stage retrieval models. Furthermore, we explored the combination of different systems via reciprocal rank fusion and achieved additional accuracy gains. Evaluation shows that our model compares favorably with the top participating system, achieving MAP scores of 0.4696, 0.3984, 0.4586, 0.4089, 0.4065 and 0.1704 on six batches.', 'externalIds': {'DBLP': 'conf/clef/LuMH22', 'CorpusId': 251471688.0}, 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load Excel file\n",
    "df = pd.read_excel(\"test_data.xlsx\", engine='openpyxl')\n",
    "\n",
    "# Function to build nested 'externalIds' dict\n",
    "def build_external_ids(row):\n",
    "    external_keys = [\"MAG\", \"DBLP\", \"PubMedCentral\", \"DOI\", \"CorpusId\", \"PubMed\", \"ACL\", \"ArXiv\"]\n",
    "    return {\n",
    "        key: row[f\"externalIds.{key}\"] for key in external_keys if not pd.isna(row[f\"externalIds.{key}\"])\n",
    "    }\n",
    "\n",
    "# Function to map isBionlp values to labels (1 for 'Y', 0 for 'N' and 'N/A')\n",
    "def map_is_bionlp(value):\n",
    "    if value == \"Y\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Convert each row to a JSON object\n",
    "jsonl_lines = []\n",
    "for _, row in df.iterrows():\n",
    "    json_obj = {\n",
    "        \"paperId\": row[\"paperId\"],\n",
    "        \"semanticScholarUrl\": row[\"semanticScholarUrl\"],\n",
    "        \"title\": row[\"title\"],\n",
    "        \"abstract\": row[\"abstract\"],\n",
    "        \"externalIds\": build_external_ids(row),\n",
    "        \"label\": map_is_bionlp(row[\"isBionlp\"]) if \"isBionlp\" in row else 0\n",
    "    }\n",
    "    jsonl_lines.append(json_obj)\n",
    "\n",
    "# Save to .jsonl\n",
    "with open(\"test_data.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in jsonl_lines:\n",
    "        print(item)\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2195e0cd",
   "metadata": {},
   "source": [
    "## Measure Annotation Agreement \n",
    "\n",
    "We use Cohen's Kappa as the evalution matrics. \n",
    "\n",
    "Cohen's Kappa coefficient is a statistic that measures inter-rater agreement for categorical items. It is generally considered a more robust measure than simple percent agreement calculation since it takes into account the agreement occurring by chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b60175fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa Score: 0.8755832037325039\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Function to read a JSONL file and return a list of dictionaries\n",
    "def read_jsonl_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "# Read the annotated files\n",
    "merged_annotations = read_jsonl_file(\"annotations/merged_annotations.jsonl\")\n",
    "papers_annotations = read_jsonl_file(\"annotations/papers.jsonl\")\n",
    "\n",
    "# Ensure they have the same number of items\n",
    "if len(merged_annotations) != len(papers_annotations):\n",
    "    raise ValueError(\"The number of papers in the merged annotations and papers annotations files do not match.\")\n",
    "\n",
    "# Extract the labels from both sets of annotations\n",
    "merged_labels = [item['label'] for item in merged_annotations]\n",
    "papers_labels = [item['label'] for item in papers_annotations]\n",
    "\n",
    "# Calculate Cohen's Kappa score for agreement\n",
    "kappa_score = cohen_kappa_score(merged_labels, papers_labels)\n",
    "\n",
    "print(f\"Cohen's Kappa Score: {kappa_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e367f388",
   "metadata": {},
   "source": [
    "Given a Cohen's Kappa score of 0.87, it can be interpreted as follows:\n",
    "\n",
    "High Reliability: The annotations are highly consistent and reliable.\n",
    "Acceptance in Most Fields: This level of agreement is generally accepted in most fields, including highly critical ones like medical research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e857fdd",
   "metadata": {},
   "source": [
    "## Convert jsonl file to csv file \n",
    "\n",
    "To see the detail difference in our final result, we convert the jsonl file into csv for easier observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52127e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "def read_jsonl_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "def flatten(d, parent_key='', sep='.'):\n",
    "    \"\"\"\n",
    "    Flatten a nested dictionary\n",
    "    \"\"\"\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "def jsonl_to_csv(jsonl_file, csv_file):\n",
    "    data = read_jsonl_file(jsonl_file)\n",
    "\n",
    "    # Flatten each JSON object and create a set of all columns\n",
    "    flattened_data = [flatten(record) for record in data]\n",
    "    columns = set()\n",
    "    for record in flattened_data:\n",
    "        columns.update(record.keys())\n",
    "    \n",
    "    # Write to CSV\n",
    "    with open(csv_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=sorted(columns))\n",
    "        writer.writeheader()\n",
    "        for record in flattened_data:\n",
    "            writer.writerow(record)\n",
    "\n",
    "# Usage\n",
    "jsonl_file_path = 'annotations/merged_annotations.jsonl'\n",
    "csv_file_path = 'merged_annotations.csv'\n",
    "jsonl_to_csv(jsonl_file_path, csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125eb525",
   "metadata": {},
   "source": [
    "## Some difference\n",
    "\n",
    "Detail information in: https://docs.google.com/spreadsheets/d/1J5xpQYRGW6fJnT6FG0xC2iRBycRBsFe4idsYKVkht_M/edit?usp=sharing\n",
    "\n",
    "1. There are some paper we classify differently. \n",
    "2. 3 of them got mark as N/A by other reviewer but I mark them as No BioNLP for model to make prediction. \n",
    "\n",
    "For the some of those paper, here are my analysis: \n",
    "\n",
    "1. Inter-sentence Relation Extraction with Document-level Graph Convolutional Neural Network: I mark as BioNLP but disaggre by other. \n",
    "\n",
    "Reason: \n",
    "Relevance to Biomedical Domain: The paper focuses on chemical disease relations and chemical reactions datasets, which are important components of biomedical research.\n",
    "\n",
    "Use of NLP Techniques: It use NLP methods for relation extraction, leveraging techniques like GCNN and MIL, specifically tailored to biomedical text.\n",
    "\n",
    "2. Nested Named Entity Recognition with Partially-Observed TreeCRFs (yes from me, no from other)\n",
    "\n",
    "Reason: \n",
    "Relevance to Biomedical Domain: Include the GENIA dataset which is biomedical, but primarily focuses on general techniques and includes datasets that are not exclusively biomedical.\n",
    "\n",
    "Use of NLP Techniques: The paper uses advanced NLP methods for NER and nested structures, even though these methods primarily applied to biomedical texts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c18dbb8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cpsc552)",
   "language": "python",
   "name": "cpsc552"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
